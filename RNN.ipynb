{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "70f147f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence, pack_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "import json\n",
    "\n",
    "from Metrics import Metrics\n",
    "from rnn_utils import split_dataset\n",
    "\n",
    "### Checking for GPU availability\n",
    "#This model was trained on a GPU enabled system...highly recommended.\n",
    "\n",
    "# check if GPU is available\n",
    "if(torch.cuda.is_available()):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('Training on CPU!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "09e8cc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2ba6ac041330>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reproducibility\n",
    "np.random.seed(546)\n",
    "torch.manual_seed(546)\n",
    "torch.cuda.manual_seed(546)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d5556b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosesDataset(Dataset):\n",
    "    def __init__(self, diagnoses_file,\n",
    "                 grouping='ccs' # desired grouping to use (for both input and output currently),\n",
    "                ):\n",
    "        \n",
    "        # load admissions data\n",
    "        with open(diagnoses_file,'r') as fp:\n",
    "            self.data = json.load(fp)\n",
    "        \n",
    "        # list patients\n",
    "        self.patients = list(self.data['data'].keys())\n",
    "        \n",
    "        self.grouping = grouping\n",
    "        \n",
    "        # necessary data of each code_grouping (eg. ccs, chapters) for posterior padding and one_hot_encoding of batches\n",
    "        self.grouping_data = {}\n",
    "        for grouping_code in self.data['metadata']['groupings']:\n",
    "            self.grouping_data[grouping_code] = {}\n",
    "            \n",
    "            # get all codes of this group\n",
    "            all_data_grouping = [self.data['data'][pat][grouping_code] for pat in self.data['data']]\n",
    "            \n",
    "            #flatten list of lists of lists\n",
    "            all_data_grouping = [item for sublist in all_data_grouping for item in sublist]\n",
    "            all_data_grouping = [item for sublist in all_data_grouping for item in sublist]\n",
    "            \n",
    "            # store n_labels this group\n",
    "            self.grouping_data[grouping_code]['n_labels'] = len(set(all_data_grouping))\n",
    "            \n",
    "            # store unique sorted codes from dataset\n",
    "            self.grouping_data[grouping_code]['sorted'] = sorted(set(all_data_grouping))\n",
    "            \n",
    "            # store code2int & int2code\n",
    "            int2code = dict(enumerate(self.grouping_data[grouping_code]['sorted']))\n",
    "            code2int = {ch: ii for ii, ch in int2code.items()}\n",
    "            \n",
    "            self.grouping_data[grouping_code]['int2code'] = int2code\n",
    "            self.grouping_data[grouping_code]['code2int'] = code2int\n",
    "            self.grouping_data[grouping_code]['int2code_converter'] = lambda idx: self.grouping_data[grouping_code]['int2code'][idx]\n",
    "        \n",
    "    def __str__(self):\n",
    "        return 'Available groupings: ' +str(self.data['metadata']['groupings'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['data'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        gets original converted from int2code\n",
    "        \"\"\"\n",
    "        patient_data = self.data['data'][self.patients[idx]][self.grouping]\n",
    "        \n",
    "        train = patient_data[:-1]\n",
    "        target = patient_data[1:]\n",
    "        \n",
    "        # remove duplicates (can happen in low granuality codes such as ccs)\n",
    "        \n",
    "        train = [list(set(admission)) for admission in train]\n",
    "        target = [list(set(admission)) for admission in target]\n",
    "        \n",
    "        return {'train':train,'target':target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a52975dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYCOLLATE:\n",
    "    \"\"\"\n",
    "    This collate class gets a dataset in the format of:\n",
    "    [\n",
    "    {'train':[[code1,code2],[code3,code4,code5],etc..]\n",
    "      'target:':[[code1,code2],[code3,code4,code5],etc..]\n",
    "    },\n",
    "     {etc..},\n",
    "     etc..\n",
    "    ]\n",
    "    \n",
    "    And outputs a pack of train and test sequences\n",
    "    \"\"\"\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __call__(self,batch):\n",
    "        patients = {'train':{'sequence':[],'original':[]},\n",
    "                    'target':{'sequence':[],'original':[]}}\n",
    "        \n",
    "        grouping_code = self.dataset.grouping\n",
    "        n_labels = self.dataset.grouping_data[grouping_code]['n_labels']\n",
    "        code2int = self.dataset.grouping_data[grouping_code]['code2int']\n",
    "        \n",
    "        # <NÂº admissions - 1> of each patient\n",
    "        seq_lengths = []\n",
    "        for pat in batch:\n",
    "            train_admissions_sequenced = []\n",
    "            target_admissions_sequenced = []\n",
    "            seq_lengths.append(len(pat))\n",
    "\n",
    "            # convert each train admission into a multi-hot vector\n",
    "            for train_admission in pat['train']:\n",
    "                admission = (F.one_hot(torch.tensor(list(map(lambda code: code2int[code],train_admission))),num_classes=n_labels)\n",
    "                             .sum(dim=0).float() #one-hot of each diagnose to multi-hot vector of diagnoses\n",
    "                            )\n",
    "                train_admissions_sequenced.append(admission)\n",
    "\n",
    "            # convert each target admission into a one-hot vector\n",
    "            for target_admission in pat['target']:\n",
    "                # convert each admission to multi-hot vector\n",
    "                admission = (F.one_hot(torch.tensor(list(map(lambda code: code2int[code],target_admission))),num_classes=n_labels)\n",
    "                             .sum(dim=0).float() #one-hot of each diagnose to multi-hot vector of diagnoses\n",
    "                            )\n",
    "                target_admissions_sequenced.append(admission)\n",
    "\n",
    "            # stack multiple train admissions of a single patient into a single tensor\n",
    "            if len(train_admissions_sequenced) > 1:\n",
    "                train_admissions_sequenced = torch.stack(train_admissions_sequenced)\n",
    "            else:\n",
    "                train_admissions_sequenced = train_admissions_sequenced[0].view((1,-1))\n",
    "\n",
    "            # stack multiple target admissions of a single patient into a single tensor\n",
    "            if len(target_admissions_sequenced) > 1:\n",
    "                target_admissions_sequenced = torch.stack(target_admissions_sequenced)\n",
    "            else:\n",
    "                target_admissions_sequenced = target_admissions_sequenced[0].view((1,-1))\n",
    "\n",
    "            # store final train and test tensors\n",
    "            patients['train']['sequence'].append(train_admissions_sequenced)\n",
    "            patients['target']['sequence'].append(target_admissions_sequenced)\n",
    "            \n",
    "            patients['train']['original'].append(pat['train'])\n",
    "            patients['target']['original'].append(pat['target'])\n",
    "\n",
    "        # pad sequences (some patients have more admissions than others)\n",
    "        patients['train']['sequence'] = pack_sequence(patients['train']['sequence'],enforce_sorted=False)\n",
    "        patients['target']['sequence'] = pad_sequence(patients['target']['sequence'],batch_first=True)\n",
    "        \n",
    "        # pack the padded sequences\n",
    "        \n",
    "        #patients['train'] = pack_padded_sequence(patients['train'],lengths=seq_lengths,batch_first=True)\n",
    "        #patients['target'] = pack_padded_sequence(patients['target'],lengths=seq_lengths,batch_first=True)\n",
    "        return {'train_sequences':patients['train'],'target_sequences':patients['target']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ba61bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size,num_layers,n_labels,model='rnn'):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "        if model == 'rnn':\n",
    "            self.model = nn.RNN(input_size=input_size,\n",
    "                              hidden_size=hidden_size,\n",
    "                              num_layers=num_layers\n",
    "                             )\n",
    "        elif model == 'gru':\n",
    "            self.model = nn.GRU(input_size=input_size,\n",
    "                              hidden_size=hidden_size,\n",
    "                              num_layers=num_layers\n",
    "                             )\n",
    "        elif model == 'lstm':\n",
    "            self.model = nn.LSTM(input_size=input_size,\n",
    "                              hidden_size=hidden_size,\n",
    "                              num_layers=num_layers\n",
    "                             )\n",
    "        else:\n",
    "            raise ValueError(f'oops. expecting model in [rnn,lstm,gru], got model={model}')\n",
    "        \n",
    "        self.lin = nn.Linear(in_features = hidden_size,\n",
    "                            out_features=n_labels\n",
    "                           )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input: pack_sequence\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        hn,_ = self.model(input)\n",
    "        \n",
    "        out = self.lin(pad_packed_sequence(hn,batch_first=True)[0])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8315b873",
   "metadata": {},
   "source": [
    "# Let's try to run the net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba4a0e",
   "metadata": {},
   "source": [
    "## prepare train and test splits\n",
    "\n",
    "**3 batches**:\n",
    "- train_dataloader\n",
    "- val_dataloader\n",
    "- test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fe9955ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "grouping = 'ccs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b3f9c9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6176"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1323"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1124"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = DiagnosesDataset('data/model_data.json',grouping)\n",
    "test_size = 0.15\n",
    "eval_size=0.15\n",
    "eval_size_corrected = eval_size/(1-test_size)\n",
    "\n",
    "whole_train_dataset_temp,test_dataset = split_dataset(dataset,test_size)\n",
    "whole_train_dataset\n",
    "train_dataset, val_dataset = split_dataset(whole_train_dataset.dataset,eval_size_corrected)\n",
    "\n",
    "len(train_dataset)\n",
    "len(val_dataset)\n",
    "len(test_dataset)\n",
    "\n",
    "whole_train_dataset = DataLoader(whole_train_dataset.dataset,batch_size=batch_size,collate_fn=MYCOLLATE(whole_train_dataset.dataset),shuffle=True)\n",
    "train_dataloader = DataLoader(train_dataset.dataset,batch_size=batch_size,collate_fn=MYCOLLATE(train_dataset.dataset),shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset.dataset,batch_size=batch_size,collate_fn=MYCOLLATE(val_dataset.dataset)) #batch_size here is arbitrary and doesn't affect total validation speed\n",
    "test_dataloader = DataLoader(test_dataset.dataset,batch_size=batch_size,collate_fn=MYCOLLATE(test_dataset.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f7202888",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=75\n",
    "num_layers=1\n",
    "input_size = n_labels = next(iter(train_dataloader))['target_sequences']['sequence'].shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d512058",
   "metadata": {},
   "source": [
    "# Converting outs from the model to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a9752c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outs2pred(outs, int2code : dict):\n",
    "    \"\"\"Converts the outputs of a model (logits) to diagnostic code predictions.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    \n",
    "    out: outputs of a model on a batch of variable-sized sequences\n",
    "    \n",
    "    int2code: dict mapping idx to diagnostic code\n",
    "    \n",
    "    \"\"\"\n",
    "    activations = nn.Sigmoid()(outs).detach().numpy()\n",
    "    \n",
    "    sorted_idx = np.argsort(activations)\n",
    "    \n",
    "    return np.vectorize(int2code.get)(sorted_idx)[:,:,::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef98cf75",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2c8c2887",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (model): GRU(272, 100)\n",
       "  (lin): Linear(in_features=100, out_features=272, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 251, 2607,   25, ...,    8,   39,  241],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        ...,\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114]],\n",
       "\n",
       "       [[ 180,  201,   33, ...,  159,   32,   38],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        ...,\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114]],\n",
       "\n",
       "       [[ 115,   92,  251, ...,   18,    8,   60],\n",
       "        [ 180,  251,  650, ...,   38,   98,    8],\n",
       "        [ 180,   57,  650, ...,   32,   98,    8],\n",
       "        ...,\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 195,    6,   11, ...,  159,  114,   60],\n",
       "        [ 195,    6,   57, ...,  230,   79,   60],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        ...,\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114]],\n",
       "\n",
       "       [[ 147,  180, 2601, ...,   79,   64,  141],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        ...,\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114]],\n",
       "\n",
       "       [[ 212,   92, 2607, ...,   12,  141,  241],\n",
       "        [ 116,   84,  224, ...,  241,  163,   61],\n",
       "        [ 116,   27,  663, ...,   26,   61,   12],\n",
       "        ...,\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114],\n",
       "        [ 234,   81,   95, ...,    8,   32,  114]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(input_size=input_size,\n",
    "              hidden_size=100,\n",
    "              num_layers=num_layers,\n",
    "              n_labels=n_labels,\n",
    "              model='gru')\n",
    "model.eval()\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "# get the inputs; data is a list of [inputs, labels]\n",
    "history_sequences, target_sequences = batch['train_sequences'],batch['target_sequences']\n",
    "\n",
    "outs = model(history_sequences['sequence'])\n",
    "_,lengths = pad_packed_sequence(history_sequences['sequence'])\n",
    "lengths = lengths.detach().numpy()\n",
    "\n",
    "int2code_dict = train_dataloader.dataset.grouping_data[grouping]['int2code']\n",
    "convert_batch_out_2_predictions_faster(outs,lengths,int2code_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29908de",
   "metadata": {},
   "source": [
    "# Compute metrics from predictions & targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a4a429cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(preds, targets):\n",
    "    \"\"\" \n",
    "    Computes recall for a batch of predictions. \n",
    "    Returns the average of each metric at the end in the format {metric:avg,metric2:avg,etc..}\n",
    "    \"\"\"\n",
    "    \n",
    "    levels = ['1 adm','2 adm','3 adm','>3 adm','last adm']\n",
    "    recall_at = [10,20,30]\n",
    "    \n",
    "    res = dict()\n",
    "    for key in levels:\n",
    "        res[key] = {f'recall{k}':[] for k in recall_at}\n",
    "    \n",
    "    for idx_pat, pat in enumerate(targets):\n",
    "        for idx_adm,adm in enumerate(pat):\n",
    "            for k in recall_at:\n",
    "                if idx_adm +1 <=3:\n",
    "                    res[f'{idx_adm+1} adm'][f'recall{k}'].append(Metrics.recall(adm,preds[idx_pat][idx_adm],k=k))\n",
    "                else:\n",
    "                    res[f'>3 adm'][f'recall{k}'].append(Metrics.recall(adm,preds[idx_pat][idx_adm],k=k))\n",
    "                \n",
    "                # we are at the last admission.\n",
    "                if idx_adm+1 == len(pat):\n",
    "                    res['last adm'][f'recall{k}'].append(Metrics.recall(adm,preds[idx_pat][idx_adm],k=k))\n",
    "    return res\n",
    "\n",
    "\n",
    "def concat_metrics(old_metrics:dict,new_metrics:dict):\n",
    "    # dicts are passed by reference\n",
    "    # so i just update whatever was passed to <old_metrics>\n",
    "    for level in old_metrics:\n",
    "        for metric in old_metrics[level]:\n",
    "            old_metrics[level][metric].extend(new_metrics[level][metric])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83401f4",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fb527e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (model): GRU(272, 100)\n",
       "  (lin): Linear(in_features=100, out_features=272, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.047619047619047616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.125, 0.05555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.04, 0.1, 0.07407407407407407, 0.0, 0.1111111111111111, 0.0, 0.05263157894736842, 0.0, 0.07142857142857142, 0.058823529411764705, 0.0, 0.1, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.058823529411764705, 0.0, 0.0, 0.0625, 0.07142857142857142, 0.0, 0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111]\n"
     ]
    }
   ],
   "source": [
    "model = RNN(input_size=input_size,\n",
    "              hidden_size=100,\n",
    "              num_layers=num_layers,\n",
    "              n_labels=n_labels,\n",
    "              model='gru')\n",
    "model.eval()\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "# get the inputs; data is a list of [inputs, labels]\n",
    "history_sequences, target_sequences = batch['train_sequences'],batch['target_sequences']\n",
    "\n",
    "outs = model(history_sequences['sequence'])\n",
    "_,lengths = pad_packed_sequence(history_sequences['sequence'])\n",
    "lengths = lengths.detach().numpy()\n",
    "\n",
    "int2code_dict = train_dataloader.dataset.grouping_data[grouping]['int2code']\n",
    "preds = outs2pred(outs,int2code_dict)\n",
    "\n",
    "\n",
    "res = compute_metricsV2(preds,target_sequences['original'])\n",
    "\n",
    "# show some stuff\n",
    "print(res['last adm']['recall10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc51ff6",
   "metadata": {},
   "source": [
    "# Eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6d66a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, criterion, epoch, name, only_loss=False):\n",
    "    \"\"\"\n",
    "    This functions evaluates and computes metrics of a model checkpoint on a dataloader\n",
    "    \"\"\"\n",
    "    \n",
    "    # eg:: ccs, icd9, etc..\n",
    "    code_type = dataloader.dataset.grouping\n",
    "    \n",
    "    \n",
    "    int2code = dataloader.dataset.grouping_data[code_type]['int2code']\n",
    "    \n",
    "    result = {'name':name,\n",
    "              'epoch':epoch\n",
    "             }\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_seq = 0 #total sequences\n",
    "    \n",
    "    all_metrics = None\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iter(dataloader)):\n",
    "            \n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            history_sequences, target_sequences = batch['train_sequences'],batch['target_sequences']\n",
    "\n",
    "            outs = model(history_sequences['sequence'])\n",
    "\n",
    "            loss = criterion(outs, target_sequences['sequence'])\n",
    "\n",
    "            # compute loss\n",
    "            n = target_sequences['sequence'].size(0)\n",
    "            total_seq += n\n",
    "            total_loss += loss.item() * n\n",
    "            \n",
    "            # compute other metrics\n",
    "\n",
    "            _,lengths = pad_packed_sequence(history_sequences['sequence'])\n",
    "            \n",
    "            preds = outs2pred(outs,int2code)\n",
    "            \n",
    "            if all_metrics is None:\n",
    "                all_metrics = compute_metrics(preds,target_sequences['original'])\n",
    "            else:\n",
    "                new_metrics = compute_metrics(preds,target_sequences['original'])\n",
    "                concat_metrics(all_metrics,new_metrics)\n",
    "\n",
    "        result['loss'] = total_loss / total_seq\n",
    "        if only_loss:\n",
    "            return result\n",
    "        for level in all_metrics:\n",
    "            if level not in result:\n",
    "                result[level] = {}\n",
    "            for metric in all_metrics[level]:\n",
    "                if metric not in result[level].keys():\n",
    "                    result[level][metric] = {}\n",
    "                result[level][metric] = {'mean':np.mean(all_metrics[level][metric]),\n",
    "                                         'std':np.std(all_metrics[level][metric]),\n",
    "                                         'n': len(all_metrics[level][metric])\n",
    "                                        }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc856a92",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d3a7802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done here\n"
     ]
    }
   ],
   "source": [
    "## Example eval_model\n",
    "\n",
    "model = RNN(input_size=input_size,\n",
    "              hidden_size=100,\n",
    "              num_layers=num_layers,\n",
    "              n_labels=n_labels,\n",
    "              model='gru')\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "res = eval_model(model, val_dataloader, criterion, epoch,'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8e0b6248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'val',\n",
       " 'epoch': 3,\n",
       " 'loss': 0.6932924579009802,\n",
       " '1 adm': {'recall10': {'mean': 0.022220470884709208,\n",
       "   'std': 0.04869707662564347,\n",
       "   'n': 7499},\n",
       "  'recall20': {'mean': 0.04922809333090191,\n",
       "   'std': 0.07253438597216255,\n",
       "   'n': 7499},\n",
       "  'recall30': {'mean': 0.07987495790207726,\n",
       "   'std': 0.0981748012054294,\n",
       "   'n': 7499}},\n",
       " '2 adm': {'recall10': {'mean': 0.025817457278895485,\n",
       "   'std': 0.057913734902979894,\n",
       "   'n': 2374},\n",
       "  'recall20': {'mean': 0.0553148705746406,\n",
       "   'std': 0.07775293177598733,\n",
       "   'n': 2374},\n",
       "  'recall30': {'mean': 0.0869839970474674,\n",
       "   'std': 0.08965554567738389,\n",
       "   'n': 2374}},\n",
       " '3 adm': {'recall10': {'mean': 0.02741393369361806,\n",
       "   'std': 0.04801716203732152,\n",
       "   'n': 1033},\n",
       "  'recall20': {'mean': 0.05792350042884539,\n",
       "   'std': 0.06568919505834019,\n",
       "   'n': 1033},\n",
       "  'recall30': {'mean': 0.09308716741743037,\n",
       "   'std': 0.08313247879423646,\n",
       "   'n': 1033}},\n",
       " '>3 adm': {'recall10': {'mean': 0.03231670332815459,\n",
       "   'std': 0.05135653832659585,\n",
       "   'n': 1506},\n",
       "  'recall20': {'mean': 0.06994991050590683,\n",
       "   'std': 0.07361114505747215,\n",
       "   'n': 1506},\n",
       "  'recall30': {'mean': 0.10996371806948578,\n",
       "   'std': 0.09173212980134518,\n",
       "   'n': 1506}},\n",
       " 'last adm': {'recall10': {'mean': 0.023512956640214844,\n",
       "   'std': 0.05140845487009863,\n",
       "   'n': 7499},\n",
       "  'recall20': {'mean': 0.05173287465265766,\n",
       "   'std': 0.07471341206154324,\n",
       "   'n': 7499},\n",
       "  'recall30': {'mean': 0.08415264697715279,\n",
       "   'std': 0.09870957605775997,\n",
       "   'n': 7499}}}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f69be",
   "metadata": {},
   "source": [
    "# Train one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f30e5c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, epoch, criterion, optimizer):\n",
    "    \"\"\"\n",
    "    Trains one epoch and returns mean loss over training\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_n = 0\n",
    "    for i, batch in enumerate(iter(train_loader)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        history_sequences, target_sequences = batch['train_sequences'],batch['target_sequences']\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        \n",
    "        outs = model(history_sequences['sequence'])\n",
    "        \n",
    "        loss = criterion(outs, target_sequences['sequence'])\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        _,lengths = pad_packed_sequence(history_sequences['sequence'])\n",
    "        \n",
    "        n = lengths.sum().item()\n",
    "        \n",
    "        total_loss += loss.item() * n\n",
    "        total_n += n\n",
    "    return total_loss / total_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c901fa",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1e8bfb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 37 ms, total: 1min 18s\n",
      "Wall time: 1min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "## Example eval_model\n",
    "\n",
    "model = RNN(input_size=input_size,\n",
    "              hidden_size=100,\n",
    "              num_layers=num_layers,\n",
    "              n_labels=n_labels,\n",
    "              model='gru')\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "\n",
    "losses = []\n",
    "val_metrics = []\n",
    "for epoch in range(0,7):\n",
    "    loss = train_one_epoch(model,train_dataloader, 1, criterion, opt)\n",
    "    losses.append(loss)\n",
    "    if epoch % 2 == 0:\n",
    "        val_metrics.append(eval_model(model,val_dataloader,criterion,epoch,'val'))\n",
    "pd.Series(losses).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ba4137f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2689212545074929"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.045974987054176374"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics[0]['loss']\n",
    "val_metrics[-1]['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6c88cc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall10': {'mean': 0.3701218691926719,\n",
       "  'std': 0.18219751326524034,\n",
       "  'n': 7499},\n",
       " 'recall20': {'mean': 0.5295617367666753,\n",
       "  'std': 0.18774851693388908,\n",
       "  'n': 7499},\n",
       " 'recall30': {'mean': 0.640873301892558,\n",
       "  'std': 0.17920721807228104,\n",
       "  'n': 7499}}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics[0]['1 adm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a849d976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recall10': {'mean': 0.36163155089136967,\n",
       "  'std': 0.1766170570851731,\n",
       "  'n': 7499},\n",
       " 'recall20': {'mean': 0.5236286991838952,\n",
       "  'std': 0.18212773054602718,\n",
       "  'n': 7499},\n",
       " 'recall30': {'mean': 0.635913820216052,\n",
       "  'std': 0.17583566818017943,\n",
       "  'n': 7499}}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'recall10': {'mean': 0.48630403387046084,\n",
       "  'std': 0.1925538402742622,\n",
       "  'n': 7499},\n",
       " 'recall20': {'mean': 0.6620859655520701,\n",
       "  'std': 0.1773473182249729,\n",
       "  'n': 7499},\n",
       " 'recall30': {'mean': 0.7636116507806993,\n",
       "  'std': 0.15810650249322447,\n",
       "  'n': 7499}}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics[0]['last adm']\n",
    "val_metrics[-1]['last adm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18783e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39f13844",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64daad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=input_size,\n",
    "          hidden_size=hidden_size,\n",
    "          num_layers=num_layers,\n",
    "          n_labels=n_labels)\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "opt = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "\n",
    "# contains softmax internally\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "show_every=100\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, batch in enumerate(iter(train_dataloader)):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        train_sequence, target_sequence = batch['train_sequences'],batch['target_sequences']\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        rnn.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        \n",
    "        outs = rnn(train_sequence['sequence'])\n",
    "        \n",
    "        loss = criterion(outs, target_sequence['sequence'])\n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        \n",
    "        running_loss += loss.item() * target_sequence.size(0)\n",
    "        \n",
    "    loss_history.append(running_loss / len(train_dataloader))\n",
    "    print('epoch',epoch+1,'Done with loss',loss_history[-1])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
