{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence, pack_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# protection against running this cell multiple times\n",
    "assert os.path.dirname(cwd).split('/')[-1] == 'master-thesis','Oops, directory already changed previously as indended. Ignoring...'\n",
    "\n",
    "# change working directory (if assert passed)\n",
    "new_cwd = os.path.dirname(cwd) # parent directory\n",
    "os.chdir(new_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'outs2df_mc' from 'rnn_utils' (/Users/simaonovais/Documents/GitHub/master-thesis/rnn_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [311]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(this_dir)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrnn_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiagnosesDataset, split_dataset, MYCOLLATE\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrnn_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_one_epoch, eval_model, outs2df_mc\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmourga_variational\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariational_rnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariationalRNN\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'outs2df_mc' from 'rnn_utils' (/Users/simaonovais/Documents/GitHub/master-thesis/rnn_utils.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "this_dir = \"..\"\n",
    "if this_dir not in sys.path:\n",
    "    sys.path.append(this_dir)\n",
    "\n",
    "from rnn_utils import DiagnosesDataset, split_dataset, MYCOLLATE\n",
    "from rnn_utils import train_one_epoch, eval_model, outs2df_mc\n",
    "\n",
    "from mourga_variational.variational_rnn import VariationalRNN\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from config import Settings; settings = Settings()\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x109ff8b90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reproducibility\n",
    "seed = settings.random_seed\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 'diag_only'\n",
    "grouping = 'ccs'\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset at data/model_ready_dataset/diag_only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5249"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_folder = os.path.join(settings.data_base,settings.model_ready_dataset_folder,dataset_id)\n",
    "print('dataset at',dataset_folder)\n",
    "\n",
    "dataset = DiagnosesDataset(os.path.join(dataset_folder,'dataset.json'),grouping)\n",
    "\n",
    "train_dataset = DiagnosesDataset(os.path.join(dataset_folder,'train_subset.json'),grouping)\n",
    "val_dataset = DiagnosesDataset(os.path.join(dataset_folder,'val_subset.json'),grouping)\n",
    "test_dataset = DiagnosesDataset(os.path.join(dataset_folder,'test_subset.json'),grouping)\n",
    "\n",
    "\n",
    "len(train_dataset)\n",
    "len(val_dataset)\n",
    "len(test_dataset)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size,collate_fn=MYCOLLATE(dataset),shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=batch_size,collate_fn=MYCOLLATE(dataset)) #batch_size here is arbitrary and doesn't affect total validation speed\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=batch_size,collate_fn=MYCOLLATE(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = next(iter(train_dataloader))['target_sequences']['sequence'].shape[2]\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "n_labels = input_size\n",
    "model_type = 'gru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.2\n",
    "dropouti = dropout\n",
    "dropoutw = dropout\n",
    "dropouto = dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VariationalRNN(input_size=input_size,\n",
    "                       hidden_size=hidden_size,\n",
    "                       n_labels=n_labels,\n",
    "                       num_layers=num_layers,\n",
    "                       rnn_type=model_type,\n",
    "                       dropouti=dropouti,\n",
    "                       dropoutw=dropoutw,\n",
    "                       dropouto=dropouto\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09338595837009094"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss: 0.1768575266721737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5978395954393771"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | loss: 0.12670961363487934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6468799973735518"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | loss: 0.12123737924070244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6683152002844288"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | loss: 0.11769239712192352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6644883834566765"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | loss: 0.114641822695014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6796602510058005"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | loss: 0.1127079840166023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.692805877349853"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | loss: 0.11075322985290045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7030957856054423"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | loss: 0.10890622885830431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7053674280792359"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | loss: 0.10731690341090581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6965423997021247"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | loss: 0.10692487639116954\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    eval_model(model,val_dataloader,dataset,['recall@30'])[1]['recall@30_adm']\n",
    "    loss = train_one_epoch(model,train_dataloader,epoch,criterion,opt)\n",
    "    losses.append(loss)\n",
    "    print(f'epoch: {epoch+1} | loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_outs,col_names,tpids,outs = outs2df_mc(model,val_dataloader,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 129, 272)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 64, 33, 272])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_outs.shape\n",
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9948898e-04, 4.7340724e-01, 3.7745050e-01], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00155328, 0.28718367, 0.3400149 ], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_outs[0,0,:3]\n",
    "relevant_outs[0,1,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.9948898e-04, 4.7340724e-01, 3.7745050e-01], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00155328, 0.28718367, 0.3400149 ], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape = relevant_outs.reshape((-1,relevant_outs.shape[-1]),order='C')\n",
    "reshape[0,:3]\n",
    "reshape[1,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = None\n",
    "for i in range(relevant_outs.shape[0]):\n",
    "    df = pd.DataFrame(relevant_outs[i,:,:],columns=col_names)\n",
    "    df = df.assign(n_pass=i+1,pat_id=tpids)\n",
    "    full_df = df if full_df is None else pd.concat([full_df,df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     64.0\n",
       "2     18.0\n",
       "3     10.0\n",
       "4      5.0\n",
       "5      3.0\n",
       "6      2.0\n",
       "26     1.0\n",
       "22     1.0\n",
       "23     1.0\n",
       "24     1.0\n",
       "25     1.0\n",
       "29     1.0\n",
       "27     1.0\n",
       "28     1.0\n",
       "20     1.0\n",
       "30     1.0\n",
       "31     1.0\n",
       "32     1.0\n",
       "21     1.0\n",
       "17     1.0\n",
       "19     1.0\n",
       "18     1.0\n",
       "16     1.0\n",
       "15     1.0\n",
       "14     1.0\n",
       "13     1.0\n",
       "12     1.0\n",
       "11     1.0\n",
       "10     1.0\n",
       "9      1.0\n",
       "8      1.0\n",
       "7      1.0\n",
       "33     1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = full_df.groupby(['pat_id','n_pass']).cumcount()+1\n",
    "a.value_counts() / 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diag_0</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>diag_4</th>\n",
       "      <th>diag_5</th>\n",
       "      <th>diag_6</th>\n",
       "      <th>diag_7</th>\n",
       "      <th>diag_8</th>\n",
       "      <th>diag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_263</th>\n",
       "      <th>diag_264</th>\n",
       "      <th>diag_265</th>\n",
       "      <th>diag_266</th>\n",
       "      <th>diag_267</th>\n",
       "      <th>diag_268</th>\n",
       "      <th>diag_269</th>\n",
       "      <th>diag_270</th>\n",
       "      <th>diag_271</th>\n",
       "      <th>pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.473407</td>\n",
       "      <td>0.377450</td>\n",
       "      <td>0.083815</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.00322</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.014055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.011414</td>\n",
       "      <td>0.311724</td>\n",
       "      <td>0.118583</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.040012</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.287184</td>\n",
       "      <td>0.340015</td>\n",
       "      <td>0.056402</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.01485</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.015139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>0.550274</td>\n",
       "      <td>0.262596</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.015141</td>\n",
       "      <td>0.050112</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diag_0    diag_1    diag_2    diag_3    diag_4    diag_5   diag_6  \\\n",
       "0  0.000299  0.473407  0.377450  0.083815  0.000143  0.004440  0.00322   \n",
       "1  0.001553  0.287184  0.340015  0.056402  0.002303  0.007843  0.01485   \n",
       "\n",
       "     diag_7    diag_8    diag_9  ...  diag_263  diag_264  diag_265  diag_266  \\\n",
       "0  0.000226  0.001236  0.014055  ...  0.012492  0.000678  0.011414  0.311724   \n",
       "1  0.001098  0.006551  0.015139  ...  0.001254  0.001542  0.008112  0.550274   \n",
       "\n",
       "   diag_267  diag_268  diag_269  diag_270  diag_271  pid  \n",
       "0  0.118583  0.007116  0.001708  0.002212  0.040012   21  \n",
       "1  0.262596  0.002852  0.003681  0.015141  0.050112   23  \n",
       "\n",
       "[2 rows x 273 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(reshape,columns=col_names).assign(pid=tpids*15)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_list = lambda x: [item for sublist in x for item in sublist]\n",
    "_,lengths = pad_packed_sequence(res['inputs'],batch_first=True)\n",
    "relevant_positions = [[i+idx*max(lengths) for i in range(e)] for idx,e in enumerate(lengths)]\n",
    "relevant_positions = flatten_list(relevant_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 64, 33, 272])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['outs'].size()\n",
    "outs = res['outs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_flattened = outs.view(15,1,-1,outs.size()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = outs2df_mc(model,val_dataloader,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>diag_0</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>diag_4</th>\n",
       "      <th>diag_5</th>\n",
       "      <th>diag_6</th>\n",
       "      <th>diag_7</th>\n",
       "      <th>diag_8</th>\n",
       "      <th>diag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_262</th>\n",
       "      <th>diag_263</th>\n",
       "      <th>diag_264</th>\n",
       "      <th>diag_265</th>\n",
       "      <th>diag_266</th>\n",
       "      <th>diag_267</th>\n",
       "      <th>diag_268</th>\n",
       "      <th>diag_269</th>\n",
       "      <th>diag_270</th>\n",
       "      <th>diag_271</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pat_id</th>\n",
       "      <th>adm_index</th>\n",
       "      <th>n_pass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93900</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.150945</td>\n",
       "      <td>0.321342</td>\n",
       "      <td>0.142524</td>\n",
       "      <td>0.216501</td>\n",
       "      <td>0.00475</td>\n",
       "      <td>0.033394</td>\n",
       "      <td>0.007169</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.111915</td>\n",
       "      <td>0.152679</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.00729</td>\n",
       "      <td>0.010546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           diag_0    diag_1    diag_2    diag_3   diag_4  \\\n",
       "pat_id adm_index n_pass                                                    \n",
       "93900  1         1       0.150945  0.321342  0.142524  0.216501  0.00475   \n",
       "\n",
       "                           diag_5    diag_6    diag_7    diag_8    diag_9  \\\n",
       "pat_id adm_index n_pass                                                     \n",
       "93900  1         1       0.033394  0.007169  0.004182  0.000807  0.011241   \n",
       "\n",
       "                         ...  diag_262  diag_263  diag_264  diag_265  \\\n",
       "pat_id adm_index n_pass  ...                                           \n",
       "93900  1         1       ...  0.000511  0.002802  0.000095  0.004301   \n",
       "\n",
       "                         diag_266  diag_267  diag_268  diag_269  diag_270  \\\n",
       "pat_id adm_index n_pass                                                     \n",
       "93900  1         1       0.111915  0.152679  0.002311  0.001637   0.00729   \n",
       "\n",
       "                         diag_271  \n",
       "pat_id adm_index n_pass            \n",
       "93900  1         1       0.010546  \n",
       "\n",
       "[1 rows x 272 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[93900,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>diag_0</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>diag_4</th>\n",
       "      <th>diag_5</th>\n",
       "      <th>diag_6</th>\n",
       "      <th>diag_7</th>\n",
       "      <th>diag_8</th>\n",
       "      <th>diag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_262</th>\n",
       "      <th>diag_263</th>\n",
       "      <th>diag_264</th>\n",
       "      <th>diag_265</th>\n",
       "      <th>diag_266</th>\n",
       "      <th>diag_267</th>\n",
       "      <th>diag_268</th>\n",
       "      <th>diag_269</th>\n",
       "      <th>diag_270</th>\n",
       "      <th>diag_271</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pat_id</th>\n",
       "      <th>adm_index</th>\n",
       "      <th>n_pass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">93900</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.150945</td>\n",
       "      <td>0.321342</td>\n",
       "      <td>0.142524</td>\n",
       "      <td>0.216501</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.033394</td>\n",
       "      <td>0.007169</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.011241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.111915</td>\n",
       "      <td>0.152679</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.001637</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>0.010546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <td>0.093866</td>\n",
       "      <td>0.234289</td>\n",
       "      <td>0.189880</td>\n",
       "      <td>0.194848</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.055939</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.057578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.014509</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.116717</td>\n",
       "      <td>0.138742</td>\n",
       "      <td>0.005906</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.045667</td>\n",
       "      <td>0.019108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <td>0.037203</td>\n",
       "      <td>0.164649</td>\n",
       "      <td>0.142297</td>\n",
       "      <td>0.177512</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.043687</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.017861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.010751</td>\n",
       "      <td>0.175521</td>\n",
       "      <td>0.095177</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.024274</td>\n",
       "      <td>0.019977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>2</th>\n",
       "      <td>0.025154</td>\n",
       "      <td>0.222276</td>\n",
       "      <td>0.189821</td>\n",
       "      <td>0.109926</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.068694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.007660</td>\n",
       "      <td>0.206475</td>\n",
       "      <td>0.050309</td>\n",
       "      <td>0.007982</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>0.029030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>2</th>\n",
       "      <td>0.015191</td>\n",
       "      <td>0.120062</td>\n",
       "      <td>0.097605</td>\n",
       "      <td>0.049162</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.033977</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.085978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.006139</td>\n",
       "      <td>0.128479</td>\n",
       "      <td>0.039098</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.018096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">99756</th>\n",
       "      <th>26</th>\n",
       "      <th>13</th>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.044662</td>\n",
       "      <td>0.066959</td>\n",
       "      <td>0.054407</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.056812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.026045</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.104684</td>\n",
       "      <td>0.065463</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.050681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <th>14</th>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.148587</td>\n",
       "      <td>0.170318</td>\n",
       "      <td>0.200187</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.696831</td>\n",
       "      <td>0.048622</td>\n",
       "      <td>0.197584</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.310313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012251</td>\n",
       "      <td>0.217895</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>0.043749</td>\n",
       "      <td>0.242031</td>\n",
       "      <td>0.327795</td>\n",
       "      <td>0.050682</td>\n",
       "      <td>0.114249</td>\n",
       "      <td>0.109062</td>\n",
       "      <td>0.179881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <th>14</th>\n",
       "      <td>0.013533</td>\n",
       "      <td>0.112761</td>\n",
       "      <td>0.106941</td>\n",
       "      <td>0.109278</td>\n",
       "      <td>0.027379</td>\n",
       "      <td>0.575033</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>0.086115</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.153722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.094190</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>0.189372</td>\n",
       "      <td>0.281381</td>\n",
       "      <td>0.010898</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>0.117959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <th>15</th>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.066402</td>\n",
       "      <td>0.054298</td>\n",
       "      <td>0.081918</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>0.433625</td>\n",
       "      <td>0.014034</td>\n",
       "      <td>0.164654</td>\n",
       "      <td>0.005430</td>\n",
       "      <td>0.220037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.006867</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.386076</td>\n",
       "      <td>0.093742</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.050406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>15</th>\n",
       "      <td>0.011288</td>\n",
       "      <td>0.050706</td>\n",
       "      <td>0.047058</td>\n",
       "      <td>0.045859</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>0.220220</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.086263</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.075128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.159617</td>\n",
       "      <td>0.081663</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.025184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           diag_0    diag_1    diag_2    diag_3    diag_4  \\\n",
       "pat_id adm_index n_pass                                                     \n",
       "93900  1         1       0.150945  0.321342  0.142524  0.216501  0.004750   \n",
       "       2         1       0.093866  0.234289  0.189880  0.194848  0.000316   \n",
       "       3         1       0.037203  0.164649  0.142297  0.177512  0.000130   \n",
       "       4         2       0.025154  0.222276  0.189821  0.109926  0.000614   \n",
       "       5         2       0.015191  0.120062  0.097605  0.049162  0.000964   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "99756  26        13      0.002165  0.044662  0.066959  0.054407  0.000255   \n",
       "       27        14      0.031242  0.148587  0.170318  0.200187  0.010490   \n",
       "       28        14      0.013533  0.112761  0.106941  0.109278  0.027379   \n",
       "       29        15      0.007244  0.066402  0.054298  0.081918  0.009042   \n",
       "       30        15      0.011288  0.050706  0.047058  0.045859  0.015758   \n",
       "\n",
       "                           diag_5    diag_6    diag_7    diag_8    diag_9  \\\n",
       "pat_id adm_index n_pass                                                     \n",
       "93900  1         1       0.033394  0.007169  0.004182  0.000807  0.011241   \n",
       "       2         1       0.055939  0.003441  0.003561  0.001317  0.057578   \n",
       "       3         1       0.043687  0.001893  0.003107  0.000848  0.017861   \n",
       "       4         2       0.015292  0.002618  0.002260  0.000977  0.068694   \n",
       "       5         2       0.033977  0.001629  0.001443  0.000214  0.085978   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "99756  26        13      0.005807  0.014281  0.013029  0.000775  0.056812   \n",
       "       27        14      0.696831  0.048622  0.197584  0.004054  0.310313   \n",
       "       28        14      0.575033  0.030195  0.086115  0.000828  0.153722   \n",
       "       29        15      0.433625  0.014034  0.164654  0.005430  0.220037   \n",
       "       30        15      0.220220  0.006702  0.086263  0.003689  0.075128   \n",
       "\n",
       "                         ...  diag_262  diag_263  diag_264  diag_265  \\\n",
       "pat_id adm_index n_pass  ...                                           \n",
       "93900  1         1       ...  0.000511  0.002802  0.000095  0.004301   \n",
       "       2         1       ...  0.001233  0.014509  0.000311  0.023370   \n",
       "       3         1       ...  0.000477  0.005153  0.000131  0.010751   \n",
       "       4         2       ...  0.000139  0.003046  0.000042  0.007660   \n",
       "       5         2       ...  0.000083  0.002630  0.000024  0.006139   \n",
       "...                      ...       ...       ...       ...       ...   \n",
       "99756  26        13      ...  0.000538  0.026045  0.000454  0.003698   \n",
       "       27        14      ...  0.012251  0.217895  0.010549  0.043749   \n",
       "       28        14      ...  0.003153  0.094190  0.002156  0.011619   \n",
       "       29        15      ...  0.000683  0.006867  0.000282  0.000498   \n",
       "       30        15      ...  0.000312  0.007497  0.000124  0.000103   \n",
       "\n",
       "                         diag_266  diag_267  diag_268  diag_269  diag_270  \\\n",
       "pat_id adm_index n_pass                                                     \n",
       "93900  1         1       0.111915  0.152679  0.002311  0.001637  0.007290   \n",
       "       2         1       0.116717  0.138742  0.005906  0.004169  0.045667   \n",
       "       3         1       0.175521  0.095177  0.002099  0.000924  0.024274   \n",
       "       4         2       0.206475  0.050309  0.007982  0.003581  0.005064   \n",
       "       5         2       0.128479  0.039098  0.002801  0.002173  0.004739   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "99756  26        13      0.104684  0.065463  0.010299  0.002955  0.006544   \n",
       "       27        14      0.242031  0.327795  0.050682  0.114249  0.109062   \n",
       "       28        14      0.189372  0.281381  0.010898  0.016342  0.058351   \n",
       "       29        15      0.386076  0.093742  0.000679  0.001955  0.003955   \n",
       "       30        15      0.159617  0.081663  0.000475  0.000676  0.002386   \n",
       "\n",
       "                         diag_271  \n",
       "pat_id adm_index n_pass            \n",
       "93900  1         1       0.010546  \n",
       "       2         1       0.019108  \n",
       "       3         1       0.019977  \n",
       "       4         2       0.029030  \n",
       "       5         2       0.018096  \n",
       "...                           ...  \n",
       "99756  26        13      0.050681  \n",
       "       27        14      0.179881  \n",
       "       28        14      0.117959  \n",
       "       29        15      0.050406  \n",
       "       30        15      0.025184  \n",
       "\n",
       "[1140 rows x 272 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outs2df_mc(model,dataloader,dataset,return_golden=False):\n",
    "    \"\"\"\n",
    "    Generates model outputs on a dataloader and returns as a pd.DataFrame.\n",
    "    \n",
    "    If <return_golden> is True, also returns a dataframe with the golden labels.\n",
    "    \"\"\"\n",
    "    model.train() # needs to be active for mc_dropout\n",
    "    \n",
    "     # eg:: ccs, icd9, etc..\n",
    "    code_type = dataset.grouping\n",
    "    \n",
    "    int2code = dataset.grouping_data[code_type]['int2code']\n",
    "    n_labels = len(int2code)\n",
    "    \n",
    "    col_names = ['diag_' + str(code) for code in int2code.keys()]\n",
    "    \n",
    "    sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    flatten_list = lambda x: [item for sublist in x for item in sublist]\n",
    "    \n",
    "    full_df = full_golden = None\n",
    "    for i, batch in enumerate(iter(dataloader)):\n",
    "\n",
    "        inputs, targets = batch['train_sequences']['sequence'],batch['target_sequences']['sequence']\n",
    "        outs = model(inputs,take_mc_average=False)\n",
    "\n",
    "        # Turn to pandas to store the <model_output> data\n",
    "\n",
    "        # we want to ignore the padded sequences\n",
    "        _,lengths = pad_packed_sequence(inputs,batch_first=True)\n",
    "        relevant_positions = [[i+idx*max(lengths) for i in range(e)] for idx,e in enumerate(lengths)]\n",
    "        relevant_positions = flatten_list(relevant_positions)\n",
    "\n",
    "        outs_flattened = outs.view(outs.size()[0],1,-1,outs.size()[-1])\n",
    "        relevant_outs = outs_flattened[:,:,relevant_positions,:]\n",
    "        relevant_outs = sigmoid(relevant_outs).detach().numpy()[:,0,:]\n",
    "        \n",
    "        # merge the N passes\n",
    "        full_df_npass = None\n",
    "        for i in range(relevant_outs.shape[0]):\n",
    "            df = pd.DataFrame(relevant_outs[i,:,:],columns=col_names)\n",
    "            df = df.assign(n_pass=i+1,pat_id=batch['target_pids'])\n",
    "            full_df_npass = df if full_df_npass is None else pd.concat([full_df_npass,df])\n",
    "        \n",
    "        full_df = full_df_npass if full_df is None else pd.concat([full_df,full_df_npass])\n",
    "\n",
    "        if return_golden:\n",
    "            targets_flattened = targets.view(1,-1,targets.size()[2])\n",
    "            relevant_targets = targets_flattened[:,relevant_positions,:].detach().numpy()[0,:,:]\n",
    "            golden_df = (pd.DataFrame(relevant_targets,\n",
    "                                    columns=col_names)\n",
    "                         .assign(pat_id=batch['target_pids'])\n",
    "                        )\n",
    "            full_golden = golden_df if full_golden is None else pd.concat([full_golden,golden_df])\n",
    "\n",
    "    full_df['adm_index'] = full_df.groupby(['pat_id','n_pass']).cumcount()+1\n",
    "    full_df = full_df.reset_index(drop=True)\n",
    "    full_df[['pat_id','adm_index']] = full_df[['pat_id','adm_index']].astype(int)\n",
    "    # reorder columns\n",
    "    full_df = full_df.set_index(['pat_id','adm_index','n_pass']).sort_index()\n",
    "\n",
    "    if return_golden:\n",
    "        full_golden['adm_index'] = full_golden.groupby(['pat_id']).cumcount()+1\n",
    "        full_golden = full_golden.reset_index(drop=True)\n",
    "        full_golden[['pat_id','adm_index']] = full_golden[['pat_id','adm_index']].astype(int)\n",
    "        # reorder columns\n",
    "        full_golden = full_golden.set_index(['pat_id','adm_index']).sort_index()\n",
    "\n",
    "        return full_df,full_golden\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 129, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 127, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 118, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 130, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 107, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 95, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 108, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 131, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 113, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 129, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 107, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 96, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 107, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 100, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 86, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 80, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 104, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, 76, 272)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>diag_0</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>diag_4</th>\n",
       "      <th>diag_5</th>\n",
       "      <th>diag_6</th>\n",
       "      <th>diag_7</th>\n",
       "      <th>diag_8</th>\n",
       "      <th>diag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_262</th>\n",
       "      <th>diag_263</th>\n",
       "      <th>diag_264</th>\n",
       "      <th>diag_265</th>\n",
       "      <th>diag_266</th>\n",
       "      <th>diag_267</th>\n",
       "      <th>diag_268</th>\n",
       "      <th>diag_269</th>\n",
       "      <th>diag_270</th>\n",
       "      <th>diag_271</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pat_id</th>\n",
       "      <th>adm_index</th>\n",
       "      <th>n_pass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">21</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.032539</td>\n",
       "      <td>0.242594</td>\n",
       "      <td>0.169882</td>\n",
       "      <td>0.167440</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.058049</td>\n",
       "      <td>0.026044</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>0.121698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.016892</td>\n",
       "      <td>0.211880</td>\n",
       "      <td>0.195146</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.079044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.162189</td>\n",
       "      <td>0.043052</td>\n",
       "      <td>0.042609</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.013655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.091234</td>\n",
       "      <td>0.065028</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.030642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.123530</td>\n",
       "      <td>0.166680</td>\n",
       "      <td>0.096426</td>\n",
       "      <td>0.130095</td>\n",
       "      <td>0.006716</td>\n",
       "      <td>0.045917</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.199120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.019225</td>\n",
       "      <td>0.071668</td>\n",
       "      <td>0.110959</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.037897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.115188</td>\n",
       "      <td>0.079149</td>\n",
       "      <td>0.070948</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.107383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>0.091769</td>\n",
       "      <td>0.080935</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.026199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.394419</td>\n",
       "      <td>0.103910</td>\n",
       "      <td>0.110775</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.050175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.165625</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.024375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">99756</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>11</th>\n",
       "      <td>0.012420</td>\n",
       "      <td>0.090209</td>\n",
       "      <td>0.175551</td>\n",
       "      <td>0.079750</td>\n",
       "      <td>0.015177</td>\n",
       "      <td>0.260487</td>\n",
       "      <td>0.097329</td>\n",
       "      <td>0.076201</td>\n",
       "      <td>0.007032</td>\n",
       "      <td>0.139333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.072918</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.102012</td>\n",
       "      <td>0.181597</td>\n",
       "      <td>0.026447</td>\n",
       "      <td>0.013044</td>\n",
       "      <td>0.097084</td>\n",
       "      <td>0.038923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.218797</td>\n",
       "      <td>0.066115</td>\n",
       "      <td>0.082487</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.072757</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>0.086022</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.141744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.006461</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.093471</td>\n",
       "      <td>0.095394</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.011953</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.036896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.101160</td>\n",
       "      <td>0.208187</td>\n",
       "      <td>0.169326</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>0.525002</td>\n",
       "      <td>0.028517</td>\n",
       "      <td>0.302174</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.248651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.060098</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.268445</td>\n",
       "      <td>0.138418</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>0.134179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.255018</td>\n",
       "      <td>0.172330</td>\n",
       "      <td>0.133123</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.049835</td>\n",
       "      <td>0.018143</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.098977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.179465</td>\n",
       "      <td>0.110899</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.015530</td>\n",
       "      <td>0.034285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.152576</td>\n",
       "      <td>0.150813</td>\n",
       "      <td>0.061259</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.034989</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.040717</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.013196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.014527</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.006992</td>\n",
       "      <td>0.139108</td>\n",
       "      <td>0.117732</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.084496</td>\n",
       "      <td>0.069815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29145 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           diag_0    diag_1    diag_2    diag_3    diag_4  \\\n",
       "pat_id adm_index n_pass                                                     \n",
       "21     1         1       0.032539  0.242594  0.169882  0.167440  0.023404   \n",
       "                 2       0.002497  0.162189  0.043052  0.042609  0.000035   \n",
       "                 3       0.123530  0.166680  0.096426  0.130095  0.006716   \n",
       "                 4       0.012353  0.115188  0.079149  0.070948  0.000103   \n",
       "                 5       0.001298  0.394419  0.103910  0.110775  0.000408   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "99756  2         11      0.012420  0.090209  0.175551  0.079750  0.015177   \n",
       "                 12      0.002756  0.218797  0.066115  0.082487  0.000059   \n",
       "                 13      0.003925  0.101160  0.208187  0.169326  0.008033   \n",
       "                 14      0.000478  0.255018  0.172330  0.133123  0.000064   \n",
       "                 15      0.003342  0.152576  0.150813  0.061259  0.000304   \n",
       "\n",
       "                           diag_5    diag_6    diag_7    diag_8    diag_9  \\\n",
       "pat_id adm_index n_pass                                                     \n",
       "21     1         1       0.058049  0.026044  0.001310  0.005399  0.121698   \n",
       "                 2       0.011330  0.009462  0.001221  0.001304  0.013655   \n",
       "                 3       0.045917  0.002916  0.002710  0.001379  0.199120   \n",
       "                 4       0.002479  0.002044  0.002383  0.000764  0.107383   \n",
       "                 5       0.008996  0.004477  0.008242  0.001130  0.050175   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "99756  2         11      0.260487  0.097329  0.076201  0.007032  0.139333   \n",
       "                 12      0.072757  0.016201  0.086022  0.000292  0.141744   \n",
       "                 13      0.525002  0.028517  0.302174  0.001704  0.248651   \n",
       "                 14      0.049835  0.018143  0.006289  0.000451  0.098977   \n",
       "                 15      0.034989  0.020145  0.040717  0.001295  0.013196   \n",
       "\n",
       "                         ...  diag_262  diag_263  diag_264  diag_265  \\\n",
       "pat_id adm_index n_pass  ...                                           \n",
       "21     1         1       ...  0.000615  0.003921  0.000233  0.016892   \n",
       "                 2       ...  0.000092  0.001542  0.000097  0.001383   \n",
       "                 3       ...  0.000375  0.007049  0.000098  0.019225   \n",
       "                 4       ...  0.000399  0.001090  0.000267  0.008366   \n",
       "                 5       ...  0.000198  0.004136  0.000102  0.001630   \n",
       "...                      ...       ...       ...       ...       ...   \n",
       "99756  2         11      ...  0.005610  0.072918  0.005971  0.003473   \n",
       "                 12      ...  0.001387  0.006461  0.001029  0.004221   \n",
       "                 13      ...  0.003009  0.060098  0.001286  0.008310   \n",
       "                 14      ...  0.000631  0.005159  0.000157  0.009730   \n",
       "                 15      ...  0.001288  0.014527  0.003363  0.006992   \n",
       "\n",
       "                         diag_266  diag_267  diag_268  diag_269  diag_270  \\\n",
       "pat_id adm_index n_pass                                                     \n",
       "21     1         1       0.211880  0.195146  0.003629  0.004870  0.005443   \n",
       "                 2       0.091234  0.065028  0.002128  0.001901  0.001478   \n",
       "                 3       0.071668  0.110959  0.004320  0.003060  0.000525   \n",
       "                 4       0.091769  0.080935  0.000838  0.001303  0.002496   \n",
       "                 5       0.165625  0.022450  0.006177  0.001745  0.001523   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "99756  2         11      0.102012  0.181597  0.026447  0.013044  0.097084   \n",
       "                 12      0.093471  0.095394  0.004561  0.011953  0.008212   \n",
       "                 13      0.268445  0.138418  0.012677  0.006711  0.023276   \n",
       "                 14      0.179465  0.110899  0.005338  0.002518  0.015530   \n",
       "                 15      0.139108  0.117732  0.015525  0.009349  0.084496   \n",
       "\n",
       "                         diag_271  \n",
       "pat_id adm_index n_pass            \n",
       "21     1         1       0.079044  \n",
       "                 2       0.030642  \n",
       "                 3       0.037897  \n",
       "                 4       0.026199  \n",
       "                 5       0.024375  \n",
       "...                           ...  \n",
       "99756  2         11      0.038923  \n",
       "                 12      0.036896  \n",
       "                 13      0.134179  \n",
       "                 14      0.034285  \n",
       "                 15      0.069815  \n",
       "\n",
       "[29145 rows x 272 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res,golden = outs2df_mc(model,val_dataloader,dataset,return_golden=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_4</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_267</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_268</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_269</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_270</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_271</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pat_id</th>\n",
       "      <th>adm_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>1</th>\n",
       "      <td>0.042819</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.296443</td>\n",
       "      <td>0.013124</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.142982</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.014196</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112774</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>4.677378e-06</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.041823</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>1</th>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.135196</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.090153</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.040959</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061166</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>6.065529e-07</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.050168</td>\n",
       "      <td>0.001309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <th>1</th>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.153172</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.105047</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085513</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>7.420928e-07</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.019389</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    diag_0              diag_1              diag_2            \\\n",
       "                      mean       var      mean       var      mean       var   \n",
       "pat_id adm_index                                                               \n",
       "21     1          0.042819  0.005386  0.296443  0.013124  0.132763  0.005358   \n",
       "23     1          0.002569  0.000005  0.135196  0.006378  0.090153  0.001808   \n",
       "61     1          0.005366  0.000052  0.153172  0.006460  0.056106  0.000944   \n",
       "\n",
       "                    diag_3              diag_4            ...  diag_267  \\\n",
       "                      mean       var      mean       var  ...      mean   \n",
       "pat_id adm_index                                          ...             \n",
       "21     1          0.142982  0.005878  0.014196  0.000522  ...  0.112774   \n",
       "23     1          0.040959  0.000376  0.004982  0.000039  ...  0.061166   \n",
       "61     1          0.105047  0.002437  0.015053  0.000774  ...  0.085513   \n",
       "\n",
       "                            diag_268            diag_269                \\\n",
       "                       var      mean       var      mean           var   \n",
       "pat_id adm_index                                                         \n",
       "21     1          0.003515  0.004854  0.000033  0.002460  4.677378e-06   \n",
       "23     1          0.000525  0.006482  0.000016  0.000678  6.065529e-07   \n",
       "61     1          0.001540  0.006851  0.000043  0.000843  7.420928e-07   \n",
       "\n",
       "                  diag_270            diag_271            \n",
       "                      mean       var      mean       var  \n",
       "pat_id adm_index                                          \n",
       "21     1          0.003000  0.000010  0.041823  0.001140  \n",
       "23     1          0.014133  0.000053  0.050168  0.001309  \n",
       "61     1          0.009249  0.000048  0.019389  0.000075  \n",
       "\n",
       "[3 rows x 544 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_res = res.groupby(['pat_id','adm_index']).agg(['mean','var'])\n",
    "stats_res.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diag_0      0.042819\n",
       "diag_1      0.296443\n",
       "diag_2      0.132763\n",
       "diag_3      0.142982\n",
       "diag_4      0.014196\n",
       "              ...   \n",
       "diag_267    0.112774\n",
       "diag_268    0.004854\n",
       "diag_269    0.002460\n",
       "diag_270    0.003000\n",
       "diag_271    0.041823\n",
       "Name: (21, 1), Length: 272, dtype: float32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.IndexSlice\n",
    "stats_res.iloc[0].loc[idx[:,'mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30\n",
    "topk_outputs = stats_res.apply(lambda row: row.loc[idx[:,'mean']].nlargest(k),axis=1)\n",
    "\n",
    "# fix missing columns from previous operation\n",
    "original_class_columns = stats_res.columns.get_level_values(0).unique()\n",
    "missing_cols = [col for col in original_class_columns if col not in topk_outputs.columns]\n",
    "topk_outputs_all_cols = pd.concat([topk_outputs,pd.DataFrame(columns=missing_cols)])\n",
    "topk_outputs_all_cols = topk_outputs_all_cols[original_class_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>diag_0</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>diag_4</th>\n",
       "      <th>diag_5</th>\n",
       "      <th>diag_6</th>\n",
       "      <th>diag_7</th>\n",
       "      <th>diag_8</th>\n",
       "      <th>diag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_262</th>\n",
       "      <th>diag_263</th>\n",
       "      <th>diag_264</th>\n",
       "      <th>diag_265</th>\n",
       "      <th>diag_266</th>\n",
       "      <th>diag_267</th>\n",
       "      <th>diag_268</th>\n",
       "      <th>diag_269</th>\n",
       "      <th>diag_270</th>\n",
       "      <th>diag_271</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pat_id</th>\n",
       "      <th>adm_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.296443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131463</td>\n",
       "      <td>0.085513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  diag_0    diag_1  diag_2    diag_3  diag_4  diag_5  diag_6  \\\n",
       "pat_id adm_index                                                               \n",
       "21     1             NaN  0.296443     NaN       NaN     NaN     NaN     NaN   \n",
       "23     1             NaN  0.135196     NaN       NaN     NaN     NaN     NaN   \n",
       "61     1             NaN  0.153172     NaN  0.105047     NaN     NaN     NaN   \n",
       "\n",
       "                  diag_7 diag_8  diag_9  ...  diag_262  diag_263  diag_264  \\\n",
       "pat_id adm_index                         ...                                 \n",
       "21     1             NaN    NaN     NaN  ...       NaN       NaN       NaN   \n",
       "23     1             NaN    NaN     NaN  ...       NaN       NaN       NaN   \n",
       "61     1             NaN    NaN     NaN  ...       NaN       NaN       NaN   \n",
       "\n",
       "                  diag_265  diag_266  diag_267  diag_268  diag_269  diag_270  \\\n",
       "pat_id adm_index                                                               \n",
       "21     1               NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "23     1               NaN  0.195936       NaN       NaN       NaN       NaN   \n",
       "61     1               NaN  0.131463  0.085513       NaN       NaN       NaN   \n",
       "\n",
       "                 diag_271  \n",
       "pat_id adm_index           \n",
       "21     1              NaN  \n",
       "23     1              NaN  \n",
       "61     1              NaN  \n",
       "\n",
       "[3 rows x 272 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_outputs_all_cols.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>diag_0</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>diag_4</th>\n",
       "      <th>diag_5</th>\n",
       "      <th>diag_6</th>\n",
       "      <th>diag_7</th>\n",
       "      <th>diag_8</th>\n",
       "      <th>diag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_262</th>\n",
       "      <th>diag_263</th>\n",
       "      <th>diag_264</th>\n",
       "      <th>diag_265</th>\n",
       "      <th>diag_266</th>\n",
       "      <th>diag_267</th>\n",
       "      <th>diag_268</th>\n",
       "      <th>diag_269</th>\n",
       "      <th>diag_270</th>\n",
       "      <th>diag_271</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pat_id</th>\n",
       "      <th>adm_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  diag_0  diag_1  diag_2  diag_3  diag_4  diag_5  diag_6  \\\n",
       "pat_id adm_index                                                           \n",
       "21     1               0       1       0       0       0       0       0   \n",
       "23     1               0       1       0       0       0       0       0   \n",
       "61     1               0       1       0       1       0       0       0   \n",
       "\n",
       "                  diag_7  diag_8  diag_9  ...  diag_262  diag_263  diag_264  \\\n",
       "pat_id adm_index                          ...                                 \n",
       "21     1               0       0       0  ...         0         0         0   \n",
       "23     1               0       0       0  ...         0         0         0   \n",
       "61     1               0       0       0  ...         0         0         0   \n",
       "\n",
       "                  diag_265  diag_266  diag_267  diag_268  diag_269  diag_270  \\\n",
       "pat_id adm_index                                                               \n",
       "21     1                 0         0         0         0         0         0   \n",
       "23     1                 0         1         0         0         0         0   \n",
       "61     1                 0         1         1         0         0         0   \n",
       "\n",
       "                  diag_271  \n",
       "pat_id adm_index            \n",
       "21     1                 0  \n",
       "23     1                 0  \n",
       "61     1                 0  \n",
       "\n",
       "[3 rows x 272 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_predictions = np.where(topk_outputs_all_cols.isna(),0,1)\n",
    "topk_predictions = pd.DataFrame(data=topk_predictions,columns=original_class_columns,index=stats_res.index)\n",
    "topk_predictions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = (topk_predictions == 1) & (golden == 1)\n",
    "FP = (topk_predictions == 1) & (golden == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>diag_0</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>diag_4</th>\n",
       "      <th>diag_5</th>\n",
       "      <th>diag_6</th>\n",
       "      <th>diag_7</th>\n",
       "      <th>diag_8</th>\n",
       "      <th>diag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_262</th>\n",
       "      <th>diag_263</th>\n",
       "      <th>diag_264</th>\n",
       "      <th>diag_265</th>\n",
       "      <th>diag_266</th>\n",
       "      <th>diag_267</th>\n",
       "      <th>diag_268</th>\n",
       "      <th>diag_269</th>\n",
       "      <th>diag_270</th>\n",
       "      <th>diag_271</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pat_id</th>\n",
       "      <th>adm_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>1</th>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.013124</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>2.740558e-06</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>...</td>\n",
       "      <td>6.732586e-08</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.453951e-08</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>4.677378e-06</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>1</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>6.956041e-06</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>...</td>\n",
       "      <td>2.044335e-07</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>6.073514e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.010382</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>6.065529e-07</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.001309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <th>1</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>5.114800e-07</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>...</td>\n",
       "      <td>1.855225e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.349718e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>7.420928e-07</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    diag_0    diag_1    diag_2    diag_3    diag_4    diag_5  \\\n",
       "pat_id adm_index                                                               \n",
       "21     1          0.005386  0.013124  0.005358  0.005878  0.000522  0.000694   \n",
       "23     1          0.000005  0.006378  0.001808  0.000376  0.000039  0.000047   \n",
       "61     1          0.000052  0.006460  0.000944  0.002437  0.000774  0.000486   \n",
       "\n",
       "                    diag_6    diag_7        diag_8    diag_9  ...  \\\n",
       "pat_id adm_index                                              ...   \n",
       "21     1          0.000123  0.000072  2.740558e-06  0.001616  ...   \n",
       "23     1          0.000324  0.000018  6.956041e-06  0.000981  ...   \n",
       "61     1          0.004798  0.000109  5.114800e-07  0.000838  ...   \n",
       "\n",
       "                      diag_262  diag_263      diag_264  diag_265  diag_266  \\\n",
       "pat_id adm_index                                                             \n",
       "21     1          6.732586e-08  0.000024  1.453951e-08  0.000098  0.004375   \n",
       "23     1          2.044335e-07  0.000008  6.073514e-07  0.000003  0.010382   \n",
       "61     1          1.855225e-07  0.000003  4.349718e-08  0.000005  0.003392   \n",
       "\n",
       "                  diag_267  diag_268      diag_269  diag_270  diag_271  \n",
       "pat_id adm_index                                                        \n",
       "21     1          0.003515  0.000033  4.677378e-06  0.000010  0.001140  \n",
       "23     1          0.000525  0.000016  6.065529e-07  0.000053  0.001309  \n",
       "61     1          0.001540  0.000043  7.420928e-07  0.000048  0.000075  \n",
       "\n",
       "[3 rows x 272 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variances = stats_res.loc[idx[:,:],idx[:,'var']]\n",
    "variances.columns = variances.columns.get_level_values(0)\n",
    "variances.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>diag_0</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>diag_4</th>\n",
       "      <th>diag_5</th>\n",
       "      <th>diag_6</th>\n",
       "      <th>diag_7</th>\n",
       "      <th>diag_8</th>\n",
       "      <th>diag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_262</th>\n",
       "      <th>diag_263</th>\n",
       "      <th>diag_264</th>\n",
       "      <th>diag_265</th>\n",
       "      <th>diag_266</th>\n",
       "      <th>diag_267</th>\n",
       "      <th>diag_268</th>\n",
       "      <th>diag_269</th>\n",
       "      <th>diag_270</th>\n",
       "      <th>diag_271</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pat_id</th>\n",
       "      <th>adm_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>1</th>\n",
       "      <td>0.042819</td>\n",
       "      <td>0.296443</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.142982</td>\n",
       "      <td>0.014196</td>\n",
       "      <td>0.030856</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.108961</td>\n",
       "      <td>0.112774</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.041823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>1</th>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.135196</td>\n",
       "      <td>0.090153</td>\n",
       "      <td>0.040959</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.029185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.195936</td>\n",
       "      <td>0.061166</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.050168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <th>1</th>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.153172</td>\n",
       "      <td>0.056106</td>\n",
       "      <td>0.105047</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.036997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.131463</td>\n",
       "      <td>0.085513</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0.019389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    diag_0    diag_1    diag_2    diag_3    diag_4    diag_5  \\\n",
       "pat_id adm_index                                                               \n",
       "21     1          0.042819  0.296443  0.132763  0.142982  0.014196  0.030856   \n",
       "23     1          0.002569  0.135196  0.090153  0.040959  0.004982  0.005615   \n",
       "61     1          0.005366  0.153172  0.056106  0.105047  0.015053  0.018926   \n",
       "\n",
       "                    diag_6    diag_7    diag_8    diag_9  ...  diag_262  \\\n",
       "pat_id adm_index                                          ...             \n",
       "21     1          0.009698  0.005205  0.001681  0.051541  ...  0.000346   \n",
       "23     1          0.026959  0.003318  0.002684  0.029185  ...  0.000491   \n",
       "61     1          0.061867  0.012876  0.000856  0.036997  ...  0.000474   \n",
       "\n",
       "                  diag_263  diag_264  diag_265  diag_266  diag_267  diag_268  \\\n",
       "pat_id adm_index                                                               \n",
       "21     1          0.006615  0.000143  0.010109  0.108961  0.112774  0.004854   \n",
       "23     1          0.002535  0.000753  0.001931  0.195936  0.061166  0.006482   \n",
       "61     1          0.002399  0.000243  0.001746  0.131463  0.085513  0.006851   \n",
       "\n",
       "                  diag_269  diag_270  diag_271  \n",
       "pat_id adm_index                                \n",
       "21     1          0.002460  0.003000  0.041823  \n",
       "23     1          0.000678  0.014133  0.050168  \n",
       "61     1          0.000843  0.009249  0.019389  \n",
       "\n",
       "[3 rows x 272 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = stats_res.loc[idx[:,:],idx[:,'mean']]\n",
    "means.columns = means.columns.get_level_values(0)\n",
    "means.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_variances = variances.where(TP,np.nan)\n",
    "fp_variances = variances.where(FP,np.nan)\n",
    "\n",
    "tp_means = means.where(TP,np.nan)\n",
    "fp_means = means.where(FP,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#parameter\n",
    "diag = 137\n",
    "\n",
    "\n",
    "diag_col = f'diag_{diag}'\n",
    "plt.subplot(1,2,1)\n",
    "tp_means[diag_col].plot.kde(label='True positives');\n",
    "fp_means[diag_col].plot.kde(label='False positives');\n",
    "plt.title(f'distribution in mean forward_pass of diag {diag}');\n",
    "plt.legend();\n",
    "#plt.show();\n",
    "plt.subplots_adjust(right=2) \n",
    "plt.subplot(1,2,2)\n",
    "tp_variances[diag_col].plot.kde(label='True positives');\n",
    "fp_variances[diag_col].plot.kde(label='False positives');\n",
    "plt.title(f'distribution in variance of the forward_pass of diag {diag}');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model whether a prediction will be FP or TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumb classifier\n",
    "\n",
    "since some diagnostics won't have enough data to train a model on, we will use 'dumb' classifiers to keep the pipeline consistent. These classifiers will always predict the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('dumbclassifier', DumbClassifier())])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class DumbClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        #X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        #self.classes_ = unique_labels(y)\n",
    "        #self.X_ = X\n",
    "        #self.y_ = y\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "         # Check if fit has been called\n",
    "        #check_is_fitted(self)\n",
    "        \n",
    "        # Input validation\n",
    "        #X = check_array(X)\n",
    "        y = np.zeros(shape=(X.shape[0],),dtype=int)\n",
    "        return y\n",
    "\n",
    "# test this out\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X = np.ones(shape=(5,5))\n",
    "y = np.random.randint(0,2,size=(5,))\n",
    "\n",
    "pipe = make_pipeline(DumbClassifier())\n",
    "\n",
    "pipe.fit(X,y)\n",
    "pipe.predict(X) # Expecting all ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dataset\n",
    "\n",
    "we shall build the dataset using the validation set (from the original train-val-test split).\n",
    "\n",
    "We need:\n",
    "1. obtain predictions on the validation set\n",
    "2. gather all TP and FP examples\n",
    "3. construct N tabular datasets (one for each diagnostic)\n",
    "4. split each into train-test\n",
    "5. train and test classifier\n",
    "    1. metric should be precision, recall and f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs, golden = outs2df_mc(model,val_dataloader,dataset,return_golden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>diag_0</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>diag_4</th>\n",
       "      <th>diag_5</th>\n",
       "      <th>diag_6</th>\n",
       "      <th>diag_7</th>\n",
       "      <th>diag_8</th>\n",
       "      <th>diag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>diag_262</th>\n",
       "      <th>diag_263</th>\n",
       "      <th>diag_264</th>\n",
       "      <th>diag_265</th>\n",
       "      <th>diag_266</th>\n",
       "      <th>diag_267</th>\n",
       "      <th>diag_268</th>\n",
       "      <th>diag_269</th>\n",
       "      <th>diag_270</th>\n",
       "      <th>diag_271</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pat_id</th>\n",
       "      <th>adm_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>1</th>\n",
       "      <td>0.041914</td>\n",
       "      <td>0.31054</td>\n",
       "      <td>0.161384</td>\n",
       "      <td>0.175384</td>\n",
       "      <td>0.043563</td>\n",
       "      <td>0.091752</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>0.00364</td>\n",
       "      <td>0.058517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.013974</td>\n",
       "      <td>0.121939</td>\n",
       "      <td>0.132394</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.04441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    diag_0   diag_1    diag_2    diag_3    diag_4    diag_5  \\\n",
       "pat_id adm_index                                                              \n",
       "21     1          0.041914  0.31054  0.161384  0.175384  0.043563  0.091752   \n",
       "\n",
       "                    diag_6    diag_7   diag_8    diag_9  ...  diag_262  \\\n",
       "pat_id adm_index                                         ...             \n",
       "21     1          0.013618  0.008234  0.00364  0.058517  ...  0.000841   \n",
       "\n",
       "                  diag_263  diag_264  diag_265  diag_266  diag_267  diag_268  \\\n",
       "pat_id adm_index                                                               \n",
       "21     1          0.013482  0.000462  0.013974  0.121939  0.132394  0.007967   \n",
       "\n",
       "                  diag_269  diag_270  diag_271  \n",
       "pat_id adm_index                                \n",
       "21     1          0.008295  0.004178   0.04441  \n",
       "\n",
       "[1 rows x 272 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_outs = outs.groupby(['pat_id','adm_index']).agg(['mean','var'])\n",
    "\n",
    "k = 30\n",
    "topk_outputs = stats_outs.apply(lambda row: row.loc[idx[:,'mean']].nlargest(k),axis=1)\n",
    "\n",
    "# fix missing columns from previous operation\n",
    "original_class_columns = stats_outs.columns.get_level_values(0).unique()\n",
    "missing_cols = [col for col in original_class_columns if col not in topk_outputs.columns]\n",
    "topk_outputs_all_cols = pd.concat([topk_outputs,pd.DataFrame(columns=missing_cols)])\n",
    "topk_outputs_all_cols = topk_outputs_all_cols[original_class_columns]\n",
    "\n",
    "topk_predictions = np.where(topk_outputs_all_cols.isna(),0,1)\n",
    "topk_predictions = pd.DataFrame(data=topk_predictions,columns=original_class_columns,index=stats_outs.index)\n",
    "#topk_predictions.head(1)\n",
    "\n",
    "TP = (topk_predictions == 1) & (golden == 1)\n",
    "FP = (topk_predictions == 1) & (golden == 0)\n",
    "\n",
    "variances = stats_outs.loc[idx[:,:],idx[:,'var']]\n",
    "variances.columns = variances.columns.get_level_values(0)\n",
    "#variances.head(1)\n",
    "\n",
    "means = stats_outs.loc[idx[:,:],idx[:,'mean']]\n",
    "means.columns = means.columns.get_level_values(0)\n",
    "means.head(1)\n",
    "\n",
    "tp_variances = variances.where(TP,np.nan)\n",
    "fp_variances = variances.where(FP,np.nan)\n",
    "\n",
    "tp_means = means.where(TP,np.nan)\n",
    "fp_means = means.where(FP,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need two conditions to decide wether to use the dumb classifier or not\n",
    "# 1) threhsold on the number of examples\n",
    "# 2) and there must be examples of both classes\n",
    "\n",
    "df_metrics = pd.DataFrame(columns=['diag','precision','recall','f1','clf','type'])\n",
    "\n",
    "clf_party = {}\n",
    "threshold = 20\n",
    "for diag in outs.columns:\n",
    "    \n",
    "    n_TP = (TP[diag] == True).sum()\n",
    "    n_FP = (FP[diag] == True).sum()\n",
    "    \n",
    "    total_n = n_TP + n_FP\n",
    "    \n",
    "    if total_n < threshold or n_TP < 5 or n_FP < 5:\n",
    "        #use dumb classifier\n",
    "        clf = DumbClassifier()\n",
    "        df_metrics = df_metrics.append({'diag':diag,'precision':np.nan,'recall':np.nan,'f1':np.nan,'clf':clf,'type':'dumb'},ignore_index=True)\n",
    "    else:\n",
    "        #use logistic regression\n",
    "        \n",
    "        ## create dataset\n",
    "        mean_tp = means[diag][TP[diag]].to_frame('mean')\n",
    "        mean_fp = means[diag][FP[diag]].to_frame('mean')\n",
    "        \n",
    "        var_tp = variances[diag][TP[diag]].to_frame('var')\n",
    "        var_fp = variances[diag][FP[diag]].to_frame('var')\n",
    "        \n",
    "        df_tp = pd.concat([mean_tp,var_tp],axis=1).assign(label=0).reset_index(drop=True)\n",
    "        df_fp = pd.concat([mean_fp,var_fp],axis=1).assign(label=1).reset_index(drop=True)\n",
    "        \n",
    "        df = pd.concat([df_tp,df_fp],ignore_index=True).sample(frac=1.0)\n",
    "        \n",
    "        ## split into train-test\n",
    "        \n",
    "        X_train,X_test,y_train,y_test = train_test_split(df[['mean','var']],df['label'],stratify=df['label'])\n",
    "        \n",
    "        ## train\n",
    "        clf = LogisticRegression(class_weight=\"balanced\");\n",
    "        clf.fit(X_train,y_train);\n",
    "        \n",
    "        ## evaluate\n",
    "        preds = clf.predict(X_test);\n",
    "        \n",
    "        precision = precision_score(y_test,preds)\n",
    "        recall = recall_score(y_test,preds)\n",
    "        f1 = f1_score(y_test,preds)\n",
    "        \n",
    "        df_metrics = df_metrics.append({'diag':diag,'precision':precision,'recall':recall,'f1':f1,'clf':clf,'type':'model'},ignore_index=True)\n",
    "    \n",
    "    clf_party[diag] = clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    132.000000\n",
       "mean       0.787429\n",
       "std        0.123074\n",
       "min        0.166667\n",
       "25%        0.727273\n",
       "50%        0.799202\n",
       "75%        0.857143\n",
       "max        1.000000\n",
       "Name: f1, dtype: float64"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics.f1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>clf</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diag_0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DumbClassifier()</td>\n",
       "      <td>dumb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_1</th>\n",
       "      <td>0.862944</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.770975</td>\n",
       "      <td>LogisticRegression(class_weight='balanced')</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        precision    recall        f1  \\\n",
       "diag                                    \n",
       "diag_0        NaN       NaN       NaN   \n",
       "diag_1   0.862944  0.696721  0.770975   \n",
       "\n",
       "                                                clf   type  \n",
       "diag                                                        \n",
       "diag_0                             DumbClassifier()   dumb  \n",
       "diag_1  LogisticRegression(class_weight='balanced')  model  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics = df_metrics.set_index('diag')\n",
    "df_metrics.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers are trained. Now we need to apply them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs, golden = outs2df_mc(model,test_dataloader,dataset,return_golden=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_4</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_267</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_268</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_269</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_270</th>\n",
       "      <th colspan=\"2\" halign=\"left\">diag_271</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pat_id</th>\n",
       "      <th>adm_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <th>1</th>\n",
       "      <td>0.007347</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.095935</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.054314</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.091747</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077534</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.005107</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>4.116630e-07</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.028682</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <th>1</th>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.466393</td>\n",
       "      <td>0.018681</td>\n",
       "      <td>0.164556</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>0.097382</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112730</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>3.693598e-07</td>\n",
       "      <td>0.012641</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.039479</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <th>1</th>\n",
       "      <td>0.011444</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.086913</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.057785</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.049028</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.005940</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081583</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>7.213809e-06</td>\n",
       "      <td>0.007857</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.019741</td>\n",
       "      <td>0.000171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 544 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    diag_0              diag_1              diag_2            \\\n",
       "                      mean       var      mean       var      mean       var   \n",
       "pat_id adm_index                                                               \n",
       "111    1          0.007347  0.000059  0.095935  0.001939  0.054314  0.000623   \n",
       "145    1          0.002079  0.000003  0.466393  0.018681  0.164556  0.004913   \n",
       "199    1          0.011444  0.000142  0.086913  0.002136  0.057785  0.000624   \n",
       "\n",
       "                    diag_3              diag_4            ...  diag_267  \\\n",
       "                      mean       var      mean       var  ...      mean   \n",
       "pat_id adm_index                                          ...             \n",
       "111    1          0.091747  0.003034  0.002875  0.000017  ...  0.077534   \n",
       "145    1          0.097382  0.001239  0.001913  0.000012  ...  0.112730   \n",
       "199    1          0.049028  0.000401  0.005940  0.000190  ...  0.081583   \n",
       "\n",
       "                            diag_268            diag_269                \\\n",
       "                       var      mean       var      mean           var   \n",
       "pat_id adm_index                                                         \n",
       "111    1          0.002375  0.005107  0.000012  0.000833  4.116630e-07   \n",
       "145    1          0.002911  0.010506  0.000069  0.001139  3.693598e-07   \n",
       "199    1          0.000585  0.005190  0.000016  0.003351  7.213809e-06   \n",
       "\n",
       "                  diag_270            diag_271            \n",
       "                      mean       var      mean       var  \n",
       "pat_id adm_index                                          \n",
       "111    1          0.010200  0.000046  0.028682  0.000205  \n",
       "145    1          0.012641  0.000034  0.039479  0.000316  \n",
       "199    1          0.007857  0.000015  0.019741  0.000171  \n",
       "\n",
       "[3 rows x 544 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_outs = outs.groupby(['pat_id','adm_index']).agg(['mean','var'])\n",
    "stats_outs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30\n",
    "topk_outputs = stats_outs.apply(lambda row: row.loc[idx[:,'mean']].nlargest(k),axis=1)\n",
    "\n",
    "# fix missing columns from previous operation\n",
    "original_class_columns = stats_outs.columns.get_level_values(0).unique()\n",
    "missing_cols = [col for col in original_class_columns if col not in topk_outputs.columns]\n",
    "topk_outputs_all_cols = pd.concat([topk_outputs,pd.DataFrame(columns=missing_cols)])\n",
    "topk_outputs_all_cols = topk_outputs_all_cols[original_class_columns]\n",
    "\n",
    "topk_predictions = np.where(topk_outputs_all_cols.isna(),0,1)\n",
    "topk_predictions = pd.DataFrame(data=topk_predictions,columns=original_class_columns,index=stats_outs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstain(row,df_metrics,stats_outs):\n",
    "    new_row = row.copy()\n",
    "    admission_forward_stats = stats_outs.loc[row.name,:]\n",
    "    for index,elem in row.iteritems():\n",
    "        if elem == 1:\n",
    "            datapoint = admission_forward_stats[index].to_numpy()\n",
    "            clf = df_metrics.loc[index,'clf']\n",
    "            pred = clf.predict(datapoint.reshape((-1,2)))\n",
    "            \n",
    "            if pred == 1: #abstain\n",
    "                new_row[index] = 0\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_predictions_abstained = topk_predictions.apply(lambda row: abstain(row,df_metrics,stats_outs),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_utils import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_normal = compute_metrics(topk_outputs_all_cols.fillna(0),topk_predictions,golden,['precision@30','recall@30','f1@30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_outputs_all_cols_after_abstention = topk_outputs_all_cols.fillna(0).mask(top_k_predictions_abstained == 0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_w_abstention = compute_metrics(topk_outputs_all_cols_after_abstention,top_k_predictions_abstained,golden,['precision@30','recall@30','f1@30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_normal.name = 'initial top 30'\n",
    "metrics_w_abstention.name = 'top 30 + abstention through MC dropout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial top 30</th>\n",
       "      <th>top 30 + abstention through MC dropout</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision@30_adm</th>\n",
       "      <td>0.275293</td>\n",
       "      <td>0.472482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall@30_adm</th>\n",
       "      <td>0.700669</td>\n",
       "      <td>0.449377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1@30_adm</th>\n",
       "      <td>0.378810</td>\n",
       "      <td>0.432183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  initial top 30  top 30 + abstention through MC dropout\n",
       "metrics                                                                 \n",
       "precision@30_adm        0.275293                                0.472482\n",
       "recall@30_adm           0.700669                                0.449377\n",
       "f1@30_adm               0.378810                                0.432183"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([metrics_normal,metrics_w_abstention],axis=1).iloc[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13bc30610>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/aklEQVR4nO3deXiU1dn48e89k8lCdkhYAoGw7yFAQARFEFFAxKUqWOtS21prrbW2Xmr7tq9V+6ttbfu+be1LrbVqSxW1VVHADVlUXAjIjuwBQggJhGxA1jm/P55JjGGSTDLPLEnuz3XN9cw8y5l7mIQ75zxnEWMMSimlVFOOUAeglFIqPGmCUEop5ZUmCKWUUl5pglBKKeWVJgillFJeRYQ6ADulpKSYjIyMUIehlFIdxsaNG08YY1K9HetUCSIjI4OcnJxQh6GUUh2GiBxq7pg2MSmllPJKE4RSSimvNEEopZTyqlPdg1BKBVdNTQ15eXlUVlaGOhTViujoaPr164fL5fL5Gk0QSql2y8vLIz4+noyMDEQk1OGoZhhjOHnyJHl5eQwcONDn67SJSSnVbpWVlfTo0UOTQ5gTEXr06NHmmp4mCKWUXzQ5dAzt+Z60iUkFj7sOdr4KpUdh9FWQ1D/UESmlWqA1CBUcbje8/HV4+TZ456fw5/PhyKehjkp1cCdPniQrK4usrCx69+5N3759G15XV1eHOrwGOTk53H333QCsWbOG9evXNxxbvHgxzz33XKhCa5HWIFRwbF4CO1+Di38KY66Bf1wDL3wV7vwEYnuEOjrVQfXo0YPNmzcD8NBDDxEXF8ePfvSjhuO1tbVERIT+v7ns7Gyys7MBK0HExcUxdepUAO64445QhtYirUGowKuthlUPQ/+pcOEPofsgWPhPOFMM7z0S6uhUJ3Prrbdy7733MnPmTO6//34eeughHn/88YbjY8aMITc3F4B//vOfTJ48maysLL797W9TV1d3TnkZGRncf//9TJ48mcmTJ7Nv3z4ADh06xKxZs8jMzGTWrFkcPnwYgJdeeokxY8Ywbtw4pk+fDlhJYf78+eTm5rJ48WJ+//vfk5WVxfvvv98Q365du5g8eXLD++bm5pKZmQnAxo0bueiii5g4cSKXXXYZx44dA+APf/gDo0aNIjMzk0WLFtn+bxn61Ko6v52vwulCuHox1N8o6z0GJn0TNjwFF96r9yM6gZ+/voOd+WW2ljkqLYH/vmJ0m6/bs2cP7777Lk6nk4ceesjrObt27WLp0qV8+OGHuFwu7rzzTpYsWcLNN998zrkJCQl8+umnPPfcc9xzzz288cYb3HXXXdx8883ccsstPP3009x99928+uqrPPzww7z11lv07duXkpKSL5WTkZHBHXfc8aWazqpVqwAYOXIk1dXVHDhwgEGDBrF06VKuv/56ampq+N73vsdrr71GamoqS5cu5Sc/+QlPP/00jz32GAcPHiQqKuqc97KD1iBU4H32D6vWMGjml/dPu9tKGB/9OTRxqU7ruuuuw+l0tnjOqlWr2LhxI5MmTSIrK4tVq1Zx4MABr+fecMMNDduPPvoIgI8++oivfvWrANx000188MEHAEybNo1bb72Vv/71r15rJC25/vrrefHFFwFYunQpCxcuZPfu3Wzfvp3Zs2eTlZXFo48+Sl5eHgCZmZnceOON/POf/wxIU5rWIFRgnSmG3A/hgh+Ao8nfI4n9YMy1sOk5uPgnEBUfmhiVLdrzl36gxMbGNjyPiIjA7XY3vK4fC2CM4ZZbbuGXv/xlq+U17iLaXHfR+v2LFy/mk08+Yfny5WRlZTXcI/HFwoULue6667jmmmsQEYYOHcq2bdsYPXp0Q2JqbPny5axbt45ly5bxyCOPsGPHDlsThdYgVGDtXgmmDkZc7v149m1Qcxp2LgtuXKrLyMjIYNOmTQBs2rSJgwcPAjBr1ixefvllCgsLASguLubQIe8zXy9durRhe/755wMwdepUXnjhBQCWLFnCBRdcAMD+/fs577zzePjhh0lJSeHIkSNfKis+Pp7y8nKv7zN48GCcTiePPPIICxcuBGD48OEUFRU1JIiamhp27NiB2+3myJEjzJw5k1//+teUlJRQUVHRvn+kZmgNQgXWgTUQ2xPSxns/nj7Zan7a8jyMvzGooamu4Stf+QrPPfccWVlZTJo0iWHDhgEwatQoHn30US699FLcbjcul4snnniCAQMGnFNGVVUV5513Hm63m+effx6wbhDfdttt/OY3vyE1NZW///3vANx3333s3bsXYwyzZs1i3LhxrF27tqGsK664gmuvvZbXXnuNP/7xj+e818KFC7nvvvsaEllkZCQvv/wyd999N6WlpdTW1nLPPfcwbNgwvva1r1FaWooxhh/84AckJSXZ+m8nxhhbCwyl7OxsowsGhRFj4PejrSRw3TPNn7f217D6F3DPNr1Z3cHs2rWLkSNHhjqMgKpfiCwlJSXUofjN2/clIhuNMdneztcmJhU4JYeh7CgMmNbyeZlWVZrt/w58TEopn2mCUIFzyDNadMDUls9LHmA1Qe16I/AxKdVGubm5naL20B4BSxAi8rSIFIrI9kb7lorIZs8jV0Q2N3Ntrohs85ynbUYd1eGPIDoRUn1oghgxH47mQFl+4ONSSvkkkDWIZ4A5jXcYYxYaY7KMMVnAv4H/tHD9TM+5XtvGVAdwbItVM2javdWbkQus7efLAxuTUspnAUsQxph1QLG3Y2J1GL4eeD5Q769CrK4GCndC70zfzk8dBinDYJd2d1UqXITqHsSFwHFjzN5mjhvgbRHZKCK3t1SQiNwuIjkiklNUVGR7oKqdinZDXTX0Gef7NSPmW4Pqznj9u0IpFWShShA30HLtYZoxZgIwF/iuiExv7kRjzJPGmGxjTHZqaqrdcar2KthmbXuP9f2aEfOtQXV73wlMTKpTcjqdDVN8Z2VlNUzE501cXFzwAmtBfn4+1157LQCbN29mxYoVDceWLVvGY489FqrQviToA+VEJAK4BpjY3DnGmHzPtlBEXgEmA+uCE6GyRcFWcHWDHkN8vyZtPMT1gt0rYNzCwMWmOpWYmJg2TWcRDtLS0nj55ZcBK0Hk5OQwb948ABYsWMCCBQtCGV6DUNQgLgE+N8bkeTsoIrEiEl//HLgU2O7tXBXGCrZBz1HgaHnCtC9xOGDYHNi3CmqrAheb6tQqKiqYNWsWEyZMYOzYsbz22mvnnHPs2DGmT59OVlYWY8aM4f333wfg7bff5vzzz2fChAlcd911XqeumDFjBvfccw9Tp05lzJgxfPqptfBVcXExV111FZmZmUyZMoWtW7cCsHbt2obazfjx4ykvLyc3N5cxY8ZQXV3Nz372M5YuXUpWVhZLly7lmWee4a677qK0tJSMjIyGeaTOnDlDeno6NTU17N+/nzlz5jBx4kQuvPBCPv/8c8D7VOP+CFgNQkSeB2YAKSKSB/y3MeZvwCKaNC+JSBrwlDFmHtALeMUz8VUE8C9jzJuBilMFyIm9MGRW268bPg82PQu5H7TvehU6Kx/4omnRLr3HwtyWm1vOnj1LVlYWAAMHDuSll17ilVdeISEhgRMnTjBlyhQWLFjwpUn2/vWvf3HZZZfxk5/8hLq6Os6cOcOJEyd49NFHeffdd4mNjeVXv/oVv/vd7/jZz352znuePn2a9evXs27dOm677Ta2b9/Of//3fzN+/HheffVV3nvvPW6++WY2b97M448/zhNPPMG0adOoqKggOjq6oZzIyEgefvhhcnJy+NOf/gTAM888A0BiYmLDNB0zZ87k9ddf57LLLsPlcnH77bezePFihg4dyieffMKdd97Je++91+JU4+0RsARhjLmhmf23etmXD8zzPD8AtOHOpgo7lWVQUdC25qV6gy6CiBhrkj9NEMoHTZuYampq+PGPf8y6detwOBwcPXqU48eP07t374ZzJk2axG233UZNTQ1XXXUVWVlZrF27lp07dzJtmjXyv7q6umFivqbqp/+ePn06ZWVllJSU8MEHH/Dvf1uzAVx88cWcPHmS0tJSpk2bxr333suNN97INddcQ79+/Xz+bAsXLmTp0qXMnDmTF154gTvvvJOKigrWr1/Pdddd13BeVZVV466favz666/nmmuu8fl9mqOT9Sn7nbRW3CJlWNuvdcXA4IutBDHvN18sMKTCXyt/6QfLkiVLKCoqYuPGjbhcLjIyMhqm+K43ffp01q1bx/Lly7npppu47777SE5OZvbs2Q2T8bWk6ZTfIoK3ee1EhAceeIDLL7+cFStWMGXKFN59990v1SJasmDBAh588EGKi4vZuHEjF198MadPnyYpKcnrfRdvU4336NH+JX11qg1lvxOe3sspQ9t3/fC5UJZnf3OF6hJKS0vp2bMnLpeL1atXe53C+9ChQ/Ts2ZNvfetbfOMb32DTpk1MmTKFDz/8sGFJ0TNnzrBnzx6v71E//fcHH3xAYmIiiYmJTJ8+nSVLlgDWEqMpKSkkJCSwf/9+xo4dy/333092dnbD/YJ6LU3/HRcXx+TJk/n+97/P/PnzcTqdJCQkNDSlgbWuxZYtW4DWpxpvK61BKPud3AvihOSB7bt+2GWAWLWIPj4OtFPK48Ybb+SKK64gOzubrKwsRowYcc45a9as4Te/+Q0ul4u4uDiee+45UlNTeeaZZ7jhhhsammweffTRhunBG0tOTmbq1KmUlZXx9NNPA/DQQw/x9a9/nczMTLp168azzz4LwP/8z/+wevVqnE4no0aNYu7cuQ1rSgPMnDmTxx57jKysLB588MFz3qt+EaE1a9Y07FuyZAnf+c53ePTRR6mpqWHRokWMGzfO61Tj/tDpvpX9XrzF+uv/7k3tL+Op2dZAu2+vbf1cFTJdYbrvpmbMmMHjjz9OdnbHmwVIp/tWoXdib/ubl+oNnwvHNkPpUVtCUkq1nSYIZS93HRTvb18PpsaGW4OG2KM9nFV4WbNmTYesPbSHJghlr7KjUFvpfw0idbh1D2P3SnviUgHTmZqpO7P2fE+aIJS9Tnl6jCRn+FeOiFWLOLgWquxdiF3ZJzo6mpMnT2qSCHPGGE6ePOlz99p62otJ2avEkyCSzl34vc2Gz4WPn4D978Go8JibRn1Zv379yMvLQ2dSDn/R0dFtGqQHmiCU3U4dAnFAYtt+EL3qfz5EJ1nNTJogwpLL5WLgwHZ2Z1ZhT5uYlL1KDkFCX3C6/C/LGWGNidjzpnXzWykVVJoglL1KDtvTvFRv+Fw4WwxHPrGvTKWUTzRBKHudOgTJNiaIwbPA4bLWiFBKBZUmCGWf2iooPwZJ/e0rMzoBBl6o3V2VCgFNEMo+JUcAY28TE1jdXU/u+2ISQKVUUGiCUPYpybW2djYxgbXKHGgzk1JBpglC2afksLW1uwaRlG6tLKbNTEoFVcAShIg8LSKFIrK90b6HROSoiGz2POY1c+0cEdktIvtE5IFAxahsVnIEHBEQ37v1c9tq+DyrJ9PpE/aXrZTyKpA1iGeAOV72/94Yk+V5nNNmICJO4AlgLjAKuEFERgUwTmWXsnyITwOH0/6yR1wOxg27Xre/bKWUVwFLEMaYdUBxOy6dDOwzxhwwxlQDLwBX2hqcCoyyo5CQFpiye2dCj6Gw7aXAlK+UOkco7kHcJSJbPU1QyV6O9wUar5OX59nnlYjcLiI5IpKj88GEWCAThAhkXg+HPvT0llJKBVqwE8T/AYOBLOAY8Fsv53hbpb7ZqSKNMU8aY7KNMdmpqam2BKnawRiriSmx2Vzuv7HXWtvtLwfuPZRSDYKaIIwxx40xdcYYN/BXrOakpvKA9Eav+wH5wYhP+eHsKWsdiIQAJojug6DfZNiqzUxKBUNQE4SI9Gn08mpgu5fTNgBDRWSgiEQCi4BlwYhP+aHMszRooJqY6mVeD4U7oMDbj45Syk6B7Ob6PPARMFxE8kTkG8CvRWSbiGwFZgI/8JybJiIrAIwxtcBdwFvALuBFY8yOQMWpbFLmqeQFsgYBMPpqECdsezGw76OUCtx6EMaYG7zs/lsz5+YD8xq9XgHosNmOJFg1iNgUGDILtv0bZj0EDh3rqVSg6G+XskfpUesv+7hegX+vsddDWZ7Vo0kpFTCaIJQ9yvKtEdSBGCTX1Ih5EBkHW14I/Hsp1YVpglD2COQYiKYiY2HUVbDzVag+HZz3VKoL0gSh7FGWH/gb1I1l3QDVFbDrjeC9p1JdjCYI5b/6QXLBTBD9p1oLE235V/DeU6kuRhOE8l9lKdScDl4TE1i9l8bdAAfWQmle8N5XqS5EE4TyX/kxa5vQp+Xz7DZuEWBg69Lgvq9SXUTAxkGoLqTiuLWNC8A6EC3pPgj6nw+bn2fX4G/y2pZjfHb4FMfLKqmoqiPSKURGOIiNiiAh2kV8dATx0S4SYjzbaGt/99hIJmV0J7GbK7jxKxXmNEEo/1UUWttgjIFoomT4dSS9cy8P/vEZdjiGMjotkcx+ScRGRVBb56aq1s3pqlrKK2s5XHyG8spays7WUF5V+6VynA7h8rF9+P4lQxmcGhf0z6FUONIEofzXUIPoGdS33ZpXwl2rUnjLRPJIxlbSb/oOSd0ifbq2zm2oqKqlvLKG/JJK3tpRwAufHubNHQX89PKR3HR+RmCDV6oD0ASh/FdxHCJiICo+aG+5u6Ccr/71ExJj4qlNv5yxR94Bl9vn650OITHGRWKMi37J3Zg8sDvfvmgQ97+8lZ++toOCskp+dOlwRLzNPq9U16A3qZX/Kgqt2kOQ/jMtOVPNN57dQLdIJy/dcT7x591k9aTas9KvcnvGR/PULZO4YXI6T6zez3MfHbIpYqU6Jk0Qyn/lBUG9//Dz13dSUFrJkzdnk5YUA4NmWGthb37e77KdDuEXV43lkpE9efiNnWzIbc+quUp1DpoglP/qaxBBsHp3Ia98dpQ7Zw4hKz3J2ulwWutE7Hv3ixvmfnA4hN8vzKJPYjT3vbSFs9V1fpepVEekCUL5r+J4UGoQtXVu/t/yXQxMieWumUO+fDDrq2DqYKs960TER7v49bWZ5J48wx/f22tLmUp1NJoglH9qq+FscVASxL835bG3sIL75wwnMqLJj27qcEibAFv8b2aqN3VwCteM78tTHxzkaMlZ28pVqqPQBKH8c7rI2ga4ianObXhi9X7G9UvkstHNDMjL+ioc3w7Httr2vj+8bDgC/Pbt3baVqVRHEcglR58WkUIR2d5o329E5HMR2Soir4hIUjPX5nqWJt0sIjmBilHZoGEMRGBrEG/vKOBw8RnuuGhw811Px3wFHC5baxF9k2K4acoAXtucz5HiM7aVq1RHEMgaxDPAnCb73gHGGGMygT3Agy1cP9MYk2WMyQ5QfMoOQRhFbYzhL+sO0L97Ny5trvYA0K07DJ9r3Yeoq7Ht/b954SAcAn9Zt9+2MpXqCAKWIIwx64DiJvveNsbUz3HwMdAvUO+vgiQIo6i35JWy+UgJ37hgIE5HK2Mtsr4KZ05YPZps0jsxmq9M6MeLOXkUlVfZVq5S4S6U9yBuA5ob2WSAt0Vko4jc3lIhInK7iOSISE5RUZHtQapWNNQgApcgXsw5QrTLwdUTfFhvYsgl0C0FNtu7TsS3pg+iutbN0g2HbS1XqXAWkgQhIj8BaoElzZwyzRgzAZgLfFdEpjdXljHmSWNMtjEmOzU1NQDRqhZVHIfoJIiICkjxZ6vreH1zPvPG9CEh2ofZVp0ua0zE7pVQYd8fDINT45g2pAfPf3qEOrexrVylwlnQE4SI3ALMB240xnj9TTPG5Hu2hcArwOTgRajaJMBjIN7aUUB5VS3XZrehNXLi18FdA5uesTWWr04ewNGSs6zbozVV1TUENUGIyBzgfmCBMcZrlxARiRWR+PrnwKXAdm/nqjAQ4FHUL208Qnr3GKYM7OH7RanDYPDFsOFvtt6snj2qFylxUSz5ROdoUl1DILu5Pg98BAwXkTwR+QbwJyAeeMfThXWx59w0EVnhubQX8IGIbAE+BZYbY94MVJzKTwGsQRwvq2T9/pN8ZUI/HK3dnG7qvDusle52LbMtnsgIB9dn9+O9zwspKK20rVylwlXApvs2xtzgZfffmjk3H5jneX4AGBeouJTNKgoDliBWbjuGMTA/sx1rXQ+ZDckD4ePF1vgIm1w7sR9/XrOf17fk863pg2wrV6lwpCOpVftVVUDN6YA1Ma3YXsCwXnEM6dmOFd4cDpjyHcj7FHI/tC2mQalxjEtP4pXPjtpWplLhShOEar8AjqIuLKtkQ24x88b2aX8hE26G2J6w9lf2BQZclZXGzmNl7Dlebmu5SoUbTRCq/QI4BuKtHQUYA5f7kyBcMTDt+3BwLRz+2LbY5mem4XQIr2otQnVymiBU+wWwBrFiWwFDesYxtJefy5hmf90aOLfqEfDeq7rNUuOjuHBoCq9tzsetYyJUJ6YJQrVfgOZhKq+sYUNuMZeMtKHcyFiY+SAc+sDWHk1XZfXlaMlZcg6dsq1MpcKNJgjVfhXHQZzWJHk2Wr//JLVuw4zhNo2Mn3Ar9BwFb/8X1NjTPfWSUb2IjHCwYtsxW8pTKhxpglDtV3EcYlOtJT9ttG5PEXFREUzon2xPgc4ImPNLKDkMH/3RliLjoiKYMSyVN7cXaDOT6rQ0Qaj2qyiEeHubl4wxrN1TxNTBPc5dNc4fg2bAyCtg3W/hlD0joeeN7UNBWSWfHSmxpTylwo0mCNV+ARhFfeDEafJOneUiu5qXGpvzGIjAmy0tQ+K7i0f2JNKpzUyq89IEodovAPMwrd1tTYQ3fWgAEkRiP7jofti9HHb7P3tLQrSLC4emeEZ8azOT6nw0Qaj2cbvhtP3TbKzdU8Sg1FjSu3eztdwGU+6E1BGw8j6o9n8J0Xlj+5BfWsmWvFIbglMqvPiUIETk3yJyuYhoQlGWs6fAXWtrgqisqePjAye5aFgA1/WIiIR5j1s3rD/4nd/FXTKyFy6nsFKbmVQn5Ot/+P8HfBXYKyKPiciIAMakOoIALDX6ycFiqmrdgU0QAAMvhMyF8OH/wol9fhWV2M3FtCEpLNdmJtUJ+ZQgjDHvGmNuBCYAuVjTda8Xka+LiA/LfKlOJwCjqNfuLiIqwsGUQW1Y+6G9Zj8CETGw4od+j7CeN6YPeafOsv1omU3BKRUefG4yEpEewK3AN4HPgP/FShjvBCQyFd4CMIp67Z5CzhvUg2iXveMqvIrvBbN+CgfWwB7/blhfOroXEQ5huTYzqU7G13sQ/wHeB7oBVxhjFhhjlhpjvge0Yy5m1eHZ3MSUd+oM+4tOB755qbGJX4ek/rDucb9qEUndIjl/cA/e3K7NTKpz8bUG8ZQxZpQx5pfGmGMAIhIFYIzJDlh0KnxVHAdXN4i05++DdXtOAAQ3QTgjYNo9cDQHDq7zq6h5Y/uQe/IMu47pFOCq8/A1QTzqZd9HdgaiOpj6MRDSxqVAm7F2TyF9k2IYnBprS3k+y7oR4nrD+j/4Vcylo3rhEFi5XZuZVOfRYoIQkd4iMhGIEZHxIjLB85iB1dzU0rVPi0ihiGxvtK+7iLwjIns9W6+T7YjIHBHZLSL7ROSBtn8sFXA2jqKuqXPz4b6TXDQ8FbEp4fjMFQ0Tb4F9q/yagqNHXBRTBvXQ3kyqU2mtBnEZ8DjQD/gd8FvP417gx61c+wwwp8m+B4BVxpihwCrP6y8RESfwBDAXGAXcICKjWnkvFWw2jqLedOgUFVW1wW1eamz8TVZNaNNzfhUzd2wfDhSdZm9hhU2BKRVaLSYIY8yzxpiZwK3GmJmNHguMMf9p5dp1QHGT3VcCz3qePwtc5eXSycA+Y8wBY0w18ILnOhVObKxBrN1TRIRDmDo4CN1bvUlKhyGz4bN/QF1tu4u5bHQvRNC5mVSn0VoT09c8TzNE5N6mj3a8X6/6m9yerbc/QfsCRxq9zvPsay7G20UkR0RyioqK2hGSarPaajhbbGuCmDAgmfjoEA6pGX+jlfRy3293ET3jo5mU0Z2V2wpsDEyp0Gmtian+jmEcEO/lEQjeGqGbbdQ1xjxpjMk2xmSnpoaoiaKrOW3fWtSF5ZXsyC8LXfNSvaGXWj2ydrziVzHzxvRm9/Fy9mkzk+oEWmti+otn+3Nvj3a833ER6QPg2RZ6OScPSG/0uh+Q3473UoFi4yjq90PRvdUbVwwMn2stS1pX0+5i5ozpA8Cb2ptJdQK+DpT7tYgkiIhLRFaJyIlGzU9tsQy4xfP8FuA1L+dsAIaKyEARiQQWea5T4aLCvhrE2j1FpMRFMapPgt9l+W301dYkhAfWtruI3onRTByQzAptZlKdgK/jIC41xpQB87H+wh8G3NfSBSLyPNZYieEikici3wAeA2aLyF5gtuc1IpImIisAjDG1wF3AW8Au4EVjzI42fzIVODbVIOrchvf3FjF9WAoOR5C7t3ozeBa4YmHPSr+KmTe2DzuPlZF74rRNgSkVGhE+nld/93Ae8Lwxpri1/urGmBuaOTTLy7n5nrLrX68AVvgYmwq2+hpErH/NQtuPlnLqTE3om5fquaJh0EWw921r6o12jsmYM6Y3j7yxk5XbC/jOjME2B6lU8Phag3hdRD4HsoFVIpIKVAYuLBXWKo5DTDJERPlVzNo9RYjAhYFYPa69hs621oo4safdRfRNiiErPUlHVasOz9fpvh8AzgeyjTE1wGl0bELXZdMYiLV7isjsl0T32EgbgrLJkNnWdu/bfhUzb2xvtuaVcqTY/1XrlAqVtqwQNxJYKCI3A9cClwYmJBX2bBhFXXqmhs8On+KioSk2BWWTpHToOcrvBDG3oTeT3qxWHZevvZj+gTXlxgXAJM9DZ3HtqmyoQXyw7wRuAxcND6PmpXpDZ8Oh9VDV/plZ07t3Y2zfRFZoM5PqwHytQWQD04wxdxpjvud53B3IwFSYMsZTg/AvQazdU0hCdATj+iXZE5edBs201ts+/LFfxcwd25vPDpeQd0qbmVTH5GuC2A70DmQgqoOoroCaM341MRljWLuniAuHphLhbEsrZ5CknwcOl99rRFyRmQbA61u0FqE6Jl9/O1OAnSLylogsq38EMjAVpmxYanT38XKOl1WFT/fWpiK7Qb9Jfs3LBFYz04T+SSzbohMBqI7J13EQDwUyCNWB2LDU6Lo91qSK08M1QQAMvBDW/QYqSyE6sd3FLBiXxkOv72Tv8XKG9grU9GVKBYav3VzXArmAy/N8A7ApgHGpcGXDKOq1e4oY0Tue3onRNgUVABkXgnHDIf8WTrw8Mw2HoLUI1SH52ovpW8DLwF88u/oCrwYoJhXO/GxiOl1Vy4aDp8K79gBWE5Mzyu9mptT4KKYNSeG1zfm60pzqcHy9B/FdYBpQBmCM2Yv3tRxUZ1deAI4IiOnersvX7z9JdZ2bGeGeIFzRkD7Z7xvVAFeMS+Nw8Rm25JXaEJhSweNrgqjyrO4GgIhE0MIaDaoTqzgOsT3B0b7eR6t3FxIb6SQ7o30JJqgyLoSCbdYMr364bHRvIp0OXtt81KbAlAoOX3/L14rIj4EYEZkNvAS8HriwVNiqOA7x7WteMsawdncR04akEBkRht1bm8qYBhg4/IlfxSTGuJg5IpU3th6jzq1/V6mOw9ff0geAImAb8G2smVb/K1BBqTBWfhzi2jckZl9hBUdLzjJjeAdpneybDc5IOPSB30UtGNeXovIqPj5w0obAlAoOn7q5GmPcIvIq8KoxRhd+7soqCqDvhHZduma39aMzIxyn1/DGFW0liUPr/S5q1siexEY6WbY5n2lDwmz+KaWa0WINQiwPicgJ4HNgt4gUicjPghOeCit1tXD6BMS3rwaxenchw3vFk5YUY3NgAZQxDfI3+zUvE0C0y8llo3uzcvsxqmrr7IlNqQBrrYnpHqzeS5OMMT2MMd2B84BpIvKDQAenwszpIsC0q4trRVUtG3KLO07tod6AqWDq4Minfhd1RVYaZZW1rN2tlXDVMbSWIG4GbjDGHKzfYYw5AHzNc6zNRGS4iGxu9CgTkXuanDNDREobnaM1lnBQ4Zm6uh0JYv2+E9TUmfCcvbUl6edZ3XoPfeh3URcMSaF7bCSv6aA51UG0dg/CZYw50XSnMaZIRFzeLmiNMWY3kAUgIk7gKPCKl1PfN8bMb897qACpHyTXjiam1buLrO6tAzpA99bGImOhT5Yt9yFcTgfzxvbm5Y15nK6qJTbK15lulAqN1moQ1e085qtZwH5jzCEbylKBVt6+GoTVvbWQC4Z2kO6tTWVMg6Mboeas30UtGNeXyho37+w8bkNgSgVWa7+t4zxNQE0f5cBYG95/EfB8M8fOF5EtIrJSREY3V4CI3C4iOSKSU1SkbbsB1TDNRtu6qe4trCC/tLLjdG9tasA0qKuGvBy/i8oekEyfxGidm0l1CC0mCGOM0xiT4OURb4xpVxNTPRGJBBZgDbprahMwwBgzDvgjLcz7ZIx50hiTbYzJTk3tYO3bHU1FAcQkQ0RUmy5bs9tKLB3uBnW9/lMAseU+hMMhLBiXxro9RZw6bUclXKnACWV9fy6wyRhzTl3bGFNmjKnwPF8BuEREO4+HWnlBu25Qr/68iOG94umT2IG6tzYWnQi9x9qSIMCam6nWbXQ5UhX2QpkgbqCZ5iUR6S0i4nk+GStOHYIaau1YarSsssbq3jqig9Ye6mVcAEc2QK3/f/WPTktgUGosyzZrM5MKbyFJECLSDZgN/KfRvjtE5A7Py2uB7SKyBfgDsMjoXMmhV1HQ5h5Ma3cXUes2XDLSvzWsQ27AVKg9C/mf+V2UiHDluL58mlvMsVL/b3wrFSghSRDGmDOegXeljfYtNsYs9jz/kzFmtDFmnDFmijHG/z6Gyj/GeOZhatuN5lW7jpPczcWE/skBCixI+k+1tjbMywSwICsNY+ANXa9ahbEO2OdQhURlKdRVtWmivto6N6t3FzFzRE+cDglgcEEQ2wNSR9oyHgJgYEosY/smam8mFdY0QSjf1C812oYmppxDpyg9W8Psjt68VC9jGhz+2JqTygZXZqWx7WgpB4oqbClPKbtpglC+aRgk53sT06pdx4l0Orgw3FeP89WAqVBdAQVbbSlufmYaoutVqzCmCUL5pmGQnO81iHd3FTJlcA/iOsuUEgOmWVuburv2ToxmckZ3lm3R9apVeNIEoXxTP1Gfj6vJ7S+q4OCJ01wysoOOnvYmvjd0H2zbfQiAK7P6cqDoNDvyy2wrUym7aIJQvikvgIhoiErw6fR3PXMNzeos9x/qZUyzEoTbbUtxc8f0JsIh2sykwpImCOWbiuPWIDnxrTfSql2FjOyTQN+OtDiQLwZMg8oSKNxpS3HJsZFMH5bK61vycet61SrMaIJQvik7Bgl9fTr11Olqcg4VM7szNS/Vs/k+BMCCcWkcK60k59Ap28pUyg6aIJRvyo5CQppPp67eXYjbdMLmJYCkdEjsb2uCmD2qF9EuB8u2HLWtTKXsoAlCtc4YKMuHhD4+nb5qVyE946MY2zcxwIGFSP19CJt6HsVGRXDJyF4s33qMmjp77m0oZQdNEKp1Z09Zo6h9aGKqrnWzdk8Rs0b2xNHRR083Z8BUa33uE3ttK3LBuDROnalh/X6dk1KFD00QqnVlnqaP+NZrEJ8cPElFVW3Hn5yvJfX3IQ6uta3Ii4anEh8Vwevam0mFEU0QqnVlnv+0fKhBvLvzONEuB9OGdOLlO7oPsh5737atyKgIJ7NH9+KtHQVU1dbZVq5S/tAEoVrXkCBavkltjOHdXYVcMCSFaJczCIGFiAgMmwMH1kL1aduKvWJcGuWVtby/54RtZSrlD00QqnVl+SCOVhcL2pFfxtGSs1w6um1rRnRIQy+17sscXGdbkRcMSSGpm4vXt2ozkwoPmiBU68rzreTgbHlOpbd2FOAQmDWiE45/aGrANIiMgz1v2Vaky+lgzujevLvzOJU12sykQk8ThGpdWb5PYyDe3nGcSRnd6REXFYSgQiwiEgZfbCUIGyfau2JcGqer61j9eaFtZSrVXqFacjRXRLaJyGYRyfFyXETkDyKyT0S2isiEUMSpPMryW+3BlHviNLuPl3eN5qV6w+dZtaujG20r8ryB3UmJi9RmJhUWQlmDmGmMyTLGZHs5NhcY6nncDvxfUCNTX+bDNBtv77Rme710VCfu3trUiHngjITt/2n9XB9FOB3MG9uH9z4vpKLKnoWJlGqvcG1iuhJ4zlg+BpJExLdhvMpeVeVQVdpqE9NbO44zOi2B9O7dghRYGIhOhCGXwI5XbJvdFayFhCpr3Kzaddy2MpVqj1AlCAO8LSIbReR2L8f7Akcavc7z7DuHiNwuIjkiklNUVBSAULu4smPWtoUEUVheyabDp7h0VBdqXqo3+mqrmSnvU9uKzB6QTO+EaF7fcsy2MpVqj1AliGnGmAlYTUnfFZHpTY57m6PB651AY8yTxphsY0x2amonWdoynJR72sJbuAfx7s5CjIHLxnSh5qV6w+da62Rs/7dtRTocwuWZfVi3p4jSszW2latUW4UkQRhj8j3bQuAVYHKTU/KA9Eav+wF61y4USjwVuaT0Zk95e2cB/bt3Y3iv+CAFFUai4q1Bc9tehtoq24qdn9mH6jo3b+8osK1Mpdoq6AlCRGJFJL7+OXApsL3JacuAmz29maYApcYYrW+HQslha5BcMzepyytrWL/vJJeN7oX4uJhQpzPhZjhbDJ8vt63IrPQk+iXH8MZW/bFXoROKGkQv4AMR2QJ8Ciw3xrwpIneIyB2ec1YAB4B9wF+BO0MQpwIoPQLxaeB0eT28encR1XXurtW9talBM601IjY9Z1uRIsL8zDQ+3HeC4tPVtpWrVFsEPUEYYw4YY8Z5HqONMb/w7F9sjFnseW6MMd81xgw2xow1xpwzVkIFSclhSOrf7OG3dxSQEhfJhP7JQQwqzDgcMP5GOLAaTuXaVuz8zD7Uug1vbtdmJhUa4drNVYWLksPN3n+oqq1jze4iLhnZC2dnXfvBV1k3Wk1xOU/bVuTotAQGpsTyhg6aUyGiCUI1r67WGkXdTA1i/X5r7YfLunLzUr2kdBh5BWx8BqoqbClSRLgisw8fHzhJYXmlLWUq1RaaIFTzyo6CqYNE7zWIt3cUEBvp5PzBPYIcWJia8l2oLIUtz9tW5PxxabgNrNymzUwq+DRBqOaV1ndxPbcGUec2vLOzkBkjenbutR/aIn0ypE2Aj//PtpHVw3rFM7xXvDYzqZDQBKGaV3LY2npJEBtyizlRUcUcbV76ggic/10o3g+7V9hW7PzMPmzIPUV+yVnbylTKF5ogVPPqE0Riv3MOrdh2jKgIBxd3hbUf2mLUlZCcAet+Y9s04PPHWdOcrNimYyJUcGmCUM0rOQJxvSHiy+s71LkNK7cXMHN4T2KjWl5EqMtxuuCCe+HYZtj3ri1FDkyJZUzfBF7XQXMqyDRBqOadOmj9NdxETm4xReVVzMvUCXa9GneDdWN/7a/tq0VkprHlSAmHT56xpTylfKEJQjXv5H7oMfic3Su3FxAV4egaS4u2R0QkXHCPNcPrwbW2FHn5WCsZv7FNb1ar4NEEobyrqoCKAug+6Eu73W7Dyu3HmDE8VZuXWpL1NWsG3LW/saW49O7dGN8/iTd0CnAVRJoglHfFB6xtkxrExsOnOF5Wxbyx2rzUIlc0TLsHDn0AB9bYUuT8zDR2Hitjf5E9A/GUao0mCOVd8X5r2/3LCWL51mNERjiYNbILrv3QVhNvhYR+sOphW+5FXD62DyJoLUIFjSYI5d3J+gTxRRNTffPSRcNSidPmpda5omHmg3B0I3z+ht/F9U6MZlJGd17dfBRj081vpVqiCUJ5V3zA6uIaFdewa5OneelybV7yXeYiSBkGqx4Bd53fxV2fnc7BE6f59GCxDcEp1TJNEMq74gPn3H94bXM+0S4Hs0Zq7yWfOSPg4v+CE7thywt+FzdvbG/ioyJYuuFI6ycr5SdNEMq7k/u/1LxUU+fmja35XDKyF/HR3hcPUs0YuQDSxsOaX0KNf7OydouM4MrxaSzfdozSM7petQosTRDqXJWlcLrwSzWIdXuKOHWmhqvHe196VLVABGY/bE1++NEf/S5u0aT+VNW6eW3LURuCU6p5oViTOl1EVovILhHZISLf93LODBEpFZHNnsfPgh1nl1a029qmjmzY9cpnR0nu5mL6sNQQBdXBDZxu1STW/daawsQPY/omMjotgec/PaI3q1VAhaIGUQv80BgzEpgCfFdERnk5731jTJbn8XBwQ+ziCnda254jACivrOGdnceZn5mGy6mVzna77BfW9u3/8ruoRZP7s+tYGZuPlPhdllLNCcWa1MeMMZs8z8uBXYC2W4STwl3gioVEa5rvt3Ycp6rWzVXj00IcWAeX1B8u+AHsfBX2v+dXUVeP70t8VARPf5hrS2hKeRPSPwdFJAMYD3zi5fD5IrJFRFaKyOjgRtbFFe60ag8O68fjlc/ySO8ew4T+ySEOrBOYdjf0GAqvfc+619NOcVERLJyUzoptx3SdCBUwIUsQIhIH/Bu4xxhT1uTwJmCAMWYc8Efg1RbKuV1EckQkp6ioKGDxdimFnzfcfzh88gwf7jvJtRPSEZEQB9YJuGLg6sVQng8rH/CrqFumZmCM4dmPcu2JTakmQpIgRMSFlRyWGGP+0/S4MabMGFPheb4CcIlIireyjDFPGmOyjTHZqal6A9Vvp09aPZh6Wgliac5hHALXTzp30SDVTv2y4cIfwpZ/wcZn211MevduzBnTm+c/OczpqlobA1TKEopeTAL8DdhljPldM+f09pyHiEzGivNk8KLswgq2WNteo6mtc/NSTh4zhvekT2JMaOPqbGY8CIMvhuU/hMMft7uYb1wwiLLKWp7/9LCNwSllCUUNYhpwE3Bxo26s80TkDhG5w3POtcB2EdkC/AFYZLQ/X3Dkf2Zt07J47/NCCsurWDQpPbQxdUYOJ1z7NCSlw5Lrrfma2mHigGSmDu7B4rUHOFvt/1QeSjUWil5MHxhjxBiT2agb6wpjzGJjzGLPOX8yxow2xowzxkwxxqwPdpxdVv5n1gjqmGRe2HCEnvFRuu50oMQkw83LICYJnrsacj9oVzH3XDKMExVVLPnkkL3xqS5PO7WrL8vfDGnjyT1xmtW7C1k4KZ0IHfsQOEnpcOtyiOsJz10Jn/61zVODTx7YnWlDerB47X7OVOu9CGUf/c1XX6gosqaDSBvPM+tziXAIN00ZEOqoOr+kdPjWKhg8C1b8CJ5fBBWFbSri3tnDOVFRzeI1+wMUpOqKNEGoL3jawSt6jOXFnCNckZlGz4ToEAfVRUQnwg0vwJzHYP9q+PMU2OX7GhITBySzYFwaf1l3gCPFZwIYqOpKNEGoLxz6AJyRvHA0lTPVddx2wcBQR9S1OBww5Tvw7XWQ0BeW3ghv3OvzDLAPzB2BCPxy5a4AB6q6Ck0Q6gu5H+JOm8hfPjrG+YN6MKZvYqgj6pp6joBvroLz74Kcv8FTl3yxwl8L0pJi+O6MIazYVsBbOwqCEKjq7DRBKEtVORzbwhbnaIrKq/j+JUNDHVHXFhFpTe731Zeg7Cg8NQsOtd6Z79sXDWZ0WgI//s82TlRUBSFQ1ZlpglCWwx+DqeOvh9OYOrgHUwb1CHVECmDYpfCt96BbitXLaetLLZ4eGeHgd9dnUV5ZywP/3obbrcOHVPtpglCWPW9R44jmvTMD+cHsYaGORjXWfSB88x3oNxn+801Y3/KiQ8N7x3P/3BG8u+s4f3hvb5CCVJ2RJggFxlD3+QrW1Y1h6oh0JmV0D3VEqqmYZLjpPzDqKms9ibd+Am53s6ffNi2Dr0zox/+8u5flW48FL07VqUSEOgAVBo5twVl+lHfq5vPT+d7WblJhISLKmp7jzZ7w0Z+ssRJXPmHdr2hCRPjF1WPIPXmae5Z+RlSEg0tG9QpB0Koj0xqEIu/DF6gzQp/JVzMwJTbU4aiWOJww99dw8U9h24vw/EKrg4EX0S4nf//6JEb1SeA7Szby7415QQ5WdXSaILq4sjNnidrxAp9GZHP7nMmhDkf5QgSm/8iqPRxYC8/Mt0bBe5EQ7eK5b5zHpIzu/PClLfz89R06qZ/ymSaILswYw7/++RSpnKLXjG8RE+kMdUiqLcZ/DRb9C4p2w99mQ/EBr6clxrh49rbJ3Do1g79/mMu8P7zPmt2F6ATJqjWaILqwP6/eR1beEioiUxk09ZpQh6PaY/gcuOV1qCyBv10Kh72t3gsup4OHFoxmyTfPo9bt5ta/b+CqP6/n5Y15lFfWBDdm1WFIZ/orIjs72+Tk5IQ6jA7hxQ1HePWVf/GvyP+HmfMrZModrV+kwlfRHlhyrTXZ4rR7rAWJvNy8BqiudfPyxjz+sm4/h06eIdLpILNfIhMHJJOREkvfpBi6x0YS7XISFeHA6RCqa93U1LmprnNTU2eoqXN7HobaRvtq3W5q6wxOh+ByOnA5hQiHA1eEg0ing4SYCBJjXCTGuIiLitBlbMOAiGw0xmR7PaYJoutZ8skhfv7qZt6Je4j+0ZXI3Z+BSyfl6/Aqy+CtB+Gzf0LKMLjs/8HQ2c2eboxh0+ES3tpRQE5uMduOllJTF7z/D5wOIblbJH2ToumbHEPfpBj694hlRO94hveOJyHaFbRYujJNEAqAypo6frF8F//4+BB/6rmM+WUvwKLnYcS8UIem7LTnbXjzASjeD4NmWutfZ1xg3dxuQW2dm4KySo6eOkvJ2Roqa+qoqnXjdhsiIxy4nA7Ptr520KiG4Pxiv9Mh1LkNte7GtQ1DVW0dZWdrKTtbQ6nncaKiiqMlZzl66ixHS85SVfvF2I6+STGMSktg4oBkJg5IZmzfRKJdep/Mbi0lCB0H0QUYY1izp4ifL9tB7skzLB7+GXMOvQATbtbk0BkNuxQGzYBPn4QP/weenQ99J8LEr8OoKyE6wetlEU4H/ZK70S+5m2/v43ZD7VnruatbqwmoNcYY8ksr2V1QxucF5ew6Vs72o6W8s/O49RZOYUzfRCb2T2Z8/2QmDEjStdIDLCQ1CBGZA/wv4ASeMsY81uS4eI7PA84AtxpjNrVWrtYgvqzkTDUrthXwwobDbM0rZXR3N0/1W0mfPUtg2BxY+E9wajW+U6s5C5v/BR//GU7ug4hoGHgRDJwO/SZBylDo1mTkvDFw9hSUHIKSI1ByGErzoCwPSo9CWb51vK7JZICuWIhNgcR0SOxrbbsPsqYKSR4I8b3blUROVFSx6dApNh4+xaZDp9iSV0q1p6bROyGa8f2TGN8/iaz0ZIb1iiOpm/d7L8q7sGpiEhEnsAeYDeQBG4AbjDE7G50zD/geVoI4D/hfY8x5rZXd1RKEMYbKGjdllTWUna3haMlZDp08w4GiCnJyi8krOE4Kp7g4qYBFPQ4yqOgdpKoCzv8uXPKQJoeuxBhrQaitL8L+9+BkozmaXLEQGWuN1K4+bQ28czfp2RQZZ61RkdgXEtKgWw+IiPni3lX1Gag5AxXHrWRSetRKKKbRdCARMZCc0ShpZHyRPGKSrfdo5sZ6Y9W1bnYdK+Ozw6f47EgJnx0u4XCjRZJS4iIZnBrHoNQ4+iRG0yship4J0aTGRREXFUFsVARxURFEuxx6k5zwa2KaDOwzxhwAEJEXgCuBnY3OuRJ4zljZ62MRSRKRPsaYgEwqM/+P7zcMHjLAf519nEF1B6n/0RHqk6jxvG783DQ5xzp07v7G11r7zZeub+69mrnOfHGeC0jxPLIwCBAj1URGeX7JzwKF8TByvpUceo/19Z9GdRYi0C/beoBVCyjYZtUqSvOs/9xrq6xEERUPsamQ1N96JKZb/4G39T/Tuhqr9nHqIBR7HqcOWuM19r/3RfNUYw4XRMVZW4cTxAnisBZTEic4nEQijAPGAbcCdIPaaOseR3Wt1dOqutBNzTFDXZPZbGuAEs+j/p9FAAQEafS8DaTFlw17f9Dtl5Q5Elo5r32Su0Xy4h3n21iiJRQJoi9wpNHrPKxaQmvn9AXOSRAicjtwO0D//v3bFdDQnvFWldXzjdWc6E9xtcPzC9H0a7R+eoznh8kgDb84jfdZW7746bOC/aKM+vPEy3VNzvN8Ts9//V8ccjqsroOuCCeREQ66RUYQHx1BTGQEEhENcT0hrhf0HAmpI7TGoL6QkGY9uCxw7+F0QY/B1qMpt9uqbRQfsJqyKsugutxTg6mwajDuOqvmY+o8zz1bLyI8j6YTxdQZQ1Wtm8oaN9W1ddS6DbV1hlq3oc7txm3AbYz1Np6tG7wOIvTa1tKGFphBPRM564zzlGVvy02genyFIkF4S5xN/7V8OcfaacyTwJNgNTG1J6DfL8xqsufP7SlGKeUrhwMS+lgPpgXsbZxAN88j1CaEOoB2CMVI6jwgvdHrfkB+O85RSikVQKFIEBuAoSIyUEQigUXAsibnLANuFssUoDRQ9x+UUkp5F/QmJmNMrYjcBbyFVQN82hizQ0Tu8BxfDKzA6sG0D6ub69eDHadSSnV1IRkoZ4xZgZUEGu9b3Oi5Ab4b7LiUUkp9QWdzVUop5ZUmCKWUUl5pglBKKeWVJgillFJedarpvkWkCDgU6jg8UoAToQ7CJvpZwldn+jz6WUJjgDEm1duBTpUgwomI5DQ3AVZHo58lfHWmz6OfJfxoE5NSSimvNEEopZTyShNE4DwZ6gBspJ8lfHWmz6OfJczoPQillFJeaQ1CKaWUV5oglFJKeaUJwg8i0l1E3hGRvZ5tcjPnzRGR3SKyT0QeaLT/IRE5KiKbPY95wYu+5dgaHRcR+YPn+FYRmeDrtcHm52fJFZFtnu8h5Aub+/BZRojIRyJSJSI/asu1webnZ+lo38uNnp+trSKyXkTG+XptWLKW2dNHex7Ar4EHPM8fAH7l5RwnsB8YBEQCW4BRnmMPAT8KYfzNxtbonHnASqxV/qYAn/h6bUf5LJ5juUBKqH+m2vBZegKTgF80/hnqoN+L18/SQb+XqUCy5/nccP198fWhNQj/XAk863n+LHCVl3MmA/uMMQeMMdXAC57rwoEvsV0JPGcsHwNJItLHx2uDyZ/PEm5a/SzGmEJjzAagpq3XBpk/nyXc+PJZ1htjTnlefoy1GqZP14YjTRD+6WU8K915tj29nNMXONLodZ5nX727PNXRp5trogqg1mJr6Rxfrg0mfz4LWGuevy0iG0Xk9oBF6Rt//m074vfSko78vXwDq8banmvDQkgWDOpIRORdoLeXQz/xtQgv++r7Fv8f8Ijn9SPAb4Hb2hqjH1qKrbVzfLk2mPz5LADTjDH5ItITeEdEPjfGrLM1Qt/582/bEb+XlnTI70VEZmIliAvaem040QTRCmPMJc0dE5HjItLHGHPM01RR6OW0PCC90et+QL6n7OONyvor8IY9Ufus2dh8OCfSh2uDyZ/PgjGmflsoIq9gNQmE6j8iXz5LIK4NBL/i6Yjfi4hkAk8Bc40xJ9tybbjRJib/LANu8Ty/BXjNyzkbgKEiMlBEIoFFnuto0v59NbA9gLF602xsjSwDbvb0AJoClHqa03y5Npja/VlEJFZE4gFEJBa4lOB/F43582/bEb8Xrzri9yIi/YH/ADcZY/a05dqwFOq75B35AfQAVgF7Pdvunv1pwIpG580D9mD1YvhJo/3/ALYBW7F+WPqE4DOcExtwB3CH57kAT3iObwOyW/tcIfw+2vVZsHqWbPE8dnSQz9Ib66/SMqDE8zyhg34vXj9LB/1engJOAZs9j5yWrg33h061oZRSyittYlJKKeWVJgillFJeaYJQSinllSYIpZRSXmmCUEop5ZUmCKWUUl5pglBKKeXV/wc98YeBRKBWFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tp_variances.diag_137.plot.kde(label='True positives')\n",
    "fp_variances.diag_137.plot.kde(label='False positives')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diag_53     104.0\n",
       "diag_51     111.0\n",
       "diag_149    111.0\n",
       "diag_239    112.0\n",
       "diag_122    119.0\n",
       "diag_5      129.0\n",
       "diag_101    138.0\n",
       "diag_246    140.0\n",
       "diag_120    142.0\n",
       "diag_221    143.0\n",
       "diag_116    146.0\n",
       "diag_115    147.0\n",
       "diag_92     155.0\n",
       "diag_87     156.0\n",
       "diag_90     167.0\n",
       "diag_58     168.0\n",
       "diag_70     171.0\n",
       "diag_121    175.0\n",
       "diag_226    176.0\n",
       "diag_267    178.0\n",
       "diag_137    183.0\n",
       "diag_176    188.0\n",
       "diag_188    188.0\n",
       "diag_139    200.0\n",
       "diag_117    207.0\n",
       "diag_84     208.0\n",
       "diag_249    218.0\n",
       "diag_105    228.0\n",
       "diag_47     237.0\n",
       "diag_56     237.0\n",
       "diag_60     242.0\n",
       "diag_104    262.0\n",
       "diag_2      268.0\n",
       "diag_266    285.0\n",
       "diag_49     287.0\n",
       "diag_243    288.0\n",
       "diag_214    316.0\n",
       "diag_83     320.0\n",
       "diag_141    333.0\n",
       "diag_145    335.0\n",
       "diag_125    339.0\n",
       "diag_109    341.0\n",
       "diag_114    346.0\n",
       "diag_82     363.0\n",
       "diag_48     377.0\n",
       "diag_1      382.0\n",
       "diag_233    421.0\n",
       "diag_86     423.0\n",
       "diag_144    467.0\n",
       "diag_215    471.0\n",
       "diag_52     525.0\n",
       "diag_235    526.0\n",
       "diag_143    531.0\n",
       "diag_118    532.0\n",
       "diag_57     598.0\n",
       "diag_88     663.0\n",
       "diag_54     680.0\n",
       "diag_93     691.0\n",
       "diag_85     710.0\n",
       "diag_95     758.0\n",
       "dtype: float32"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden.sum(axis=0).sort_values().where(lambda x: x > 100).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 30\n",
    "topk_outputs = res.apply(lambda row: row.loc[idx[:,'mean']].nlargest(k),axis=1)\n",
    "\n",
    "# fix missing columns from previous operation\n",
    "missing_cols = [col for col in model_outputs.columns if col not in topk_outputs.columns]\n",
    "topk_outputs_all_cols = pd.concat([topk_outputs,pd.DataFrame(columns=missing_cols)])\n",
    "topk_outputs_all_cols = topk_outputs_all_cols[model_outputs.columns]\n",
    "\n",
    "## sometimes k > (#logits>0) so we will turn all 0 logits into nan so that the following lines don't convert them to predictions\n",
    "topk_outputs_all_cols = topk_outputs_all_cols.mask(topk_outputs_all_cols == 0,np.nan)\n",
    "# done, continuing...\n",
    "\n",
    "topk_predictions = np.where(topk_outputs_all_cols.isna(),0,1)\n",
    "topk_predictions = pd.DataFrame(data=topk_predictions,columns=model_predictions.columns,index=model_predictions.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_epochs(**kwargs):\n",
    "    n_epochs = kwargs.get('n_epochs',15)\n",
    "    \n",
    "    \n",
    "    model = VariationalRNN(kwargs.get('input_size'),\n",
    "                           kwargs.get('hidden_size'),\n",
    "                           kwargs.get('n_labels'),\n",
    "                           kwargs.get('num_layers'),\n",
    "                           kwargs.get('rnn_type'),\n",
    "                           kwargs.get('dropoutii'),\n",
    "                           kwargs.get('dropoutww'),\n",
    "                           kwargs.get('dropoutoo'))\n",
    "    \n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_one_epoch(model,train_dataloader,epoch,criterion,opt)\n",
    "    \n",
    "    res = eval_model(model,val_dataloader,dataset,criterion,'all','eval',False,'last adm',30)\n",
    "    return res['last adm']['recall30']['mean']\n",
    "func = lambda dropoutii,dropoutww,dropoutoo: train_multiple_epochs(n_epochs=10,\n",
    "                                                                input_size=input_size,\n",
    "                                                                hidden_size=hidden_size,\n",
    "                                                                n_labels=n_labels,\n",
    "                                                                num_layers=num_layers,\n",
    "                                                                rnn_type=model_type,\n",
    "                                                                dropoutii=dropoutii,\n",
    "                                                                dropoutww=dropoutww,\n",
    "                                                                dropoutoo=dropoutoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | dropoutii | dropoutoo | dropoutww |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6002  \u001b[0m | \u001b[0m 0.3919  \u001b[0m | \u001b[0m 0.6042  \u001b[0m | \u001b[0m 0.1001  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5985  \u001b[0m | \u001b[0m 0.3116  \u001b[0m | \u001b[0m 0.2027  \u001b[0m | \u001b[0m 0.1646  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.6059  \u001b[0m | \u001b[95m 0.2304  \u001b[0m | \u001b[95m 0.3419  \u001b[0m | \u001b[95m 0.3777  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5755  \u001b[0m | \u001b[0m 0.4772  \u001b[0m | \u001b[0m 0.3934  \u001b[0m | \u001b[0m 0.5797  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5895  \u001b[0m | \u001b[0m 0.2431  \u001b[0m | \u001b[0m 0.7147  \u001b[0m | \u001b[0m 0.1192  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5383  \u001b[0m | \u001b[0m 0.3631  \u001b[0m | \u001b[0m 0.6529  \u001b[0m | \u001b[0m 0.6421  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.6168  \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.4499  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5568  \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5687  \u001b[0m | \u001b[0m 0.2593  \u001b[0m | \u001b[0m 0.2089  \u001b[0m | \u001b[0m 0.7631  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5874  \u001b[0m | \u001b[0m 0.6084  \u001b[0m | \u001b[0m 0.61    \u001b[0m | \u001b[0m 0.2363  \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m 0.6287  \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 0.242   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5682  \u001b[0m | \u001b[0m 0.7688  \u001b[0m | \u001b[0m 0.5648  \u001b[0m | \u001b[0m 0.4295  \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/miniconda3/envs/thesis/lib/python3.9/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0.4421129060123973, 0.6888250716125918, 0.7853479068552041)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/__/lcwlgwm95q9_vf5ypxxn3d7c0000gn/T/ipykernel_23217/970594063.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/thesis/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/thesis/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/thesis/lib/python3.9/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/__/lcwlgwm95q9_vf5ypxxn3d7c0000gn/T/ipykernel_23217/1400149000.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(dropoutii, dropoutww, dropoutoo)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'last adm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last adm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall30'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m func = lambda dropoutii,dropoutww,dropoutoo: train_multiple_epochs(n_epochs=15,\n\u001b[0m\u001b[1;32m     23\u001b[0m                                                                 \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                                 \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/__/lcwlgwm95q9_vf5ypxxn3d7c0000gn/T/ipykernel_23217/1400149000.py\u001b[0m in \u001b[0;36mtrain_multiple_epochs\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'last adm'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/master-thesis/mourga_variational/../rnn_utils.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, epoch, criterion, optimizer)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/master-thesis/mourga_variational/variational_rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;31m# calculate hidden states and output from the l RNN layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;31m# apply dropout to the output of the l-th RNN layer (dropouto)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/master-thesis/mourga_variational/weight_drop.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setweights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    269\u001b[0m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    270\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    272\u001b[0m                            self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# bayesian optimization\n",
    "\n",
    "## bounds of parameter search\n",
    "pbounds = {'dropoutii': (0.1,0.8), \n",
    "           'dropoutww': (0.1,0.8),\n",
    "           'dropoutoo': (0.1,0.8)\n",
    "          }\n",
    "\n",
    "## parameter search\n",
    "optimizer = BayesianOptimization(\n",
    "    f=func,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "optimizer.maximize(init_points=5,n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.6287178853774116,\n",
       " 'params': {'dropoutii': 0.1,\n",
       "  'dropoutoo': 0.1,\n",
       "  'dropoutww': 0.2419500529180941}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best_params_1st_run = optimizer.max\n",
    "#best_params_1st_run\n",
    "\n",
    "best_params = optimizer.max\n",
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mthesis)",
   "language": "python",
   "name": "mthesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
