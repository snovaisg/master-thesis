{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2add6a-c28a-436f-b8bc-79bfb265b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import json\n",
    "from mourga_variational.variational_rnn import VariationalRNN\n",
    "#from temperature_scaling import _ECELoss\n",
    "\n",
    "from config import Settings; settings = Settings()\n",
    "from rnn_utils import DiagnosesDataset, split_dataset, MYCOLLATE\n",
    "import torch.optim as optim\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c61e94-86c8-4c5a-8b0d-934dcabf85ee",
   "metadata": {},
   "source": [
    "# Load variational model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21f6f6c7-e29c-4680-891f-3a087204f7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "hyperparameters_path = 'data/models/golden-oath-84/hyper_parameters.json'\n",
    "model_path = 'data/models/golden-oath-84/weights'\n",
    "with open(hyperparameters_path,'r') as f:\n",
    "    hyperparams = json.load(f)\n",
    "    \n",
    "# weights\n",
    "weights = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bd6ba2b-7357-4f6b-b2f9-ffebfa66cf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VariationalRNN(**hyperparams)\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cf73bc-8330-44d7-9f4e-82ec5df1de72",
   "metadata": {},
   "source": [
    "# Load validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4a28cb7e-0b55-4b82-8fc7-27ac51a245ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset at data/model_ready_dataset/diag_only\n",
      "1125\n"
     ]
    }
   ],
   "source": [
    "grouping='ccs'\n",
    "batch_size=64\n",
    "\n",
    "dataset_folder = os.path.join(settings.data_base,settings.model_ready_dataset_folder,'diag_only')\n",
    "dataset = DiagnosesDataset(os.path.join(dataset_folder,'dataset.json'),grouping)\n",
    "print('dataset at',dataset_folder)\n",
    "\n",
    "val_dataset = DiagnosesDataset(os.path.join(dataset_folder,'val_subset.json'),grouping)\n",
    "print(len(val_dataset))\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=batch_size,collate_fn=MYCOLLATE(dataset)) #batch_size here is arbitrary and doesn't affect total validation speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d0157-9a56-440a-81c7-93d25bca827b",
   "metadata": {},
   "source": [
    "# Use validation set to set the temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bf085a-f274-415b-a34c-0aaa403184a8",
   "metadata": {},
   "source": [
    "## Global Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da71bbc6-df2d-4444-8142-16f1d70a938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0, lr: 0.1000, loss: 0.1114, T: 1.0510\n",
      "Epoch  1, lr: 0.1000, loss: 0.1112, T: 1.0860\n",
      "Epoch  2, lr: 0.1000, loss: 0.1112, T: 1.0745\n",
      "Epoch  3, lr: 0.1000, loss: 0.1113, T: 1.0853\n",
      "Epoch  4, lr: 0.1000, loss: 0.1112, T: 1.0687\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence, pack_sequence\n",
    "import numpy as np\n",
    "import abc\n",
    "class ModelWithGlobalTemperature(nn.Module):\n",
    "    \"\"\"\n",
    "    A thin decorator, which wraps a model with temperature scaling\n",
    "    model (nn.Module):\n",
    "        A classification neural network\n",
    "        NB: Output of the neural network should be the classification logits,\n",
    "            NOT the softmax (or log softmax)!\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(ModelWithGlobalTemperature, self).__init__()\n",
    "        self.model = model\n",
    "        self.temperature = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, input,**kwargs):\n",
    "        logits = self.model(input,kwargs)\n",
    "        return self.temperature_scale(logits)\n",
    "\n",
    "    def temperature_scale(self, logits):\n",
    "        \"\"\"\n",
    "        Perform temperature scaling on logits\n",
    "        \"\"\"\n",
    "        # Expand temperature to match the size of logits\n",
    "        temperature = self.temperature.unsqueeze(1).expand(logits.size(0), logits.size(1), logits.size(2))\n",
    "        return logits / temperature\n",
    "    \n",
    "def train_global_T(model, dataloader):\n",
    "        \"\"\"\n",
    "        dataloader: pytorch dataloader\n",
    "            Should be a validation dataloader\n",
    "        \"\"\"\n",
    "        criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        optimizer = optim.Adam([model.temperature], lr=1e-1, weight_decay=0)\n",
    "        #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.1)\n",
    "        epochs = 5\n",
    "\n",
    "        train_losses = []\n",
    "        model.train()\n",
    "        for e in range(epochs):\n",
    "            total_seqs = []\n",
    "            total_loss = []\n",
    "            for batch in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                history_sequences, target_sequences = batch['train_sequences'],batch['target_sequences']\n",
    "\n",
    "                inputs = history_sequences['sequence']\n",
    "                outs = model(inputs,mc_dropout=True)\n",
    "\n",
    "                loss = criterion(outs, target_sequences['sequence'])\n",
    "\n",
    "                # zero-out positions of the loss corresponding to padded inputs\n",
    "                # if a sequence has all zeros it is considered to be a padding.\n",
    "                # Comment: safer way to do this would be a solution using the lengths...\n",
    "                sequences,lengths = pad_packed_sequence(inputs,batch_first=True)\n",
    "                mask = ~sequences.any(dim=2).unsqueeze(2).repeat(1,1,sequences.shape[-1])\n",
    "\n",
    "                loss.masked_fill_(mask, 0)\n",
    "\n",
    "                loss = loss.sum() / (lengths.sum()*sequences.shape[-1])\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss.append(loss.item())\n",
    "\n",
    "            epoch_train_loss = np.mean(total_loss)\n",
    "\n",
    "            #lr_scheduler.step(epoch_train_loss)\n",
    "\n",
    "            print(\"Epoch {:2d}, lr: {:.4f}, loss: {:.4f}, T: {:.4f}\"\n",
    "                  .format(e,\n",
    "                          optimizer.param_groups[0]['lr'],\n",
    "                          epoch_train_loss,\n",
    "                          model.temperature.item()\n",
    "                          ))\n",
    "            \n",
    "            \n",
    "# define new model with added global temperature scaling\n",
    "model_global_temperature = ModelWithGlobalTemperature(model)\n",
    "# train temperature\n",
    "train_global_T(model_global_temperature,val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c298a-5dcb-4add-9892-7017d7a1db85",
   "metadata": {},
   "source": [
    "## Specific Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fbbfe7af-4bbe-4ca0-aa38-5bdc3fb5d115",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(2,3,3,requires_grad=True)\n",
    "mask = torch.zeros(2,3,3,requires_grad=False)\n",
    "mask[0,0,1] = 1\n",
    "res = a * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2a756a10-bc90-4a6b-a954-1279bd35bfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_st.temperature.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5961193-b60e-4290-8aad-c8cc4e581c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0, lr: 0.0050, loss: 0.2449, T: 0.9786\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1760132/732006143.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mmodel_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelWithSpecificTemperature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# train temperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mtrain_specific_temperature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_st\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1760132/732006143.py\u001b[0m in \u001b[0;36mtrain_specific_temperature\u001b[0;34m(model, dataloader, pos)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence, pack_sequence\n",
    "import numpy as np\n",
    "import abc\n",
    "\n",
    "class ModelWithSpecificTemperature(nn.Module):\n",
    "    \"\"\"\n",
    "    A thin decorator, which wraps a model with temperature scaling\n",
    "    model (nn.Module):\n",
    "        A classification neural network\n",
    "        NB: Output of the neural network should be the classification logits,\n",
    "            NOT the softmax (or log softmax)!\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(ModelWithSpecificTemperature, self).__init__()\n",
    "        self.model = model\n",
    "        self.temperature = nn.Parameter(torch.ones(model.n_labels))\n",
    "\n",
    "    def forward(self, input,**kwargs):\n",
    "        logits = self.model(input,kwargs)\n",
    "        return logits / self.temperature\n",
    "\n",
    "    def temperature_scale(self, logits):\n",
    "        \"\"\"\n",
    "        Perform temperature scaling on logits\n",
    "        \"\"\"\n",
    "        # Expand temperature to match the size of logits\n",
    "        return logits / temperature\n",
    "    \n",
    "    \n",
    "def train_specific_temperature(model, dataloader, pos):\n",
    "        \"\"\"\n",
    "        dataloader: pytorch dataloader\n",
    "            Should be a validation dataloader\n",
    "        \"\"\"\n",
    "        inputs = next(iter(dataloader))['train_sequences']['sequence']\n",
    "        sequences,lengths = pad_packed_sequence(inputs,batch_first=True)\n",
    "        mask_diagnostic = torch.zeros(sequences.shape)\n",
    "        mask_diagnostic[:,:,pos] = 1\n",
    "        mask_diagnostic = mask_diagnostic == 0 # True when value is 0\n",
    "        del inputs,sequences,lengths\n",
    "        \n",
    "        criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        optimizer = optim.Adam([model.temperature], lr=5e-3)\n",
    "        #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.1)\n",
    "        epochs = 5\n",
    "\n",
    "        train_losses = []\n",
    "        model.train()\n",
    "        for e in range(epochs):\n",
    "            total_seqs = []\n",
    "            total_loss = []\n",
    "            for batch in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                history_sequences, target_sequences = batch['train_sequences'],batch['target_sequences']\n",
    "\n",
    "                inputs = history_sequences['sequence']\n",
    "                outs = model(inputs,mc_dropout=True)\n",
    "\n",
    "                loss = criterion(outs, target_sequences['sequence'])\n",
    "\n",
    "                # zero-out positions of the loss corresponding to padded inputs\n",
    "                # if a sequence has all zeros it is considered to be a padding.\n",
    "                # Comment: safer way to do this would be a solution using the lengths...\n",
    "                sequences,lengths = pad_packed_sequence(inputs,batch_first=True)\n",
    "                mask = ~sequences.any(dim=2).unsqueeze(2).repeat(1,1,sequences.shape[-1])\n",
    "\n",
    "                loss.masked_fill_(mask, 0)\n",
    "                \n",
    "                # now mask out all the diagnoses except the one\n",
    "                mask_diagnostic = torch.zeros(outs.shape)\n",
    "                mask_diagnostic[:,:,pos] = 1\n",
    "                mask_diagnostic = mask_diagnostic == 0 # True when value is 0\n",
    "                loss.masked_fill_(mask_diagnostic,0)\n",
    "\n",
    "                \n",
    "                loss = loss.sum() / (lengths.sum()+loss.shape[0])\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss.append(loss.item())\n",
    "\n",
    "            epoch_train_loss = np.mean(total_loss)\n",
    "\n",
    "            #lr_scheduler.step(epoch_train_loss)\n",
    "\n",
    "            print(\"Epoch {:2d}, lr: {:.4f}, loss: {:.4f}, T: {:.4f}\"\n",
    "                  .format(e,\n",
    "                          optimizer.param_groups[0]['lr'],\n",
    "                          epoch_train_loss,\n",
    "                          model.temperature[pos].item()\n",
    "                          ))\n",
    "            \n",
    "            \n",
    "# define new model with added global temperature scaling\n",
    "model_st = ModelWithSpecificTemperature(model)\n",
    "# train temperature\n",
    "train_specific_temperature(model_st,val_dataloader,88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25b9f7ab-d957-4df1-bc7a-823a991b2fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0334, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.sum() / (lengths.sum()+loss.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "831dc7f2-5e40-44f8-9944-4eb447899a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1,  1,  1, 33,  3,  1,  1,  1,  4,  1,  1,  1,  2,  1,  1,  1,\n",
       "         1,  1,  1,  1,  5,  3,  1,  2,  1,  2,  3,  1,  1,  3,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  2,  1,  2,  2,  1,  1,  1,  1,  4,  1,  3,  1,  1,  1,\n",
       "         2,  1,  1,  2,  6,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6876914-fc61-4e14-b8b0-2743db53d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_st = ModelWithSpecificTemperature(model)\n",
    "for batch in val_dataloader:\n",
    "    inputs = batch['train_sequences']['sequence']\n",
    "    sequences,lengths = pad_packed_sequence(inputs,batch_first=True)\n",
    "    a = sequences.any(dim=2).unsqueeze(2).repeat(1,1,sequences.shape[-1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91e7aede-495f-4094-804d-de0bab8fc408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c277298b-2198-4221-bc8c-ec9e8ff6abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_global_temperature = ModelWithGlobalTemperature(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6be884cb-be03-48c0-aea2-cf243b04c229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0, lr: 0.1000, loss: 0.1113, T: 1.0640\n",
      "Epoch  1, lr: 0.1000, loss: 0.1112, T: 1.0830\n",
      "Epoch  2, lr: 0.1000, loss: 0.1114, T: 1.0791\n",
      "Epoch  3, lr: 0.1000, loss: 0.1112, T: 1.0853\n",
      "Epoch  4, lr: 0.1000, loss: 0.1112, T: 1.0812\n",
      "Epoch  5, lr: 0.1000, loss: 0.1113, T: 1.0858\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1756072/3413411970.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_global_T\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_global_temperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1756072/3863738220.py\u001b[0m in \u001b[0;36mtrain_global_T\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_global_T(model_global_temperature,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b308b50b-e7ac-4f64-a83b-5478128c26db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c59fa1-e6d3-4727-95a5-41db8983c192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence, pack_sequence\n",
    "import numpy as np\n",
    "\n",
    "def train_temperature_global_T(model, dataloader):\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "    optimizer = optim.Adam([model.T], lr=1e-1, weight_decay=0)\n",
    "    #lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.1)\n",
    "    epochs = 30\n",
    "    \n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    for e in range(epochs):\n",
    "        total_seqs = []\n",
    "        total_loss = []\n",
    "        for batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            history_sequences, target_sequences = batch['train_sequences'],batch['target_sequences']\n",
    "\n",
    "            inputs = history_sequences['sequence']\n",
    "            outs = model(inputs,mc_dropout=True)\n",
    "\n",
    "            loss = criterion(outs, target_sequences['sequence'])\n",
    "            \n",
    "            # zero-out positions of the loss corresponding to padded inputs\n",
    "            # if a sequence has all zeros it is considered to be a padding.\n",
    "            # Comment: safer way to do this would be a solution using the lengths...\n",
    "            sequences,lengths = pad_packed_sequence(inputs,batch_first=True)\n",
    "            mask = ~sequences.any(dim=2).unsqueeze(2).repeat(1,1,sequences.shape[-1])\n",
    "            \n",
    "            loss.masked_fill_(mask, 0)\n",
    "        \n",
    "            loss = loss.sum() / (lengths.sum()*sequences.shape[-1])\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss.append(loss.item())\n",
    "            \n",
    "        epoch_train_loss = np.mean(total_loss)\n",
    "        \n",
    "        #lr_scheduler.step(epoch_train_loss)\n",
    "        \n",
    "        print(\"Epoch {:2d}, lr: {:.4f}, loss: {:.4f}, T: {:.4f}\"\n",
    "              .format(e,\n",
    "                      optimizer.param_groups[0]['lr'],\n",
    "                      epoch_train_loss,\n",
    "                      model.T.item()\n",
    "                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aa5ca63-0a2d-4f96-8cdc-c1a1ea1eed9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0, lr: 0.1000, loss: 0.1113, T: 1.0523\n",
      "Epoch  1, lr: 0.1000, loss: 0.1112, T: 1.0937\n",
      "Epoch  2, lr: 0.1000, loss: 0.1114, T: 1.0761\n",
      "Epoch  3, lr: 0.1000, loss: 0.1112, T: 1.0811\n",
      "Epoch  4, lr: 0.1000, loss: 0.1112, T: 1.0729\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1755818/907385208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_temperature_global_T\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1755818/2351752286.py\u001b[0m in \u001b[0;36mtrain_temperature_global_T\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmc_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/master-thesis/mourga_variational/variational_rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, mc_dropout, temperature_scaling)\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlockdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropouto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/thesis/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_temperature_global_T(model,val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d7843-fe72-4b6d-974b-056d1b7592a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_temperature(model,val_dataloader):\n",
    "    \n",
    "    T = torch.Varia\n",
    "    \n",
    "\n",
    "for batch in val_dataloader:\n",
    "    inputs = batch['train_sequences']['sequence']\n",
    "    model(inputs,mc_dropout=True).shape\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b00d4b-868d-45c5-916d-533401b5a77f",
   "metadata": {},
   "source": [
    "## Wrapper temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ac6a30-f6df-4a67-9633-f80211af3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence, pack_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "45c73643-fd46-47a3-b65e-ff3dcbf2686c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10571006685495377"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "sequences = None\n",
    "total_loss = total_n = 0\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "\n",
    "        inputs = batch['train_sequences']['sequence']\n",
    "\n",
    "        logits = model(inputs)\n",
    "\n",
    "        loss = criterion(logits, batch['target_sequences']['sequence'])\n",
    "\n",
    "        # zero-out positions of the loss corresponding to padded inputs\n",
    "        # if a sequence has all zeros it is considered to be a padding.\n",
    "        # Comment: safer way to do this would be a solution using the lengths...\n",
    "        sequences,lengths = pad_packed_sequence(inputs,batch_first=True)\n",
    "        mask = ~sequences.any(dim=2).unsqueeze(2).repeat(1,1,sequences.shape[-1])\n",
    "        _ = loss.masked_fill_(mask, 0);\n",
    "\n",
    "        total_loss += loss.sum() \n",
    "        total_n += lengths.sum()*sequences.shape[-1]\n",
    "        \n",
    "        \n",
    "        relevant_positions = [[i+idx*max(lengths) for i in range(e)] for idx,e in enumerate(lengths)]\n",
    "        relevant_positions = [item for sublist in relevant_positions for item in sublist]\n",
    "        \n",
    "        logits_flattened = logits.view(1,-1,logits.size()[2]).squeeze(0)\n",
    "            \n",
    "        relevant_logits = logits_flattened[relevant_positions,:]\n",
    "        relevant_sigmoids = torch.sigmoid(relevant_logits).detach().numpy().squeeze()\n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "bce_loss = (total_loss/total_n).item()\n",
    "bce_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45808af1-b583-47e0-82ee-2a04cead8ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2112, 272])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce1c0152-58b2-4a4e-b39d-54cc72c7d9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.8265, -2.2606, -3.2920, -2.2174, -2.3171])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[2,0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0623ef2d-e375-4bdb-8cb8-fe41adf871f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence, pack_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90b1ea8c-ad2d-4c58-b224-f277c9803e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.1894, -4.0555, -4.1948, -4.1926, -4.1396])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0,1,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86260980-9828-46af-8127-6c178d36bc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.2151, -2.1821, -2.6066, -3.3682, -8.2770])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flattened[0,0,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca153fb8-7815-4eee-b951-a51cf06975fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.2151, -2.1821, -2.6066,  ..., -5.6378, -5.9094, -4.4652],\n",
       "         [-8.5842, -3.0011, -2.6911,  ..., -7.6248, -5.6858, -4.9581],\n",
       "         [-6.3826, -2.2121, -3.3051,  ..., -5.5728, -4.4747, -3.1380],\n",
       "         ...,\n",
       "         [-7.7056, -3.8565, -3.5821,  ..., -6.5852, -6.4756, -4.4986],\n",
       "         [-6.9114, -1.7634, -1.7422,  ..., -7.0475, -6.1005, -3.3008],\n",
       "         [-3.6556, -2.4959, -2.9706,  ..., -8.0930, -6.3574, -4.4456]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_logits[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "10f81648-cc1b-4b5e-a911-f992b8bbcd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.2151, -2.1821, -2.6066,  ..., -5.6378, -5.9094, -4.4652],\n",
       "         [-8.5842, -3.0011, -2.6911,  ..., -7.6248, -5.6858, -4.9581],\n",
       "         [-6.3826, -2.2121, -3.3051,  ..., -5.5728, -4.4747, -3.1380],\n",
       "         ...,\n",
       "         [-7.7056, -3.8565, -3.5821,  ..., -6.5852, -6.4756, -4.4986],\n",
       "         [-6.9114, -1.7634, -1.7422,  ..., -7.0475, -6.1005, -3.3008],\n",
       "         [-3.6556, -2.4959, -2.9706,  ..., -8.0930, -6.3574, -4.4456]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "854a2f22-01d5-46b8-8662-f7bb6fa906e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.1440, -2.1221, -2.8844,  ..., -7.5836, -4.8592, -3.2502],\n",
       "        [-5.1509, -0.0974, -1.2883,  ..., -6.9359, -5.3083, -3.4558],\n",
       "        [ 0.6767, -2.0198, -2.8582,  ..., -7.3179, -5.9209, -3.4635],\n",
       "        ...,\n",
       "        [-3.6152, -1.8538, -2.3008,  ..., -9.1104, -5.1172, -3.0493],\n",
       "        [-3.1273, -1.4662, -1.9435,  ..., -9.0815, -5.3970, -2.5897],\n",
       "        [-3.4668, -1.6321, -1.9710,  ..., -9.1904, -5.4358, -2.5226]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "211da2de-3130-46c8-89ff-73abd6d0395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ya = pack_padded_sequence(logits,lengths=lengths,batch_first=True,enforce_sorted=False).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8e778396-47bb-4c5f-94e3-0e2b9f4eb68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithTemperature(nn.Module):\n",
    "    \"\"\"\n",
    "    A thin decorator, which wraps a model with temperature scaling\n",
    "    model (nn.Module):\n",
    "        A classification neural network\n",
    "        NB: Output of the neural network should be the classification logits,\n",
    "            NOT the softmax (or log softmax)!\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        super(ModelWithTemperature, self).__init__()\n",
    "        self.model = model\n",
    "        self.temperature = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        logits = self.model(input)\n",
    "        return self.temperature_scale(logits)\n",
    "\n",
    "    def temperature_scale(self, logits):\n",
    "        \"\"\"\n",
    "        Perform temperature scaling on logits\n",
    "        \"\"\"\n",
    "        # Expand temperature to match the size of logits\n",
    "        temperature = self.temperature.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
    "        return logits / temperature\n",
    "\n",
    "    # This function probably should live outside of this class, but whatever\n",
    "    def set_temperature(self, valid_loader):\n",
    "        \"\"\"\n",
    "        Tune the tempearature of the model (using the validation set).\n",
    "        We're going to set it to optimize NLL.\n",
    "        valid_loader (DataLoader): validation set loader\n",
    "        \"\"\"\n",
    "\n",
    "        bce_criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        ece_criterion = _ECELoss()\n",
    "\n",
    "        # First: collect all the logits and labels for the validation set\n",
    "        before_temperature_bce = list()\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                \n",
    "                history_sequences, target_sequences = batch['train_sequences'],batch['target_sequences']\n",
    "                \n",
    "                logits = self.model(history_sequences['sequence'])\n",
    "                return history_sequenceslogits,target_sequences['sequence']\n",
    "                \n",
    "                before_temperature_bce.append(bce_criterion(logits, target_sequences['sequence']))\n",
    "                return before_temperature_bce\n",
    "        # Calculate NLL and ECE before temperature scaling\n",
    "                before_temperature_nll = nll_criterion(logits, labels).item()\n",
    "        before_temperature_ece = ece_criterion(logits, labels).item()\n",
    "        print('Before temperature - NLL: %.3f, ECE: %.3f' % (before_temperature_nll, before_temperature_ece))\n",
    "\n",
    "        # Next: optimize the temperature w.r.t. NLL\n",
    "        optimizer = optim.LBFGS([self.temperature], lr=0.01, max_iter=50)\n",
    "\n",
    "        def eval():\n",
    "            optimizer.zero_grad()\n",
    "            loss = nll_criterion(self.temperature_scale(logits), labels)\n",
    "            loss.backward()\n",
    "            return loss\n",
    "        optimizer.step(eval)\n",
    "\n",
    "        # Calculate NLL and ECE after temperature scaling\n",
    "        after_temperature_nll = nll_criterion(self.temperature_scale(logits), labels).item()\n",
    "        after_temperature_ece = ece_criterion(self.temperature_scale(logits), labels).item()\n",
    "        print('Optimal temperature: %.3f' % self.temperature.item())\n",
    "        print('After temperature - NLL: %.3f, ECE: %.3f' % (after_temperature_nll, after_temperature_ece))\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "59f9c4eb-9195-4b7c-a55e-8ac164a7d426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 33, 272])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 33, 272])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        inputs = batch['train_sequences']['sequence']\n",
    "        targets = batch['target_sequences']['sequence']\n",
    "        targets[0,15,:].sum()\n",
    "        out = model(inputs)\n",
    "        out.shape\n",
    "        loss = criterion(out,targets)\n",
    "        loss.shape\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d33a1a46-9c6c-46b9-9061-3488b1daf1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1,  1,  1, 33,  3,  1,  1,  1,  4,  1,  1,  1,  2,  1,  1,  1,\n",
       "         1,  1,  1,  1,  5,  3,  1,  2,  1,  2,  3,  1,  1,  3,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  2,  1,  2,  2,  1,  1,  1,  1,  4,  1,  3,  1,  1,  1,\n",
       "         2,  1,  1,  2,  6,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a693faf7-3c38-4242-942d-6ded9fe00855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.any(dim=2).unsqueeze(2).repeat(1,1,272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "34746dc0-7ed6-4fc6-8759-8adeeeaec3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences,lengths = pad_packed_sequence(inputs,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5ae9d95c-0e24-434e-b42b-fb30c0c6b22b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = ~sequences.any(dim=2).unsqueeze(2).repeat(1,1,272) # True when value corresponds to a padding input\n",
    "sequences.masked_fill(mask, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5546ee48-11f7-4502-bd8e-8733cb23225c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 33])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((len(lengths),lengths.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22589679-5f4d-4f2e-84f8-33bd51beed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ad4bb714-7365-4f97-96a1-e78732fc6ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1,  1,  1, 33,  3,  1,  1,  1,  4,  1,  1,  1,  2,  1,  1,  1,\n",
       "         1,  1,  1,  1,  5,  3,  1,  2,  1,  2,  3,  1,  1,  3,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  2,  1,  2,  2,  1,  1,  1,  1,  4,  1,  3,  1,  1,  1,\n",
       "         2,  1,  1,  2,  6,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7ddf203d-b363-4dbe-9064-d466d8440211",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sequence', 'original', 'pids'])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[[121,\n",
       "   153,\n",
       "   99,\n",
       "   100,\n",
       "   129,\n",
       "   101,\n",
       "   4,\n",
       "   106,\n",
       "   108,\n",
       "   49,\n",
       "   29,\n",
       "   113,\n",
       "   53,\n",
       "   54,\n",
       "   249,\n",
       "   59,\n",
       "   157]],\n",
       " [[96, 98, 164, 101, 53, 94]],\n",
       " [[38, 238, 52, 153, 155, 60, 253, 62, 63]],\n",
       " [[96, 98, 163, 7, 106, 205, 117, 55]],\n",
       " [[129, 2, 130, 97, 259, 106, 81, 55, 151, 59, 157]],\n",
       " [[161, 99, 102, 238, 210, 117, 2616, 153, 156, 157],\n",
       "  [97, 99, 210, 83, 59],\n",
       "  [259, 99, 210, 90, 156, 158],\n",
       "  [99, 210, 90, 59, 156, 158],\n",
       "  [97, 2, 99, 4, 257, 200, 91, 237, 238, 210, 90, 59, 158],\n",
       "  [2, 99, 3, 259, 237, 210, 90, 59, 156, 158],\n",
       "  [2, 99, 3, 109, 210, 83, 156, 158],\n",
       "  [97, 99, 259, 91, 210, 62, 59, 156, 158],\n",
       "  [97, 258, 99, 238, 251, 2617, 210, 51, 118, 55, 62, 121, 250, 59, 156, 158],\n",
       "  [257, 99, 259, 58, 167, 210, 55, 118, 95, 62, 90, 59, 156, 158, 159],\n",
       "  [97,\n",
       "   161,\n",
       "   99,\n",
       "   58,\n",
       "   158,\n",
       "   210,\n",
       "   244,\n",
       "   117,\n",
       "   118,\n",
       "   2620,\n",
       "   55,\n",
       "   2617,\n",
       "   250,\n",
       "   59,\n",
       "   156,\n",
       "   62,\n",
       "   159],\n",
       "  [97, 99, 259, 205, 210, 51, 118, 55, 62, 59, 156, 158, 159],\n",
       "  [97, 99, 58, 205, 238, 210, 55, 62, 122, 59, 156, 158],\n",
       "  [257,\n",
       "   259,\n",
       "   133,\n",
       "   138,\n",
       "   151,\n",
       "   155,\n",
       "   156,\n",
       "   158,\n",
       "   51,\n",
       "   55,\n",
       "   59,\n",
       "   62,\n",
       "   200,\n",
       "   210,\n",
       "   83,\n",
       "   97,\n",
       "   99,\n",
       "   102,\n",
       "   103,\n",
       "   246,\n",
       "   118,\n",
       "   250,\n",
       "   251],\n",
       "  [257, 99, 251, 210, 118, 59, 158],\n",
       "  [97, 257, 99, 259, 102, 651, 210, 84, 118, 151, 59, 158],\n",
       "  [99, 259, 238, 47, 251, 210, 118, 62, 154, 59, 156, 158, 95],\n",
       "  [97, 257, 99, 259, 59, 2616, 237, 657, 210, 118, 55, 62, 2617, 251, 158],\n",
       "  [97, 257, 99, 259, 251, 657, 210, 244, 118, 62, 2617, 59, 158],\n",
       "  [97, 257, 99, 238, 210, 118, 55, 158],\n",
       "  [97, 99, 238, 210, 118, 158],\n",
       "  [97, 257, 99, 259, 657, 210, 211, 117, 118, 62, 59, 156, 158],\n",
       "  [97,\n",
       "   257,\n",
       "   99,\n",
       "   259,\n",
       "   238,\n",
       "   657,\n",
       "   210,\n",
       "   211,\n",
       "   117,\n",
       "   661,\n",
       "   55,\n",
       "   62,\n",
       "   2613,\n",
       "   118,\n",
       "   59,\n",
       "   156,\n",
       "   158],\n",
       "  [257,\n",
       "   2,\n",
       "   3,\n",
       "   259,\n",
       "   156,\n",
       "   158,\n",
       "   159,\n",
       "   55,\n",
       "   2616,\n",
       "   59,\n",
       "   62,\n",
       "   210,\n",
       "   95,\n",
       "   97,\n",
       "   99,\n",
       "   102,\n",
       "   237,\n",
       "   118,\n",
       "   121,\n",
       "   251],\n",
       "  [97, 257, 99, 259, 251, 210, 55, 59, 156, 158, 95],\n",
       "  [97, 257, 99, 259, 59, 10, 210, 114, 118, 55, 62, 90, 251, 156, 158],\n",
       "  [97,\n",
       "   257,\n",
       "   99,\n",
       "   58,\n",
       "   259,\n",
       "   59,\n",
       "   10,\n",
       "   251,\n",
       "   210,\n",
       "   117,\n",
       "   55,\n",
       "   62,\n",
       "   250,\n",
       "   155,\n",
       "   156,\n",
       "   158,\n",
       "   95],\n",
       "  [257,\n",
       "   259,\n",
       "   10,\n",
       "   143,\n",
       "   145,\n",
       "   153,\n",
       "   156,\n",
       "   158,\n",
       "   55,\n",
       "   58,\n",
       "   59,\n",
       "   60,\n",
       "   62,\n",
       "   210,\n",
       "   95,\n",
       "   97,\n",
       "   99,\n",
       "   117,\n",
       "   251],\n",
       "  [97, 99, 139, 251, 657, 210, 83, 117, 118, 55, 59, 158, 95],\n",
       "  [97,\n",
       "   257,\n",
       "   99,\n",
       "   259,\n",
       "   59,\n",
       "   250,\n",
       "   139,\n",
       "   210,\n",
       "   83,\n",
       "   117,\n",
       "   118,\n",
       "   62,\n",
       "   90,\n",
       "   251,\n",
       "   156,\n",
       "   158,\n",
       "   95],\n",
       "  [97,\n",
       "   257,\n",
       "   99,\n",
       "   259,\n",
       "   139,\n",
       "   251,\n",
       "   210,\n",
       "   83,\n",
       "   117,\n",
       "   118,\n",
       "   151,\n",
       "   62,\n",
       "   90,\n",
       "   59,\n",
       "   156,\n",
       "   158,\n",
       "   95],\n",
       "  [257,\n",
       "   2,\n",
       "   3,\n",
       "   259,\n",
       "   133,\n",
       "   134,\n",
       "   139,\n",
       "   151,\n",
       "   156,\n",
       "   158,\n",
       "   55,\n",
       "   2616,\n",
       "   59,\n",
       "   2620,\n",
       "   62,\n",
       "   210,\n",
       "   83,\n",
       "   95,\n",
       "   97,\n",
       "   99,\n",
       "   237,\n",
       "   117,\n",
       "   118,\n",
       "   121,\n",
       "   251],\n",
       "  [257,\n",
       "   259,\n",
       "   138,\n",
       "   139,\n",
       "   657,\n",
       "   151,\n",
       "   156,\n",
       "   158,\n",
       "   175,\n",
       "   59,\n",
       "   62,\n",
       "   210,\n",
       "   83,\n",
       "   212,\n",
       "   95,\n",
       "   97,\n",
       "   99,\n",
       "   117,\n",
       "   118,\n",
       "   121,\n",
       "   251]],\n",
       " [[128, 98, 101, 109, 110, 238, 53],\n",
       "  [98, 101, 6, 237, 115, 117, 53, 122, 127],\n",
       "  [99, 3, 8, 106, 238, 114, 29, 19, 54, 127, 157, 158, 159]],\n",
       " [[96, 98, 100, 101, 108, 237, 49, 59]],\n",
       " [[226, 98, 102, 106, 2603, 52, 55, 157]],\n",
       " [[100, 138, 651, 117, 122, 59, 157, 158, 127]],\n",
       " [[2, 237, 206, 238, 205, 244, 26, 159],\n",
       "  [2, 231, 238, 206, 48, 211, 244, 55, 249, 26, 59, 157, 159],\n",
       "  [259,\n",
       "   135,\n",
       "   657,\n",
       "   147,\n",
       "   153,\n",
       "   26,\n",
       "   155,\n",
       "   158,\n",
       "   161,\n",
       "   162,\n",
       "   163,\n",
       "   175,\n",
       "   48,\n",
       "   55,\n",
       "   206,\n",
       "   211,\n",
       "   84,\n",
       "   95,\n",
       "   101,\n",
       "   238,\n",
       "   251],\n",
       "  [2,\n",
       "   259,\n",
       "   133,\n",
       "   657,\n",
       "   148,\n",
       "   151,\n",
       "   663,\n",
       "   26,\n",
       "   155,\n",
       "   158,\n",
       "   159,\n",
       "   161,\n",
       "   48,\n",
       "   53,\n",
       "   55,\n",
       "   2616,\n",
       "   2617,\n",
       "   59,\n",
       "   206,\n",
       "   84,\n",
       "   99,\n",
       "   101,\n",
       "   238,\n",
       "   244,\n",
       "   118]],\n",
       " [[96, 97, 98, 2616, 237, 49, 53, 125, 55, 152, 157, 159]],\n",
       " [[96, 2, 131, 98, 149]],\n",
       " [[259, 35, 230, 81, 243, 2613, 2620, 95]],\n",
       " [[32, 226, 98, 100, 101, 103, 2603, 206, 79, 55, 2621],\n",
       "  [96, 32, 2, 98, 100, 101, 108, 206, 79, 55, 159]],\n",
       " [[130,\n",
       "   259,\n",
       "   657,\n",
       "   663,\n",
       "   158,\n",
       "   48,\n",
       "   53,\n",
       "   2616,\n",
       "   97,\n",
       "   99,\n",
       "   100,\n",
       "   101,\n",
       "   108,\n",
       "   237,\n",
       "   238,\n",
       "   113,\n",
       "   114,\n",
       "   115,\n",
       "   245,\n",
       "   122]],\n",
       " [[2, 131, 233, 2603, 81, 146, 148, 52, 118]],\n",
       " [[130, 2, 197, 103, 199, 108, 118, 157, 127]],\n",
       " [[106, 59, 205, 238]],\n",
       " [[106, 108, 47, 50, 117, 55, 153, 157]],\n",
       " [[96, 64, 98, 259, 164, 257, 106, 48]],\n",
       " [[257, 98, 259, 140, 109, 238, 653, 83, 148, 149, 55, 152, 58, 247, 62]],\n",
       " [[128, 97, 130, 98, 1, 118, 55],\n",
       "  [128, 97, 98, 42, 138, 43, 238, 118, 2616],\n",
       "  [98, 42, 43, 2617, 155],\n",
       "  [159, 97, 128, 98, 42, 43, 118, 63],\n",
       "  [128, 97, 98, 131, 106, 42, 43, 122]],\n",
       " [[96, 257, 131, 133, 134, 108, 48, 24, 60, 127],\n",
       "  [64, 257, 96, 131, 99, 133, 134, 105, 106, 108, 155, 53, 59, 158, 127],\n",
       "  [257,\n",
       "   131,\n",
       "   259,\n",
       "   133,\n",
       "   134,\n",
       "   135,\n",
       "   138,\n",
       "   663,\n",
       "   24,\n",
       "   153,\n",
       "   157,\n",
       "   158,\n",
       "   44,\n",
       "   47,\n",
       "   48,\n",
       "   53,\n",
       "   55,\n",
       "   2615,\n",
       "   2617,\n",
       "   59,\n",
       "   60,\n",
       "   205,\n",
       "   93,\n",
       "   94,\n",
       "   96,\n",
       "   99,\n",
       "   105,\n",
       "   106,\n",
       "   108,\n",
       "   244,\n",
       "   122,\n",
       "   127]],\n",
       " [[96, 97, 130, 131, 100, 101, 98, 257, 259, 106, 108, 50, 18, 53, 152, 158]],\n",
       " [[131, 6, 138, 237, 238, 2617, 81, 83, 116, 85, 55, 151, 661, 149, 51, 60],\n",
       "  [103, 651, 237, 81, 49, 83, 661, 246, 59]],\n",
       " [[131, 100, 108, 237, 50, 249, 122, 157, 159]],\n",
       " [[99, 237, 83, 53, 59, 157, 159], [98, 7, 137, 237, 59, 157]],\n",
       " [[98, 131, 100, 83, 117, 55, 122, 59, 127],\n",
       "  [98, 131, 101, 83, 663, 59, 95, 127],\n",
       "  [98, 131, 101, 133, 83, 59, 127]],\n",
       " [[2, 131, 42, 13, 238, 145, 62]],\n",
       " [[237, 98, 53, 101]],\n",
       " [[130, 105, 106, 108, 238, 145, 19, 55, 151, 157, 127],\n",
       "  [121, 130, 131, 98, 101, 105, 108, 238, 19, 118, 153, 122, 59, 127],\n",
       "  [129, 2, 131, 100, 97, 101, 105, 108, 19, 249, 59, 157, 95, 127]],\n",
       " [[224, 256, 10, 218, 222]],\n",
       " [[96, 106, 237, 98]],\n",
       " [[128, 257, 98, 131, 5, 6, 238, 50, 83, 52, 55, 151, 2617, 59, 156, 62]],\n",
       " [[33, 42, 83]],\n",
       " [[96, 3, 101, 106, 108, 114, 159]],\n",
       " [[131, 99, 6, 76, 109, 237, 47, 81, 49, 83, 118, 60, 157, 158, 95]],\n",
       " [[256, 10, 218, 219, 221]],\n",
       " [[96, 128, 100, 101, 138, 140, 204, 48, 58, 93]],\n",
       " [[98, 100, 101, 108, 53], [104, 98, 96, 101]],\n",
       " [[2, 99, 237, 660, 54, 62, 59, 158, 127]],\n",
       " [[81, 42, 15], [98, 259, 42, 109, 15, 83, 51, 2617, 95]],\n",
       " [[256, 98, 131, 115, 660, 54, 663, 29],\n",
       "  [129,\n",
       "   2,\n",
       "   257,\n",
       "   259,\n",
       "   145,\n",
       "   156,\n",
       "   29,\n",
       "   157,\n",
       "   159,\n",
       "   50,\n",
       "   54,\n",
       "   199,\n",
       "   99,\n",
       "   106,\n",
       "   108,\n",
       "   238,\n",
       "   115,\n",
       "   116,\n",
       "   248,\n",
       "   122]],\n",
       " [[130, 105, 106, 238, 113, 114, 19, 2616, 89, 127]],\n",
       " [[131, 101, 48, 55, 127]],\n",
       " [[82, 164, 109]],\n",
       " [[130, 98, 103, 106, 12, 238, 53, 663]],\n",
       " [[96, 101, 105, 106, 108, 53],\n",
       "  [161, 99, 104, 141, 657, 55, 2617, 59, 62],\n",
       "  [96, 101, 106, 108, 141, 55, 155],\n",
       "  [99, 101, 105, 106, 108, 55, 155, 60]],\n",
       " [[99, 6, 106, 237, 238, 50, 151, 62]],\n",
       " [[131, 134, 19, 53, 55, 122, 157, 158, 127],\n",
       "  [128, 161, 130, 131, 98, 19, 244, 55, 157],\n",
       "  [129, 2, 131, 1, 108, 19, 52, 125, 55, 249, 122, 59, 157, 95, 127]],\n",
       " [[129, 2, 153, 131, 98, 12, 54, 55, 22, 249, 60, 157]],\n",
       " [[2, 135, 660, 149, 661, 55, 249, 157, 62]],\n",
       " [[98, 259, 42, 238, 18, 54, 2616, 157, 127]],\n",
       " [[129, 98, 131, 135, 141, 52, 53, 122, 155], [98, 134, 137, 657, 53, 59]],\n",
       " [[122, 227, 131, 2607]],\n",
       " [[2, 237, 50, 87, 248, 158, 95]],\n",
       " [[98, 101, 106, 238, 49, 53, 127], [130, 98, 101, 238, 48, 49, 53]],\n",
       " [[2, 131, 197, 135, 106, 108, 141, 49, 122],\n",
       "  [128, 2, 259, 4, 197, 101, 199, 50, 58],\n",
       "  [257, 98, 131, 3, 58, 108, 237, 50, 148, 149, 122, 155, 156, 95, 127],\n",
       "  [257,\n",
       "   3,\n",
       "   4,\n",
       "   259,\n",
       "   134,\n",
       "   657,\n",
       "   661,\n",
       "   155,\n",
       "   156,\n",
       "   157,\n",
       "   159,\n",
       "   163,\n",
       "   50,\n",
       "   58,\n",
       "   59,\n",
       "   211,\n",
       "   87,\n",
       "   95,\n",
       "   98,\n",
       "   108,\n",
       "   237,\n",
       "   117,\n",
       "   127],\n",
       "  [129,\n",
       "   2,\n",
       "   131,\n",
       "   259,\n",
       "   3,\n",
       "   133,\n",
       "   257,\n",
       "   651,\n",
       "   141,\n",
       "   155,\n",
       "   157,\n",
       "   159,\n",
       "   50,\n",
       "   51,\n",
       "   55,\n",
       "   58,\n",
       "   59,\n",
       "   197,\n",
       "   203,\n",
       "   204,\n",
       "   211,\n",
       "   98,\n",
       "   108,\n",
       "   238,\n",
       "   114,\n",
       "   244,\n",
       "   117,\n",
       "   122,\n",
       "   127],\n",
       "  [2,\n",
       "   131,\n",
       "   259,\n",
       "   134,\n",
       "   156,\n",
       "   157,\n",
       "   158,\n",
       "   159,\n",
       "   50,\n",
       "   58,\n",
       "   59,\n",
       "   197,\n",
       "   211,\n",
       "   87,\n",
       "   95,\n",
       "   108,\n",
       "   237,\n",
       "   122,\n",
       "   127]],\n",
       " [[98, 101, 138, 238, 49, 159]],\n",
       " [[130, 131, 108, 238, 118, 55, 122, 157]],\n",
       " [[217, 218]],\n",
       " [[129,\n",
       "   130,\n",
       "   2,\n",
       "   98,\n",
       "   259,\n",
       "   101,\n",
       "   3,\n",
       "   108,\n",
       "   109,\n",
       "   110,\n",
       "   48,\n",
       "   81,\n",
       "   50,\n",
       "   149,\n",
       "   118,\n",
       "   122,\n",
       "   95]],\n",
       " [[98, 100, 101, 5, 108, 663, 127]]]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['train_sequences'].keys()\n",
    "batch['train_sequences']['original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8233c71c-a751-4acf-b90f-d96024b43c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.masked_fill_(mask, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6b518938-6df8-40b6-9071-cb99b256c724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  1,  1,  1, 33,  3,  1,  1,  1,  4,  1,  1,  1,  2,  1,  1,  1,\n",
       "         1,  1,  1,  1,  5,  3,  1,  2,  1,  2,  3,  1,  1,  3,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  2,  1,  2,  2,  1,  1,  1,  1,  4,  1,  3,  1,  1,  1,\n",
       "         2,  1,  1,  2,  6,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "417870fe-8b6f-4e9a-9a44-34e7780febd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 1., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " tensor([ 1,  1,  1,  1,  1, 33,  3,  1,  1,  1,  4,  1,  1,  1,  2,  1,  1,  1,\n",
       "          1,  1,  1,  1,  5,  3,  1,  2,  1,  2,  3,  1,  1,  3,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  2,  1,  2,  2,  1,  1,  1,  1,  4,  1,  3,  1,  1,  1,\n",
       "          2,  1,  1,  2,  6,  1,  1,  1,  1,  1]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_packed_sequence(inputs,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "08482993-5a7b-4ca7-a927-c4b279ce22aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0150, 0.0172, 0.0150, 0.0150, 0.0158])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0150, 0.0172, 0.0150, 0.0150, 0.0158])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[0,1,:5]\n",
    "loss[0,2,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c0cd0d6e-a60a-4909-9a92-6e860510a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w_temperature = ModelWithTemperature(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "86e35264-0461-4e09-948d-3972f13bbe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1,res2 = model_w_temperature.set_temperature(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ec89e5a1-9778-4396-9ed1-65999dbfd3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 33, 272])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4c08bfc-e326-41b3-9ef4-d1b256faf1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0150, 0.0172, 0.0150, 0.0150, 0.0158, 0.0161, 0.0157, 0.0142, 0.0152,\n",
       "        0.0158, 0.0158, 0.0153, 0.0157, 0.0145, 0.0152, 0.0143, 0.0147, 0.0154,\n",
       "        0.0145, 0.0153, 0.0159, 0.0155, 0.0146, 0.0146, 0.0143, 0.0149, 0.0143,\n",
       "        0.0141, 0.0153, 0.0148, 0.0142, 0.0163, 0.0152, 0.0145, 0.0153, 0.0159,\n",
       "        0.0151, 0.0142, 0.0156, 0.0146, 0.0147, 0.0157, 0.0141, 0.0159, 0.0149,\n",
       "        0.0141, 0.0149, 0.0162, 0.0157, 0.0161, 0.0160, 0.0162, 0.0156, 0.0142,\n",
       "        0.0165, 0.0156, 0.0161, 0.0172, 0.0157, 0.0145, 0.0153, 0.0157, 0.0145,\n",
       "        0.0160, 0.0150, 0.0161, 0.0144, 0.0150, 0.0150, 0.0144, 0.0146, 0.0153,\n",
       "        0.0147, 0.0144, 0.0147, 0.0153, 0.0146, 0.0143, 0.0161, 0.0142, 0.0145,\n",
       "        0.0153, 0.0170, 0.0165, 0.0147, 0.0158, 0.0162, 0.0158, 0.0153, 0.0158,\n",
       "        0.0149, 0.0154, 0.0146, 0.0166, 0.0148, 0.0162, 0.0150, 0.0161, 0.0146,\n",
       "        0.0153, 0.0154, 0.0149, 0.0161, 0.0152, 0.0153, 0.0148, 0.0145, 0.0145,\n",
       "        0.0141, 0.0156, 0.0147, 0.0148, 0.0158, 0.0148, 0.0154, 0.0152, 0.0151,\n",
       "        0.0154, 0.0162, 0.0158, 0.0163, 0.0149, 0.0147, 0.0155, 0.0165, 0.0162,\n",
       "        0.0143, 0.0154, 0.0146, 0.0150, 0.0153, 0.0145, 0.0155, 0.0150, 0.0156,\n",
       "        0.0152, 0.0153, 0.0157, 0.0146, 0.0160, 0.0155, 0.0154, 0.0149, 0.0170,\n",
       "        0.0147, 0.0154, 0.0154, 0.0144, 0.0158, 0.0156, 0.0146, 0.0150, 0.0142,\n",
       "        0.0152, 0.0162, 0.0153, 0.0153, 0.0159, 0.0149, 0.0145, 0.0148, 0.0150,\n",
       "        0.0145, 0.0145, 0.0158, 0.0161, 0.0158, 0.0149, 0.0150, 0.0146, 0.0151,\n",
       "        0.0149, 0.0145, 0.0152, 0.0142, 0.0148, 0.0159, 0.0160, 0.0163, 0.0146,\n",
       "        0.0158, 0.0156, 0.0147, 0.0148, 0.0153, 0.0159, 0.0151, 0.0145, 0.0168,\n",
       "        0.0161, 0.0156, 0.0144, 0.0142, 0.0147, 0.0154, 0.0155, 0.0154, 0.0150,\n",
       "        0.0157, 0.0158, 0.0161, 0.0152, 0.0150, 0.0141, 0.0146, 0.0154, 0.0157,\n",
       "        0.0153, 0.0146, 0.0159, 0.0149, 0.0149, 0.0142, 0.0151, 0.0157, 0.0169,\n",
       "        0.0149, 0.0146, 0.0150, 0.0163, 0.0156, 0.0155, 0.0156, 0.0159, 0.0158,\n",
       "        0.0146, 0.0152, 0.0144, 0.0157, 0.0144, 0.0158, 0.0156, 0.0151, 0.0156,\n",
       "        0.0160, 0.0169, 0.0160, 0.0149, 0.0151, 0.0148, 0.0154, 0.0148, 0.0154,\n",
       "        0.0157, 0.0159, 0.0156, 0.0159, 0.0160, 0.0143, 0.0155, 0.0151, 0.0146,\n",
       "        0.0144, 0.0162, 0.0156, 0.0149, 0.0156, 0.0157, 0.0152, 0.0145, 0.0145,\n",
       "        0.0144, 0.0158, 0.0143, 0.0148, 0.0158, 0.0160, 0.0152, 0.0154, 0.0157,\n",
       "        0.0149, 0.0163])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][6,30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c63eabad-5174-48e5-ae03-fd1fda21fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(val_dataloader)\n",
    "batch1 = next(a)\n",
    "batch2 = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fef648d7-6ff0-4627-a7b6-e101d5aac3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), batch_sizes=tensor([64, 18, 10,  5,  3,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]), sorted_indices=tensor([ 5, 58, 22, 48, 10, 23,  6, 50, 31, 28, 43, 25, 27, 14, 54, 57, 42, 40,\n",
       "        44, 38, 45, 41, 39, 32, 46, 47, 49, 51, 52, 53, 55, 56, 59, 60, 61, 62,\n",
       "        63, 18,  1,  2,  3,  4,  7,  8,  9, 11, 12, 13, 15, 16, 17, 37, 19, 20,\n",
       "        21, 24, 26, 29, 30,  0, 33, 34, 35, 36]), unsorted_indices=tensor([59, 38, 39, 40, 41,  0,  6, 42, 43, 44,  4, 45, 46, 47, 13, 48, 49, 50,\n",
       "        37, 52, 53, 54,  2,  5, 55, 11, 56, 12,  9, 57, 58,  8, 23, 60, 61, 62,\n",
       "        63, 51, 19, 22, 17, 21, 16, 10, 18, 20, 24, 25,  3, 26,  7, 27, 28, 29,\n",
       "        14, 30, 31, 15,  1, 32, 33, 34, 35, 36]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch1['train_sequences']['sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "007001c6-2c9a-41f5-9f5a-fe79f6b8f71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_sequences', 'target_sequences', 'train_pids', 'target_pids'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7e17ebc-d642-4e10-be65-146825ad51cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sequence', 'original', 'pids'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['train_sequences'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9da77c67-f2be-4b8c-80e5-0f47ffdea9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'109'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['train_sequences']['pids'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7f36189-10cc-4a04-9c16-f2fbe7c0c6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.8721, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894,\n",
       "        -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894,\n",
       "        -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894,\n",
       "        -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894, -4.1894,\n",
       "        -4.1894])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_list[0][0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8c8de76-1fe1-4cef-8795-52769c668c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 33, 272])\n",
      "torch.Size([64, 11, 272])\n",
      "torch.Size([64, 7, 272])\n"
     ]
    }
   ],
   "source": [
    "print(logits_list[0].shape)\n",
    "print(logits_list[1].shape)\n",
    "print(logits_list[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c53217c-3344-4fc4-a821-e6c263ad515f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "im out\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 33 but got size 11 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_934048/359664660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#labels_list.append(label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'im out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#labels = torch.cat(labels_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 33 but got size 11 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "logits_list = list()\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        print('hi')\n",
    "        input = batch['train_sequences']['sequence']\n",
    "        logits = model(input)#logits = self.model(input)\n",
    "        logits_list.append(logits)\n",
    "        #labels_list.append(label)\n",
    "    print('im out')\n",
    "    logits = torch.cat(logits_list)\n",
    "    #labels = torch.cat(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2afb7e11-6a11-46ca-aed0-575a02088885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_sequences': {'sequence': PackedSequence(data=tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 1.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), batch_sizes=tensor([64, 18, 10,  5,  3,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]), sorted_indices=tensor([ 5, 58, 22, 48, 10, 23,  6, 50, 31, 28, 43, 25, 27, 14, 54, 57, 42, 40,\n",
      "        44, 38, 45, 41, 39, 32, 46, 47, 49, 51, 52, 53, 55, 56, 59, 60, 61, 62,\n",
      "        63, 18,  1,  2,  3,  4,  7,  8,  9, 11, 12, 13, 15, 16, 17, 37, 19, 20,\n",
      "        21, 24, 26, 29, 30,  0, 33, 34, 35, 36]), unsorted_indices=tensor([59, 38, 39, 40, 41,  0,  6, 42, 43, 44,  4, 45, 46, 47, 13, 48, 49, 50,\n",
      "        37, 52, 53, 54,  2,  5, 55, 11, 56, 12,  9, 57, 58,  8, 23, 60, 61, 62,\n",
      "        63, 51, 19, 22, 17, 21, 16, 10, 18, 20, 24, 25,  3, 26,  7, 27, 28, 29,\n",
      "        14, 30, 31, 15,  1, 32, 33, 34, 35, 36])), 'original': [[[121, 153, 99, 100, 129, 101, 4, 106, 108, 49, 29, 113, 53, 54, 249, 59, 157]], [[96, 98, 164, 101, 53, 94]], [[38, 238, 52, 153, 155, 60, 253, 62, 63]], [[96, 98, 163, 7, 106, 205, 117, 55]], [[129, 2, 130, 97, 259, 106, 81, 55, 151, 59, 157]], [[161, 99, 102, 238, 210, 117, 2616, 153, 156, 157], [97, 99, 210, 83, 59], [259, 99, 210, 90, 156, 158], [99, 210, 90, 59, 156, 158], [97, 2, 99, 4, 257, 200, 91, 237, 238, 210, 90, 59, 158], [2, 99, 3, 259, 237, 210, 90, 59, 156, 158], [2, 99, 3, 109, 210, 83, 156, 158], [97, 99, 259, 91, 210, 62, 59, 156, 158], [97, 258, 99, 238, 251, 2617, 210, 51, 118, 55, 62, 121, 250, 59, 156, 158], [257, 99, 259, 58, 167, 210, 55, 118, 95, 62, 90, 59, 156, 158, 159], [97, 161, 99, 58, 158, 210, 244, 117, 118, 2620, 55, 2617, 250, 59, 156, 62, 159], [97, 99, 259, 205, 210, 51, 118, 55, 62, 59, 156, 158, 159], [97, 99, 58, 205, 238, 210, 55, 62, 122, 59, 156, 158], [257, 259, 133, 138, 151, 155, 156, 158, 51, 55, 59, 62, 200, 210, 83, 97, 99, 102, 103, 246, 118, 250, 251], [257, 99, 251, 210, 118, 59, 158], [97, 257, 99, 259, 102, 651, 210, 84, 118, 151, 59, 158], [99, 259, 238, 47, 251, 210, 118, 62, 154, 59, 156, 158, 95], [97, 257, 99, 259, 59, 2616, 237, 657, 210, 118, 55, 62, 2617, 251, 158], [97, 257, 99, 259, 251, 657, 210, 244, 118, 62, 2617, 59, 158], [97, 257, 99, 238, 210, 118, 55, 158], [97, 99, 238, 210, 118, 158], [97, 257, 99, 259, 657, 210, 211, 117, 118, 62, 59, 156, 158], [97, 257, 99, 259, 238, 657, 210, 211, 117, 661, 55, 62, 2613, 118, 59, 156, 158], [257, 2, 3, 259, 156, 158, 159, 55, 2616, 59, 62, 210, 95, 97, 99, 102, 237, 118, 121, 251], [97, 257, 99, 259, 251, 210, 55, 59, 156, 158, 95], [97, 257, 99, 259, 59, 10, 210, 114, 118, 55, 62, 90, 251, 156, 158], [97, 257, 99, 58, 259, 59, 10, 251, 210, 117, 55, 62, 250, 155, 156, 158, 95], [257, 259, 10, 143, 145, 153, 156, 158, 55, 58, 59, 60, 62, 210, 95, 97, 99, 117, 251], [97, 99, 139, 251, 657, 210, 83, 117, 118, 55, 59, 158, 95], [97, 257, 99, 259, 59, 250, 139, 210, 83, 117, 118, 62, 90, 251, 156, 158, 95], [97, 257, 99, 259, 139, 251, 210, 83, 117, 118, 151, 62, 90, 59, 156, 158, 95], [257, 2, 3, 259, 133, 134, 139, 151, 156, 158, 55, 2616, 59, 2620, 62, 210, 83, 95, 97, 99, 237, 117, 118, 121, 251], [257, 259, 138, 139, 657, 151, 156, 158, 175, 59, 62, 210, 83, 212, 95, 97, 99, 117, 118, 121, 251]], [[128, 98, 101, 109, 110, 238, 53], [98, 101, 6, 237, 115, 117, 53, 122, 127], [99, 3, 8, 106, 238, 114, 29, 19, 54, 127, 157, 158, 159]], [[96, 98, 100, 101, 108, 237, 49, 59]], [[226, 98, 102, 106, 2603, 52, 55, 157]], [[100, 138, 651, 117, 122, 59, 157, 158, 127]], [[2, 237, 206, 238, 205, 244, 26, 159], [2, 231, 238, 206, 48, 211, 244, 55, 249, 26, 59, 157, 159], [259, 135, 657, 147, 153, 26, 155, 158, 161, 162, 163, 175, 48, 55, 206, 211, 84, 95, 101, 238, 251], [2, 259, 133, 657, 148, 151, 663, 26, 155, 158, 159, 161, 48, 53, 55, 2616, 2617, 59, 206, 84, 99, 101, 238, 244, 118]], [[96, 97, 98, 2616, 237, 49, 53, 125, 55, 152, 157, 159]], [[96, 2, 131, 98, 149]], [[259, 35, 230, 81, 243, 2613, 2620, 95]], [[32, 226, 98, 100, 101, 103, 2603, 206, 79, 55, 2621], [96, 32, 2, 98, 100, 101, 108, 206, 79, 55, 159]], [[130, 259, 657, 663, 158, 48, 53, 2616, 97, 99, 100, 101, 108, 237, 238, 113, 114, 115, 245, 122]], [[2, 131, 233, 2603, 81, 146, 148, 52, 118]], [[130, 2, 197, 103, 199, 108, 118, 157, 127]], [[106, 59, 205, 238]], [[106, 108, 47, 50, 117, 55, 153, 157]], [[96, 64, 98, 259, 164, 257, 106, 48]], [[257, 98, 259, 140, 109, 238, 653, 83, 148, 149, 55, 152, 58, 247, 62]], [[128, 97, 130, 98, 1, 118, 55], [128, 97, 98, 42, 138, 43, 238, 118, 2616], [98, 42, 43, 2617, 155], [159, 97, 128, 98, 42, 43, 118, 63], [128, 97, 98, 131, 106, 42, 43, 122]], [[96, 257, 131, 133, 134, 108, 48, 24, 60, 127], [64, 257, 96, 131, 99, 133, 134, 105, 106, 108, 155, 53, 59, 158, 127], [257, 131, 259, 133, 134, 135, 138, 663, 24, 153, 157, 158, 44, 47, 48, 53, 55, 2615, 2617, 59, 60, 205, 93, 94, 96, 99, 105, 106, 108, 244, 122, 127]], [[96, 97, 130, 131, 100, 101, 98, 257, 259, 106, 108, 50, 18, 53, 152, 158]], [[131, 6, 138, 237, 238, 2617, 81, 83, 116, 85, 55, 151, 661, 149, 51, 60], [103, 651, 237, 81, 49, 83, 661, 246, 59]], [[131, 100, 108, 237, 50, 249, 122, 157, 159]], [[99, 237, 83, 53, 59, 157, 159], [98, 7, 137, 237, 59, 157]], [[98, 131, 100, 83, 117, 55, 122, 59, 127], [98, 131, 101, 83, 663, 59, 95, 127], [98, 131, 101, 133, 83, 59, 127]], [[2, 131, 42, 13, 238, 145, 62]], [[237, 98, 53, 101]], [[130, 105, 106, 108, 238, 145, 19, 55, 151, 157, 127], [121, 130, 131, 98, 101, 105, 108, 238, 19, 118, 153, 122, 59, 127], [129, 2, 131, 100, 97, 101, 105, 108, 19, 249, 59, 157, 95, 127]], [[224, 256, 10, 218, 222]], [[96, 106, 237, 98]], [[128, 257, 98, 131, 5, 6, 238, 50, 83, 52, 55, 151, 2617, 59, 156, 62]], [[33, 42, 83]], [[96, 3, 101, 106, 108, 114, 159]], [[131, 99, 6, 76, 109, 237, 47, 81, 49, 83, 118, 60, 157, 158, 95]], [[256, 10, 218, 219, 221]], [[96, 128, 100, 101, 138, 140, 204, 48, 58, 93]], [[98, 100, 101, 108, 53], [104, 98, 96, 101]], [[2, 99, 237, 660, 54, 62, 59, 158, 127]], [[81, 42, 15], [98, 259, 42, 109, 15, 83, 51, 2617, 95]], [[256, 98, 131, 115, 660, 54, 663, 29], [129, 2, 257, 259, 145, 156, 29, 157, 159, 50, 54, 199, 99, 106, 108, 238, 115, 116, 248, 122]], [[130, 105, 106, 238, 113, 114, 19, 2616, 89, 127]], [[131, 101, 48, 55, 127]], [[82, 164, 109]], [[130, 98, 103, 106, 12, 238, 53, 663]], [[96, 101, 105, 106, 108, 53], [161, 99, 104, 141, 657, 55, 2617, 59, 62], [96, 101, 106, 108, 141, 55, 155], [99, 101, 105, 106, 108, 55, 155, 60]], [[99, 6, 106, 237, 238, 50, 151, 62]], [[131, 134, 19, 53, 55, 122, 157, 158, 127], [128, 161, 130, 131, 98, 19, 244, 55, 157], [129, 2, 131, 1, 108, 19, 52, 125, 55, 249, 122, 59, 157, 95, 127]], [[129, 2, 153, 131, 98, 12, 54, 55, 22, 249, 60, 157]], [[2, 135, 660, 149, 661, 55, 249, 157, 62]], [[98, 259, 42, 238, 18, 54, 2616, 157, 127]], [[129, 98, 131, 135, 141, 52, 53, 122, 155], [98, 134, 137, 657, 53, 59]], [[122, 227, 131, 2607]], [[2, 237, 50, 87, 248, 158, 95]], [[98, 101, 106, 238, 49, 53, 127], [130, 98, 101, 238, 48, 49, 53]], [[2, 131, 197, 135, 106, 108, 141, 49, 122], [128, 2, 259, 4, 197, 101, 199, 50, 58], [257, 98, 131, 3, 58, 108, 237, 50, 148, 149, 122, 155, 156, 95, 127], [257, 3, 4, 259, 134, 657, 661, 155, 156, 157, 159, 163, 50, 58, 59, 211, 87, 95, 98, 108, 237, 117, 127], [129, 2, 131, 259, 3, 133, 257, 651, 141, 155, 157, 159, 50, 51, 55, 58, 59, 197, 203, 204, 211, 98, 108, 238, 114, 244, 117, 122, 127], [2, 131, 259, 134, 156, 157, 158, 159, 50, 58, 59, 197, 211, 87, 95, 108, 237, 122, 127]], [[98, 101, 138, 238, 49, 159]], [[130, 131, 108, 238, 118, 55, 122, 157]], [[217, 218]], [[129, 130, 2, 98, 259, 101, 3, 108, 109, 110, 48, 81, 50, 149, 118, 122, 95]], [[98, 100, 101, 5, 108, 663, 127]]], 'pids': ['21', '23', '61', '94', '105', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '124', '124', '124', '209', '321', '368', '406', '406', '406', '406', '494', '507', '550', '618', '618', '731', '755', '771', '779', '787', '796', '807', '808', '808', '808', '808', '808', '878', '878', '878', '890', '914', '914', '924', '948', '948', '952', '952', '952', '959', '969', '1006', '1006', '1006', '1080', '1124', '1137', '1192', '1207', '1241', '1292', '1516', '1517', '1517', '1571', '1594', '1594', '1636', '1636', '1673', '1802', '1811', '1915', '1931', '1931', '1931', '1931', '1967', '1972', '1972', '1972', '1982', '2005', '2015', '2081', '2081', '2092', '2165', '2185', '2185', '2187', '2187', '2187', '2187', '2187', '2187', '2258', '2280', '2303', '2310', '2343']}, 'target_sequences': {'sequence': tensor([[[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'original': [[[2, 130, 3, 135, 151, 29, 48, 49, 54, 2616, 59, 197, 199, 99, 101, 106, 238, 113, 114, 249]], [[96, 98, 259, 101, 47, 83, 53, 663, 95]], [[2, 4, 38, 8, 106, 155, 237, 51, 148, 52, 117, 55, 59, 95]], [[98, 131, 164, 106, 81, 122, 59]], [[81, 122, 108, 246]], [[97, 99, 210, 83, 59], [259, 99, 210, 90, 156, 158], [99, 210, 90, 59, 156, 158], [97, 2, 99, 4, 257, 200, 91, 237, 238, 210, 90, 59, 158], [2, 99, 3, 259, 237, 210, 90, 59, 156, 158], [2, 99, 3, 109, 210, 83, 156, 158], [97, 99, 259, 91, 210, 62, 59, 156, 158], [97, 258, 99, 238, 251, 2617, 210, 51, 118, 55, 62, 121, 250, 59, 156, 158], [257, 99, 259, 58, 167, 210, 55, 118, 95, 62, 90, 59, 156, 158, 159], [97, 161, 99, 58, 158, 210, 244, 117, 118, 2620, 55, 2617, 250, 59, 156, 62, 159], [97, 99, 259, 205, 210, 51, 118, 55, 62, 59, 156, 158, 159], [97, 99, 58, 205, 238, 210, 55, 62, 122, 59, 156, 158], [257, 259, 133, 138, 151, 155, 156, 158, 51, 55, 59, 62, 200, 210, 83, 97, 99, 102, 103, 246, 118, 250, 251], [257, 99, 251, 210, 118, 59, 158], [97, 257, 99, 259, 102, 651, 210, 84, 118, 151, 59, 158], [99, 259, 238, 47, 251, 210, 118, 62, 154, 59, 156, 158, 95], [97, 257, 99, 259, 59, 2616, 237, 657, 210, 118, 55, 62, 2617, 251, 158], [97, 257, 99, 259, 251, 657, 210, 244, 118, 62, 2617, 59, 158], [97, 257, 99, 238, 210, 118, 55, 158], [97, 99, 238, 210, 118, 158], [97, 257, 99, 259, 657, 210, 211, 117, 118, 62, 59, 156, 158], [97, 257, 99, 259, 238, 657, 210, 211, 117, 661, 55, 62, 2613, 118, 59, 156, 158], [257, 2, 3, 259, 156, 158, 159, 55, 2616, 59, 62, 210, 95, 97, 99, 102, 237, 118, 121, 251], [97, 257, 99, 259, 251, 210, 55, 59, 156, 158, 95], [97, 257, 99, 259, 59, 10, 210, 114, 118, 55, 62, 90, 251, 156, 158], [97, 257, 99, 58, 259, 59, 10, 251, 210, 117, 55, 62, 250, 155, 156, 158, 95], [257, 259, 10, 143, 145, 153, 156, 158, 55, 58, 59, 60, 62, 210, 95, 97, 99, 117, 251], [97, 99, 139, 251, 657, 210, 83, 117, 118, 55, 59, 158, 95], [97, 257, 99, 259, 59, 250, 139, 210, 83, 117, 118, 62, 90, 251, 156, 158, 95], [97, 257, 99, 259, 139, 251, 210, 83, 117, 118, 151, 62, 90, 59, 156, 158, 95], [257, 2, 3, 259, 133, 134, 139, 151, 156, 158, 55, 2616, 59, 2620, 62, 210, 83, 95, 97, 99, 237, 117, 118, 121, 251], [257, 259, 138, 139, 657, 151, 156, 158, 175, 59, 62, 210, 83, 212, 95, 97, 99, 117, 118, 121, 251], [257, 259, 138, 139, 151, 156, 158, 175, 55, 59, 62, 210, 83, 95, 97, 99, 107, 117, 118, 121, 251]], [[98, 101, 6, 237, 115, 117, 53, 122, 127], [99, 3, 8, 106, 238, 114, 29, 19, 54, 127, 157, 158, 159], [2, 99, 101, 106, 108, 238, 145, 29, 19, 52, 122, 155, 157, 158, 127]], [[257, 99, 100, 164, 101, 259, 108, 50, 211, 19, 53, 55, 62, 59, 127, 157, 158, 95]], [[98, 105, 106, 138, 49, 212, 661, 60]], [[131, 100, 99, 101, 138, 651, 108, 653, 117, 118, 55, 122, 59, 127]], [[2, 231, 238, 206, 48, 211, 244, 55, 249, 26, 59, 157, 159], [259, 135, 657, 147, 153, 26, 155, 158, 161, 162, 163, 175, 48, 55, 206, 211, 84, 95, 101, 238, 251], [2, 259, 133, 657, 148, 151, 663, 26, 155, 158, 159, 161, 48, 53, 55, 2616, 2617, 59, 206, 84, 99, 101, 238, 244, 118], [2, 98, 259, 101, 238, 206, 48, 657, 211, 244, 55, 2616, 249, 26, 155, 157, 95, 159]], [[64, 97, 98, 259, 101, 138, 52, 213, 2617, 59, 28, 158]], [[96, 97, 130, 131, 98, 3, 105, 106, 238, 117, 53, 122, 157]], [[81, 129, 83, 95]], [[96, 32, 2, 98, 100, 101, 108, 206, 79, 55, 159], [32, 129, 98, 259, 101, 108, 206, 79, 2617, 244, 52, 149, 55, 117, 153, 2621, 62]], [[99, 100, 101, 203, 108, 48, 657, 117, 53, 158]], [[81, 130, 101, 237]], [[131, 100, 259, 103, 108, 151, 249, 157, 62]], [[257, 3, 99, 106, 138, 53, 153, 59, 158]], [[96, 106, 108, 47, 55, 153, 59, 157, 159]], [[96, 2, 163, 3, 259, 164, 98, 106, 108, 237, 48, 53, 159]], [[247, 47, 143]], [[128, 97, 98, 42, 138, 43, 238, 118, 2616], [98, 42, 43, 2617, 155], [159, 97, 128, 98, 42, 43, 118, 63], [128, 97, 98, 131, 106, 42, 43, 122], [128, 97, 130, 98, 257, 42, 43, 106, 52, 118, 151, 122, 59, 159]], [[64, 257, 96, 131, 99, 133, 134, 105, 106, 108, 155, 53, 59, 158, 127], [257, 131, 259, 133, 134, 135, 138, 663, 24, 153, 157, 158, 44, 47, 48, 53, 55, 2615, 2617, 59, 60, 205, 93, 94, 96, 99, 105, 106, 108, 244, 122, 127], [257, 131, 259, 133, 138, 14, 663, 153, 157, 158, 48, 53, 55, 58, 59, 60, 62, 200, 205, 85, 93, 94, 96, 99, 105, 106, 108, 121, 122, 127]], [[257, 2, 131, 101, 106, 49, 18, 149, 53, 55, 249, 91, 157, 158]], [[103, 651, 237, 81, 49, 83, 661, 246, 59], [257, 2, 131, 130, 6, 106, 237, 238, 49, 83, 116, 148, 149, 152, 62]], [[199, 108, 238, 50, 55, 248, 122, 157]], [[98, 7, 137, 237, 59, 157], [257, 99, 135, 175, 117, 53, 55, 59, 157, 158]], [[98, 131, 101, 83, 663, 59, 95, 127], [98, 131, 101, 133, 83, 59, 127], [98, 131, 101, 103, 83, 53, 59, 127]], [[98, 4, 13, 83, 246, 2617, 63]], [[96, 257, 259, 131, 101, 133, 103, 199, 105, 106, 651, 108, 52, 117, 23, 155, 158]], [[121, 130, 131, 98, 101, 105, 108, 238, 19, 118, 153, 122, 59, 127], [129, 2, 131, 100, 97, 101, 105, 108, 19, 249, 59, 157, 95, 127], [98, 131, 101, 134, 105, 106, 108, 109, 19, 85, 55, 122, 155, 127]], [[224, 222, 55]], [[96, 98, 106, 203, 108, 205, 238, 48, 55, 217, 157]], [[257, 131, 99, 5, 198, 6, 233, 2603, 238, 81, 49, 83, 151, 152, 2617, 90, 158, 62]], [[33, 97, 42, 238, 83, 52, 51, 55, 58]], [[101, 108, 155, 47, 147, 59]], [[98, 6, 199, 49, 120, 59]], [[224, 10, 91]], [[128, 98, 100, 101, 108, 237, 48, 211]], [[104, 98, 96, 101], [96, 98, 101, 238, 53, 2616, 58]], [[99, 135, 660, 148, 54, 55, 151, 149, 156, 63, 158, 127]], [[98, 259, 42, 109, 15, 83, 51, 2617, 95], [2, 98, 42, 15, 49, 244, 152, 95]], [[129, 2, 257, 259, 145, 156, 29, 157, 159, 50, 54, 199, 99, 106, 108, 238, 115, 116, 248, 122], [96, 99, 131, 106, 238, 657, 114, 115, 2616, 60, 29]], [[96, 97, 131, 101, 103, 108, 114, 19, 157, 127]], [[101, 106, 108, 117, 127]], [[129, 131, 259, 106, 146, 83, 55, 122, 155]], [[2, 130, 3, 98, 59, 138, 12, 238, 148, 53, 118, 55, 155]], [[161, 99, 104, 141, 657, 55, 2617, 59, 62], [96, 101, 106, 108, 141, 55, 155], [99, 101, 105, 106, 108, 55, 155, 60], [96, 161, 98, 101, 106, 138, 108, 117]], [[257, 2, 99, 4, 6, 199, 237, 48, 50, 83, 55, 85, 151, 122, 157, 62]], [[128, 161, 130, 131, 98, 19, 244, 55, 157], [129, 2, 131, 1, 108, 19, 52, 125, 55, 249, 122, 59, 157, 95, 127], [128, 98, 131, 100, 107, 49, 19, 55, 59, 157, 62]], [[129, 2, 131, 99, 100, 42, 107, 12, 145, 83, 118, 23, 22, 249, 58, 157, 62]], [[98, 3, 138, 140, 114, 660, 661, 663, 152]], [[129, 130, 259, 142, 144, 145, 157, 41, 42, 54, 55, 2616, 2621, 98, 106, 238, 114, 244, 122]], [[98, 134, 137, 657, 53, 59], [131, 134, 83, 59, 127]], [[257, 2, 130, 131, 4, 3, 259, 134, 653, 145, 148, 155, 162, 49, 55, 2618, 59, 58, 199, 82, 95, 98, 227, 105, 108, 238, 244, 117, 118]], [[2, 131, 98, 237, 49, 55, 249, 122, 60, 157, 62, 127]], [[130, 98, 101, 238, 48, 49, 53], [130, 98, 101, 106, 238, 48, 49, 53]], [[128, 2, 259, 4, 197, 101, 199, 50, 58], [257, 98, 131, 3, 58, 108, 237, 50, 148, 149, 122, 155, 156, 95, 127], [257, 3, 4, 259, 134, 657, 661, 155, 156, 157, 159, 163, 50, 58, 59, 211, 87, 95, 98, 108, 237, 117, 127], [129, 2, 131, 259, 3, 133, 257, 651, 141, 155, 157, 159, 50, 51, 55, 58, 59, 197, 203, 204, 211, 98, 108, 238, 114, 244, 117, 122, 127], [2, 131, 259, 134, 156, 157, 158, 159, 50, 58, 59, 197, 211, 87, 95, 108, 237, 122, 127], [2, 131, 259, 3, 134, 657, 155, 156, 50, 51, 55, 58, 59, 203, 211, 87, 95, 98, 108, 244, 117, 122, 127]], [[257, 98, 131, 101, 138, 108, 50, 114, 117, 53, 157, 95, 127]], [[97, 130, 131, 4, 107, 108, 238, 157]], [[224, 10, 213]], [[257, 98, 101, 106, 138, 110, 49, 113, 149, 55, 157]], [[128, 2, 131, 100, 5, 101, 663, 108, 19, 244, 55, 122, 157, 127]]], 'pids': ['21', '23', '61', '94', '105', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '124', '124', '124', '209', '321', '368', '406', '406', '406', '406', '494', '507', '550', '618', '618', '731', '755', '771', '779', '787', '796', '807', '808', '808', '808', '808', '808', '878', '878', '878', '890', '914', '914', '924', '948', '948', '952', '952', '952', '959', '969', '1006', '1006', '1006', '1080', '1124', '1137', '1192', '1207', '1241', '1292', '1516', '1517', '1517', '1571', '1594', '1594', '1636', '1636', '1673', '1802', '1811', '1915', '1931', '1931', '1931', '1931', '1967', '1972', '1972', '1972', '1982', '2005', '2015', '2081', '2081', '2092', '2165', '2185', '2185', '2187', '2187', '2187', '2187', '2187', '2187', '2258', '2280', '2303', '2310', '2343']}, 'train_pids': ['21', '23', '61', '94', '105', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '124', '124', '124', '209', '321', '368', '406', '406', '406', '406', '494', '507', '550', '618', '618', '731', '755', '771', '779', '787', '796', '807', '808', '808', '808', '808', '808', '878', '878', '878', '890', '914', '914', '924', '948', '948', '952', '952', '952', '959', '969', '1006', '1006', '1006', '1080', '1124', '1137', '1192', '1207', '1241', '1292', '1516', '1517', '1517', '1571', '1594', '1594', '1636', '1636', '1673', '1802', '1811', '1915', '1931', '1931', '1931', '1931', '1967', '1972', '1972', '1972', '1982', '2005', '2015', '2081', '2081', '2092', '2165', '2185', '2185', '2187', '2187', '2187', '2187', '2187', '2187', '2258', '2280', '2303', '2310', '2343'], 'target_pids': ['21', '23', '61', '94', '105', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '109', '124', '124', '124', '209', '321', '368', '406', '406', '406', '406', '494', '507', '550', '618', '618', '731', '755', '771', '779', '787', '796', '807', '808', '808', '808', '808', '808', '878', '878', '878', '890', '914', '914', '924', '948', '948', '952', '952', '952', '959', '969', '1006', '1006', '1006', '1080', '1124', '1137', '1192', '1207', '1241', '1292', '1516', '1517', '1517', '1571', '1594', '1594', '1636', '1636', '1673', '1802', '1811', '1915', '1931', '1931', '1931', '1931', '1967', '1972', '1972', '1972', '1982', '2005', '2015', '2081', '2081', '2092', '2165', '2185', '2185', '2187', '2187', '2187', '2187', '2187', '2187', '2258', '2280', '2303', '2310', '2343']}\n"
     ]
    }
   ],
   "source": [
    "for e in val_dataloader:\n",
    "    print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d2a40-6701-46d8-aac4-4a28c9ce792b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis)",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
