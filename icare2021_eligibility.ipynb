{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae70a096-5daa-4e4e-b521-d17cac174723",
   "metadata": {},
   "source": [
    "dataset code: A301\n",
    "\n",
    "eligibility:\n",
    "1. after 2016\n",
    "2. at least 2 admissions\n",
    "3. admission is eligible if there is at least 1 recognized ccs code\n",
    "5. episodes can't have multiple diagnostics assigned with more than 1 day delay between each other\n",
    "\n",
    "process:\n",
    "1. ccs codes\n",
    "2. 12 months target window\n",
    "3. saves delta_days and date of last admission before prediction_period of all datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e0ded2-04af-4c2a-a0fc-e6a63c66b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c7f36c6-046e-4337-a9e5-79a4756fcfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "idx = pd.IndexSlice\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from datetime import timedelta\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from ICDMappings import ICDMappings\n",
    "icdmap = ICDMappings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7209211-4f73-42e1-8d7d-10db997c1ea1",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8924c7-1ea7-4a52-849d-0c9c8f75147c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "File exists, are you sure you want to overwrite it? If so, comment this line and run the notebook again",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(dataset_filepath) \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(raw_data_filepath), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmake sure both dataset are saved under the same directory\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(dataset_filepath)),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease create the directory first or try another path to save\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(dataset_filepath) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(raw_data_filepath), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFile exists, are you sure you want to overwrite it? If so, comment this line and run the notebook again\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: File exists, are you sure you want to overwrite it? If so, comment this line and run the notebook again"
     ]
    }
   ],
   "source": [
    "#where to save the resulting dataset\n",
    "dataset_filepath = 'data/model_ready_dataset/icare2021_diag_A301/dataset.json'\n",
    "raw_data_filepath = 'data/model_ready_dataset/icare2021_diag_A301/dataset.csv'\n",
    "\n",
    "#checks\n",
    "\n",
    "assert os.path.dirname(dataset_filepath) == os.path.dirname(raw_data_filepath), 'make sure both dataset are saved under the same directory'\n",
    "assert os.path.isdir(os.path.dirname(dataset_filepath)),'Please create the directory first or try another path to save'\n",
    "\n",
    "assert not os.path.isfile(dataset_filepath) or not os.path.isfile(raw_data_filepath), 'File exists, are you sure you want to overwrite it? If so, comment this line and run the notebook again'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7754b9c-9640-4c8a-98c7-34fdbfaae9b9",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12dac82-4783-4530-855d-1a0245dffc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Icare:\n",
    "    def __init__(self,data_folder):\n",
    "        self.data_folder = data_folder\n",
    "        self.diagnoses_path = 'LS_ANALYTICS.ICARE_CLINICO_DIAGNOSTICOS/index.csv'\n",
    "        self.atividade_path = 'LS_ANALYTICS.ICARE_ATIVIDADE_HOSPITALAR/index.csv'\n",
    "        \n",
    "    \n",
    "    def _read_diagnoses(self):\n",
    "        print('Reading diagnostics table...')\n",
    "        diagnoses_file = os.path.join(self.data_folder,self.diagnoses_path)\n",
    "        \n",
    "        df = pd.read_csv(diagnoses_file,sep='\\t')\n",
    "        \n",
    "        print('begining: ',round(df.memory_usage(index=True).sum() / 1_000_000,1),'Mb') #Mbytes\n",
    "        \n",
    "        df = df.drop(columns='UNIDADE')\n",
    "        #print('drop UNIDADE:',df.memory_usage(index=True).sum() / 1_000_000) #Mbytes\n",
    "        \n",
    "        df = df.drop(columns='DATA_FIM')\n",
    "        #print('drop date_end:',df.memory_usage(index=True).sum() / 1_000_000) #Mbytes\n",
    "        \n",
    "        df.loc[:,'PRIORIDADE_DIAGNOSTICO'] = df.PRIORIDADE_DIAGNOSTICO.astype('category')\n",
    "        #print('PRIORIDADE_DIAGNOSTICO to category:',df.memory_usage(index=True).sum() / 1_000_000) #Mbytes\n",
    "        \n",
    "        df = df.drop(columns=['ICD9_DESCRICAO'])\n",
    "        #print('drop icd9_descricao:',df.memory_usage(index=True).sum() / 1_000_000) #Mbytes\n",
    "        \n",
    "        df.loc[:,'DIAGNOSTICO_PRINCIPAL'] = df.DIAGNOSTICO_PRINCIPAL.map({'S':True,'N':False})        \n",
    "        #print('DIAGNOSTICO_PRINCIPAL to boolean:',df.memory_usage(index=True).sum() / 1_000_000) #Mbytes\n",
    "        \n",
    "        # a single row with the year 9064 ruins pd.to_datetime (overflow since pandas uses miliseconds in dates)\n",
    "        # tldr:  we will remove that row\n",
    "        nrows_before = df.shape[0]\n",
    "        df = df.drop(df.DATA_INICIO.apply(lambda x: x[:4] if x is not np.nan else x).astype(float).where(lambda x: x==9064.0).dropna().index[0])\n",
    "        nrows_after = df.shape[0]\n",
    "        assert nrows_before == nrows_after + 1, 'Ooops, expecting to drop exactly 1 row. maybe dataset changed.'\n",
    "        \n",
    "        df.loc[:,'DATA_INICIO'] = pd.to_datetime(df.DATA_INICIO,format='%Y-%m-%d %H:%M:%S')\n",
    "        #print('DATA_INICIO to datetime:',df.memory_usage(index=True).sum() / 1_000_000) #Mbytes\n",
    "        \n",
    "        df = df.drop_duplicates()\n",
    "        #print('drop duplicates:',df.memory_usage(index=True).sum() / 1_000_000) #Mbytes\n",
    "        \n",
    "        # last row is trash\n",
    "        df = df.iloc[:-1]\n",
    "        \n",
    "        print('end: ',round(df.memory_usage(index=True).sum() / 1_000_000),'Mb') #Mbytes\n",
    "        print('Done')\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbeb72-c064-46dd-b64c-99fbc963bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "icare = Icare('../../icare-dataset_2021-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ede27-9d63-4ef7-abde-6262441797b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = icare._read_diagnoses()\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39e7287-c87d-4352-8872-59fe3723a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df.groupby(['EPISODIO','NHC']).DATA_INICIO.agg([min,max])\n",
    "res.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f36a9-d491-44d6-a2e6-e09e99d24653",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ac3b7-87c6-47f3-b354-9e1b46f5a691",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3bc526-cdb0-492c-84eb-06e1701ba476",
   "metadata": {},
   "source": [
    "# ICD9 to ICD9_3 then CCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e2712-f2f9-4bc1-af5f-65067d2b9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'ICD9_3'] = df.ICD9.apply(lambda x: x[:3] if x is not np.nan else x)\n",
    "df.loc[:,'ICD9_3->CCS'] = icdmap.lookup('icd9_3toccs',df['ICD9_3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5231be-47bf-46e6-9a25-8d55c9b28a73",
   "metadata": {},
   "source": [
    "## define eligibility criteria\n",
    "\n",
    "1. data after 2016\n",
    "1. patients with at least 2 admissions\n",
    "1. all admissions must have at least 1 ccs diagnostic that is eligible\n",
    "\n",
    "## define windows\n",
    "\n",
    "3,6,12 months\n",
    "\n",
    "what metrics to keep track of:\n",
    "1. distribution of #admissions per target window\n",
    "1. distribution of # diagnoses per target window\n",
    "1. distribution of # admissions of input per target window\n",
    "1. distribution # diagnoses of input per target window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe886256-15b6-4e3a-9b89-412566fd907c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eligibility\n",
    "df = icare._read_diagnoses()\n",
    "\n",
    "print('Preparing eligibility filtering...')\n",
    "df['ICD9_3'] = df.ICD9.apply(lambda x: x[:3] if x is not np.nan else x)\n",
    "df['ICD9_3->CCS'] = icdmap.lookup('icd9_3toccs',df['ICD9_3'])\n",
    "\n",
    "## after 2016\n",
    "df = df.loc[df.DATA_INICIO > '2016-01-01']\n",
    "\n",
    "## admission is eligible if there is at least 1 recognized ccs code\n",
    "df['is_ccs_na'] = df['ICD9_3->CCS'].isna()\n",
    "admissions_without_any_eligible_ccs = df.groupby('EPISODIO')['is_ccs_na'].all().where(lambda x: x == True).dropna().index\n",
    "df = df.loc[~df.EPISODIO.isin(admissions_without_any_eligible_ccs)]\n",
    "\n",
    "## drop rows where diagnostic is not recognized\n",
    "df = df.loc[~df['ICD9_3->CCS'].isna()]\n",
    "\n",
    "## patient with at least 2 admissions\n",
    "patients_2_admissions = df.groupby('NHC').EPISODIO.size().where(lambda x: x > 1).dropna().index\n",
    "df = df.loc[df.NHC.isin(patients_2_admissions)]\n",
    "\n",
    "## episodes with multiple diagnostics can't have diagnostics assigned with more than 1 day delay between each other\n",
    "episodes_far_diagnostics = df.groupby('EPISODIO').DATA_INICIO.agg([min,max]).diff(axis=1)['max'].dt.days.where(lambda x: x > 0).dropna().index\n",
    "df = df.loc[~df.EPISODIO.isin(episodes_far_diagnostics)]\n",
    "print('Done')\n",
    "\n",
    "df = df.sort_values('DATA_INICIO')\n",
    "df.DATA_INICIO = pd.to_datetime(df.DATA_INICIO.dt.date,format='%Y-%m-%d')\n",
    "\n",
    "df.shape\n",
    "df.EPISODIO.nunique()\n",
    "df.NHC.nunique()\n",
    "df.groupby('NHC').EPISODIO.size().value_counts().rename('Distribution of #episodes per eligible patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb71d4-407c-4643-a7a8-35c7a5a143eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'ccs_list'] = df['ICD9_3->CCS'].apply(lambda x: [x])\n",
    "df_ = df.groupby(['NHC','DATA_INICIO'])[['ccs_list']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a89b8-a66a-4c28-bb74-c397060920bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_.iloc[:50_000].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924d3f7-b9ec-4a85-bd7b-6a30ad82f72a",
   "metadata": {},
   "source": [
    "#### 1000 rows\n",
    "1. 1.68\n",
    "2. 1.08\n",
    "\n",
    "#### 10_000 rows\n",
    "1. 14.4 (8.5x)\n",
    "2. 8.49 (7.9x)\n",
    "\n",
    "#### 100_000 rows\n",
    "1. 189 (112x) (13x)\n",
    "2. 85 (78x) (10x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bccfa-46ad-4097-9945-fe54d3424eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#assert 1==2,'Prevent myself from running this cell\n",
    "m = 12 #months\n",
    "res = (test\n",
    " .groupby('NHC')\n",
    " .apply(lambda subdf: \n",
    "        subdf.assign(target = \n",
    "                     subdf.apply(lambda row: \n",
    "                                 subdf\n",
    "                                 .loc[idx[:,\n",
    "                                         row.name[1]+timedelta(days=1):row.name[1]+timedelta(days=30*m)\n",
    "                                         ],\n",
    "                                      'ccs_list'\n",
    "                                     ]\n",
    "                                 .sum(),\n",
    "                                 axis=1\n",
    "                                ),\n",
    "                     history = \n",
    "                     subdf.apply(lambda row:\n",
    "                                 subdf\n",
    "                                 .loc[idx[:,\n",
    "                                          :row.name[1]+timedelta(days=1)\n",
    "                                         ],\n",
    "                                      'ccs_list'\n",
    "                                     ]\n",
    "                                 .tolist(),\n",
    "                                 axis=1\n",
    "                                ),\n",
    "                    )\n",
    "       )\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161aef3-1111-477c-83ec-e7838a89d4fe",
   "metadata": {},
   "source": [
    "# Add feature: delta days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062540b-22d3-4418-a6b2-4a3f379886c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['delta_days'] = res.reset_index().groupby('NHC')['DATA_INICIO'].diff().dt.days.fillna(0).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced255f-18b5-47d8-bcc6-77381e0855a9",
   "metadata": {},
   "source": [
    "# Print out some distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c63f2c-4b34-4df3-8bb3-85370558a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of non-empty targets out of {res.shape[0]}: {res[res.target != 0].shape[0]}')\n",
    "print(f'Distribution of target size')\n",
    "res.loc[res.target != 0,'target'].apply(len).value_counts(normalize=True).iloc[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbc0b3-60f7-4328-be2a-ee1a219aadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[res.target != 0].groupby('NHC').delta_days.agg('median').describe()[['25%','50%','75%']].rename('Quartiles of all patients of the median delta_days of each patient, on eligible datapoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1e7fa-fe49-4957-89c6-0e050d1e44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res[res.target != 0].reset_index(1).rename(columns={'DATA_INICIO':'DATA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94c8d0-6ec5-4157-888f-88f825141c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.groupby('NHC').size().describe()[['25%','50%','75%']].rename('Quartiles #admissions eligible per patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e56b2-37e1-4708-b4aa-4d321e96e296",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{res2.index.get_level_values(0).nunique()} patients eligible out of {test.index.get_level_values(0).nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd52e9-32a2-4b57-87f0-fed513db84d8",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d50faf-e117-4722-875f-fc56a4e14615",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res2.astype({'DATA':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70679bed-a75e-4ea1-8d09-f2319d69fb36",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ee7438-f7a0-455c-8aeb-a580100d67af",
   "metadata": {},
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875a7a74-7f7e-4992-94e7-faef737302b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.to_csv(raw_data_filepath,index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56e5e4-352f-49a9-9ad9-ff00ca50c022",
   "metadata": {},
   "source": [
    "and dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b1740-c0ec-4e4f-a10a-8ea9547f1763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where it all begins\n",
    "data = {}\n",
    "\n",
    "patients = res2.index.unique()\n",
    "for idx,p in tqdm(enumerate(patients)):\n",
    "    \n",
    "    history = res2.loc[p,'history']\n",
    "    targets = res2.loc[p,'target']\n",
    "    delta_days = res2.loc[p,'delta_days']\n",
    "    date_last_history = res2.loc[p,'DATA']\n",
    "    \n",
    "    history = [history] if type(history) != pd.Series else history.tolist()\n",
    "    targets = [targets] if type(targets) != pd.Series else targets.tolist()\n",
    "    delta_days = [delta_days] if type(delta_days) != pd.Series else delta_days.tolist()\n",
    "    date_last_history = [date_last_history] if type(date_last_history) != pd.Series else date_last_history.tolist()\n",
    "    \n",
    "    data[p] = { 'ccs': #only ccs for now\n",
    "               {\n",
    "                   'history':history,\n",
    "                   'targets':targets,\n",
    "                   'extra_features':\n",
    "                   {\n",
    "                       'delta_days': delta_days,\n",
    "                       'date_last_history': date_last_history\n",
    "                   }\n",
    "               }\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87458e19-84a7-4c20-8b6d-f98132cc32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_filepath, 'w') as fp:\n",
    "    json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196ae87-1fe2-4b91-ab87-0e581c0841ca",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632b2da1-7038-44d6-a909-c4306f281f95",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67daf06-3f6f-4bef-97e6-a11f2bed05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_filepath, 'r') as fp:\n",
    "    test_data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694a3037-32e7-4bc3-b6ee-a4108f9e0dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [[[670.0]]],\n",
       " 'targets': [[670.0]],\n",
       " 'extra_features': {'delta_days': [0.0], 'date_last_history': ['2016-02-28']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['0000676389D1EE60EB48AF5693F3F3DE']['ccs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (simao thesis)",
   "language": "python",
   "name": "simao_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
