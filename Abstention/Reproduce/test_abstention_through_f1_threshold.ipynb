{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749204d2-6ee9-4d08-98d3-f0c071db47b8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook i abstain through the threshold that maximizes f1 in train set. And i want to compare the final f1 score of this pipeline and see wether it is lower than my mc+LR method. If it is lower it means i was able to progress past this baseline\n",
    "\n",
    "**TLDR**: this method improves f1 from 0.38 to 0.40. My method improves f1 from 0.38 up to 0.45!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf5109-3d79-4284-964f-065d916f1a41",
   "metadata": {},
   "source": [
    "# WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eff9be6-a9c0-487d-b590-4d0524aff02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12543506",
   "metadata": {},
   "source": [
    "# Change directory to parent folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96417374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# protection against running this cell multiple times\n",
    "assert os.path.dirname(os.path.dirname(cwd)).split('/')[-1] == 'master-thesis','Oops, directory already changed previously as indended. Ignoring...'\n",
    "\n",
    "# change working directory (if assert passed)\n",
    "new_cwd = os.path.dirname(os.path.dirname(cwd)) # parent directory\n",
    "os.chdir(new_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da94e5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353a88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea40462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from rnn_utils import DiagnosesDataset, split_dataset, MYCOLLATE\n",
    "from rnn_utils import RNN, train_one_epoch, eval_model, compute_loss, outs2df, compute_metrics, get_prediction_thresholds\n",
    "\n",
    "from Abstention.utils import plot_reliability,get_prediction_thresholds,ece\n",
    "\n",
    "from config import Settings; settings = Settings()\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d36e98",
   "metadata": {},
   "source": [
    "# Model reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e0e44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x114dc45b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reproducibility\n",
    "seed = settings.random_seed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca416982",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4f571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset at data/model_ready_dataset/diag_only\n"
     ]
    }
   ],
   "source": [
    "dataset_id = 'diag_only'\n",
    "dataset_folder = os.path.join(settings.data_base,settings.model_ready_dataset_folder,dataset_id)\n",
    "print('dataset at',dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d27f7873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5249"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouping = 'ccs' # coding-scheme\n",
    "batch_size=64\n",
    "\n",
    "dataset = DiagnosesDataset(os.path.join(dataset_folder,'dataset.json'),grouping)\n",
    "\n",
    "train_dataset = DiagnosesDataset(os.path.join(dataset_folder,'train_subset.json'),grouping)\n",
    "val_dataset = DiagnosesDataset(os.path.join(dataset_folder,'val_subset.json'),grouping)\n",
    "test_dataset = DiagnosesDataset(os.path.join(dataset_folder,'test_subset.json'),grouping)\n",
    "\n",
    "\n",
    "len(train_dataset)\n",
    "len(val_dataset)\n",
    "len(test_dataset)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size,collate_fn=MYCOLLATE(dataset),shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=batch_size,collate_fn=MYCOLLATE(dataset)) #batch_size here is arbitrary and doesn't affect total validation speed\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=batch_size,collate_fn=MYCOLLATE(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add62695",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6e8798",
   "metadata": {},
   "source": [
    "Define hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d66251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining hyperparameters of best model\n",
    "input_size = next(iter(train_dataloader))['target_sequences']['sequence'].shape[2]\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "n_labels = input_size\n",
    "rnn_type = 'lstm'\n",
    "model_type ='deterministic'\n",
    "\n",
    "lr = 0.01\n",
    "n_labels = input_size\n",
    "epochs = 15\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d426a4c-8065-4cf5-b761-089d1ba33daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'seed':seed,\n",
    "          'input_size':input_size,\n",
    "          'hidden_size':hidden_size,\n",
    "          'num_layers':num_layers,\n",
    "          'n_labels':n_labels,\n",
    "          'rnn_type':rnn_type,\n",
    "          'lr':lr,\n",
    "          'optim':'adam',\n",
    "          'epochs':epochs,\n",
    "          'model_type':model_type\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ef5687",
   "metadata": {},
   "source": [
    "and now train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484055d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = RNN(input_size=input_size,\\n            hidden_size=hidden_size,\\n            num_layers=num_layers,\\n            n_labels=n_labels,\\n            model=rnn_type,\\n           )\\n    \\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\\n\\ncriterion = torch.nn.BCEWithLogitsLoss(reduction=\\'none\\')\\n\\n# train\\nfor idx,epoch in enumerate(range(1,epochs+1)):\\n    loss = train_one_epoch(model, train_dataloader, epoch, criterion, optimizer);\\n    _,metrics = eval_model(model,val_dataloader,dataset, [\\'recall@30\\'])\\n    if idx % 5 == 0 or idx == epochs-1:\\n        print(f\"epoch {epoch}\\t| loss {loss}\\t| recall@30 {metrics[\\'recall@30_adm\\']}\") \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = RNN(input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            n_labels=n_labels,\n",
    "            model=rnn_type,\n",
    "           )\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "# train\n",
    "for idx,epoch in enumerate(range(1,epochs+1)):\n",
    "    loss = train_one_epoch(model, train_dataloader, epoch, criterion, optimizer);\n",
    "    _,metrics = eval_model(model,val_dataloader,dataset, ['recall@30'])\n",
    "    if idx % 5 == 0 or idx == epochs-1:\n",
    "        print(f\"epoch {epoch}\\t| loss {loss}\\t| recall@30 {metrics['recall@30_adm']}\") \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d246a8f-c1cc-448d-85be-3120ad566aca",
   "metadata": {},
   "source": [
    "or load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81fa1376-48cb-4b04-8995-5987a62901ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'pleasant-music-50'\n",
    "model_folder = os.path.join(settings.data_base,settings.models_folder,model_name)\n",
    "hypp_save_path = os.path.join(model_folder, 'hyper_parameters.json')\n",
    "weights_save_path = os.path.join(model_folder,\"weights\")\n",
    "\n",
    "params = dict(input_size = input_size,\n",
    "              hidden_size=hidden_size,\n",
    "              num_layers=num_layers,\n",
    "              n_labels=n_labels,\n",
    "              model=rnn_type\n",
    "             )\n",
    "\n",
    "#hyperparameters\n",
    "with open(hypp_save_path,'r') as f:\n",
    "    params_loaded = json.load(f)\n",
    "    \n",
    "# weights\n",
    "weights = torch.load(weights_save_path)\n",
    "\n",
    "new_model = RNN(**params_loaded)\n",
    "new_model.load_state_dict(torch.load(weights_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4216298-df77-4e76-b073-9d35424ccbd9",
   "metadata": {},
   "source": [
    "# basic performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a61135a1-cae7-48f3-aa43-fb5507b93599",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outs, train_golden = outs2df(new_model,train_dataloader,dataset,return_golden = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1f0e406-aded-4fc0-8619-08fc4181902a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metrics\n",
       "f1_diag       0.192786\n",
       "f1@30_diag    0.249744\n",
       "f1_adm        0.271918\n",
       "f1@30_adm     0.380333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_thresholds = get_prediction_thresholds(train_outs,train_golden,method='max f1')\n",
    "loss, metric = eval_model(new_model,val_dataloader,dataset,decision_thresholds,['f1','f1@30'])\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8078db-0290-48dd-9127-4237f3e6fe0e",
   "metadata": {},
   "source": [
    "# Findings\n",
    "\n",
    "Final f1 was 0.27. COmparing to the f1 obtained with mc dropout+LR it is lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f9447-aa67-4609-9d6a-7ffe0cdd3139",
   "metadata": {},
   "source": [
    "# Now abstaining based on the thresholds of each diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "282b0608-1b91-4392-9306-54fa2f1bc20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs, golden = outs2df(new_model,val_dataloader,dataset,return_golden = True)\n",
    "k = 30\n",
    "topk_outputs = model_outputs.apply(lambda row: row.nlargest(k),axis=1)\n",
    "\n",
    "# fix missing columns from previous operation\n",
    "missing_cols = [col for col in model_outputs.columns if col not in topk_outputs.columns]\n",
    "topk_outputs_all_cols = pd.concat([topk_outputs,pd.DataFrame(columns=missing_cols)])\n",
    "topk_outputs_all_cols = topk_outputs_all_cols[model_outputs.columns]\n",
    "\n",
    "## sometimes k > (#logits>0) so we will turn all 0 logits into nan so that the following lines don't convert them to predictions\n",
    "topk_outputs_all_cols = topk_outputs_all_cols.mask(topk_outputs_all_cols == 0,np.nan)\n",
    "# done, continuing...\n",
    "\n",
    "topk_predictions = np.where(topk_outputs_all_cols.isna(),0,1)\n",
    "topk_predictions = pd.DataFrame(data=topk_predictions,columns=model_outputs.columns,index=model_outputs.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49f7e3d7-032a-4d41-88d6-1da43c531b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstain(row,model_outputs,decision_thresholds):\n",
    "    \"\"\"\n",
    "    Receives a row which contains the predictions of all diagnoses (0 or 1) for a given admission.\n",
    "    Also receives df_metrics, which contains the LRs trained on each diagnostic (that predicts if TP or FP)\n",
    "    And stats_outs contains the means and variances of the forward passes.\n",
    "    \n",
    "    this function will turn some predictions from 1 to 0 if the LR model predicts it will be a FP.\n",
    "    \"\"\"\n",
    "    new_row = row.copy()\n",
    "    admission_outputs = model_outputs.loc[row.name,:]\n",
    "    for index,elem in row.iteritems():\n",
    "        if elem == 1:\n",
    "            proba_predicted = admission_outputs[index]\n",
    "            \n",
    "            if decision_thresholds.loc[index,'threshold'] > proba_predicted:\n",
    "                new_row[index] = 0\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a11e7a4-519c-4d01-b3e2-1736b1848547",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_predictions_abstained = topk_predictions.apply(lambda row: abstain(row, model_outputs,decision_thresholds),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "318dcf42-36c7-46d2-9e40-610d340d1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk_outputs_all_cols_after_abstention = topk_outputs_all_cols.fillna(0).mask(top_k_predictions_abstained == 0,0)\n",
    "metrics_w_abstention = compute_metrics(topk_outputs_all_cols_after_abstention,top_k_predictions_abstained,golden,['precision@30','recall@30','f1@30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20d39645-ea31-4090-9fc8-ad5ffd40bdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metrics\n",
       "precision@30_adm    0.333004\n",
       "recall@30_adm       0.576964\n",
       "f1@30_adm           0.403593\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_w_abstention.iloc[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d418ce3-b666-4e30-a3a1-9f6cce2747ec",
   "metadata": {},
   "source": [
    "# Conclusion 2 (more important)\n",
    "\n",
    "Abstaining using the thresholds that maximize f1 doesn't improve f1 more than my method!!! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (simao thesis)",
   "language": "python",
   "name": "simao_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
