{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# protection against running this cell multiple times\n",
    "assert os.path.dirname(cwd).split('/')[-1] == 'master-thesis','Oops, directory already changed previously as indended. Ignoring...'\n",
    "\n",
    "# change working directory (if assert passed)\n",
    "new_cwd = os.path.dirname(cwd) # parent directory\n",
    "os.chdir(new_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rnn_utils import DiagnosesDataset, split_dataset, MYCOLLATE\n",
    "from rnn_utils import RNN, train_one_epoch, eval_model, compute_loss\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid, ParameterSampler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from config import Settings; settings = Settings()\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 'diag_only/mimic_iv_quick_baseline_dataset'\n",
    "\n",
    "# model\n",
    "grouping = 'ccs'\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "seed = settings.random_seed\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset at data/model_ready_dataset/diag_only/mimic_iv_quick_baseline_dataset\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = os.path.join(settings.data_base,settings.model_ready_dataset_folder,dataset_id)\n",
    "print('dataset at',dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiagnosesDataset(os.path.join(dataset_folder,'mimic_iv_quick_baseline_dataset.json'),grouping)\n",
    "\n",
    "train_dataset = DiagnosesDataset(os.path.join(dataset_folder,'train_subset.json'),grouping)\n",
    "val_dataset = DiagnosesDataset(os.path.join(dataset_folder,'val_subset.json'),grouping)\n",
    "test_dataset = DiagnosesDataset(os.path.join(dataset_folder,'test_subset.json'),grouping)\n",
    "\n",
    "\n",
    "len(train_dataset)\n",
    "len(val_dataset)\n",
    "len(test_dataset)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size,collate_fn=MYCOLLATE(dataset),shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=batch_size,collate_fn=MYCOLLATE(dataset)) #batch_size here is arbitrary and doesn't affect total validation speed\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=batch_size,collate_fn=MYCOLLATE(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/debian/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data and train conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = input_size = next(iter(train_dataloader))['target_sequences']['sequence'].shape[2]\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: 27\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    'hidden_size':[50,75,100],\n",
    "    'num_layers':[2],\n",
    "    'lr':[0.01,0.02,0.03],\n",
    "    'model':['rnn','gru','lstm']\n",
    "    \n",
    "}\n",
    "meta_parameters = {\n",
    "    'epochs':10\n",
    "}\n",
    "\n",
    "params = ParameterGrid(hyperparameters)\n",
    "print(f'params:',len(params))\n",
    "\n",
    "#random_params = ParameterSampler(params.param_grid,n_iter=len(params)-1,random_state=231)\n",
    "#next(iter(random_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(train_dataloader))['train_sequences']['sequence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([64, 30, 18, 12, 11,  6,  5,  5,  5,  5,  5,  3,  2,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.batch_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2u15qa8g) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.034 MB of 0.034 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hardy-star-54</strong>: <a href=\"https://wandb.ai/snovaisg/basic_deterministic_model_tunning/runs/2u15qa8g\" target=\"_blank\">https://wandb.ai/snovaisg/basic_deterministic_model_tunning/runs/2u15qa8g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220605_181953-2u15qa8g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2u15qa8g). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/debian/Simao/master-thesis/wandb/run-20220605_182113-3easvw7w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/snovaisg/basic_deterministic_model_tunning/runs/3easvw7w\" target=\"_blank\">graceful-shadow-55</a></strong> to <a href=\"https://wandb.ai/snovaisg/basic_deterministic_model_tunning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "RNN.forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     19\u001b[0m     log \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 21\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     23\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m:epoch,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m:loss})\n\u001b[1;32m     25\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m eval_model(model,train_dataloader,dataset,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mfilter(regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_adm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Simao/master-thesis/rnn_utils.py:560\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, epoch, criterion, optimizer, take_mc_average)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m    559\u001b[0m inputs \u001b[38;5;241m=\u001b[39m history_sequences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 560\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtake_mc_average\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outs, target_sequences[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# zero-out positions of the loss corresponding to padded inputs\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# if a sequence has all zeros it is considered to be a padding.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# Comment: safer way to do this would be a solution using the lengths...\u001b[39;00m\n",
      "File \u001b[0;32m~/Simao/miniconda3/envs/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: RNN.forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "for idx,param_set in enumerate(params):\n",
    "    config = {**param_set, \n",
    "              **meta_parameters}\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"basic_deterministic_model_tunning\", \n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    model = RNN(input_size=input_size,\n",
    "              hidden_size=config['hidden_size'],\n",
    "              num_layers=config['num_layers'],\n",
    "              n_labels=n_labels,\n",
    "              model=config['model'])\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    \n",
    "    for epoch in range(1,config['epochs']+1):\n",
    "        log = {}\n",
    "        \n",
    "        loss = train_one_epoch(model,train_dataloader,epoch,criterion,optimizer);\n",
    "        \n",
    "        wandb.log({'epoch':epoch,'loss':loss})\n",
    "        \n",
    "    train_metrics = eval_model(model,train_dataloader,dataset,metrics=['roc','f1'])[1].filter(regex='_adm')\n",
    "    val_metrics = eval_model(model,val_dataloader,dataset,metrics=['roc','f1'])[1].filter(regex='_adm')\n",
    "    train_metrics.index = ['train_' + n for n in train_metrics.index]\n",
    "    val_metrics.index = ['val_' + n for n in val_metrics.index]\n",
    "        \n",
    "\n",
    "    log = dict()\n",
    "\n",
    "    log.update(train_metrics.to_dict())\n",
    "    log.update(val_metrics.to_dict())\n",
    "    log.update({'loss':loss})\n",
    "\n",
    "    wandb.log(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best model\n",
    "\n",
    "- name: silver-salad-21\n",
    "- lr: 0.01\n",
    "- model_type = 'lstm'\n",
    "- num_layers = 1\n",
    "- hidden_size = 75\n",
    "- epochs: 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'hidden_size':[25,50,75],\n",
    "    'num_layers':[2],\n",
    "    'lr':[0.01,0.02,0.03],\n",
    "    'model':['rnn','gru','lstm']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 15}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:fv6qbc51) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">royal-dust-52</strong>: <a href=\"https://wandb.ai/snovaisg/basic_deterministic_model_tunning/runs/fv6qbc51\" target=\"_blank\">https://wandb.ai/snovaisg/basic_deterministic_model_tunning/runs/fv6qbc51</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220421_175909-fv6qbc51/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:fv6qbc51). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/simaonovais/Documents/GitHub/master-thesis/wandb/run-20220421_175950-35ueo6uc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/snovaisg/basic_deterministic_model_tunning/runs/35ueo6uc\" target=\"_blank\">glamorous-dragon-53</a></strong> to <a href=\"https://wandb.ai/snovaisg/basic_deterministic_model_tunning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/snovaisg/basic_deterministic_model_tunning/runs/35ueo6uc?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x13939c9a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_set = dict(hidden_size=75,num_layers=1,lr=0.01,model_type='lstm',epochs=15,mode='metrics')\n",
    "wandb.init(\n",
    "    project=\"basic_deterministic_model_tunning\", \n",
    "    config=param_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=input_size,\n",
    "            hidden_size=param_set['hidden_size'],\n",
    "            num_layers=param_set['num_layers'],\n",
    "            n_labels=n_labels,\n",
    "            model=param_set['model_type'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=param_set['lr'])\n",
    "for epoch in range(1,config['epochs']+1):\n",
    "    loss = train_one_epoch(model,train_dataloader,epoch,criterion,optimizer);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {**param_set, \n",
    "              **meta_parameters}\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"basic_deterministic_model_tunning\", \n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    model = RNN(input_size=input_size,\n",
    "              hidden_size=config['hidden_size'],\n",
    "              num_layers=config['num_layers'],\n",
    "              n_labels=n_labels,\n",
    "              model=config['model'])\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    \n",
    "    for epoch in range(1,config['epochs']+1):\n",
    "        log = {}\n",
    "        \n",
    "        loss = train_one_epoch(model,train_dataloader,epoch,criterion,optimizer);\n",
    "        \n",
    "        wandb.log({'epoch':epoch,'loss':loss})\n",
    "        \n",
    "    train_metrics = eval_model(model,train_dataloader,dataset,metrics=['roc','f1'])[1].filter(regex='_adm')\n",
    "    val_metrics = eval_model(model,val_dataloader,dataset,metrics=['roc','f1'])[1].filter(regex='_adm')\n",
    "    train_metrics.index = ['train_' + n for n in train_metrics.index]\n",
    "    val_metrics.index = ['val_' + n for n in val_metrics.index]\n",
    "        \n",
    "\n",
    "    log = dict()\n",
    "\n",
    "    log.update(train_metrics.to_dict())\n",
    "    log.update(val_metrics.to_dict())\n",
    "    log.update({'loss':loss})\n",
    "\n",
    "    wandb.log(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (simao thesis)",
   "language": "python",
   "name": "simao_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
